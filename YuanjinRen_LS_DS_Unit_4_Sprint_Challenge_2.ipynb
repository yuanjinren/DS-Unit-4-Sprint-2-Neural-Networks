{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S2-NNF-DS10",
      "language": "python",
      "name": "u4-s2-nnf-ds10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "YuanjinRen_LS_DS_Unit_4_Sprint_Challenge_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuanjinren/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/YuanjinRen_LS_DS_Unit_4_Sprint_Challenge_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39fVLlIQJkxS"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2*\n",
        "\n",
        "# Sprint Challenge - Neural Network Foundations\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. [Defining Neural Networks](#Q1)\n",
        "2. [Simple Perceptron](#Q2)\n",
        "    - Perceptron\n",
        "    - Multilayer Perceptron\n",
        "    - Analyze and Compare\n",
        "4. [Keras MMP](#Q3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_-o1ecZJkxT"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## 1. Defining Neural Networks \n",
        "\n",
        "Write *your own* definitions for the following terms:\n",
        "\n",
        "- **Neuron:**\n",
        "Neuron is the basic component of the neural network. They are highly interconnected elements which are organized in layers which process information using dynamic state responses to external inputs.\n",
        "- **Input Layer:**\n",
        "It is the starting point of the neural network, which would communicate to hidden layers. Nodes in input layer are passive since they don't change the data. Their job is receiving value and then sending to the next hidden layer. \n",
        "- **Hidden Layer:**\n",
        "Hidden layer(s) are layers between input layer and output layer. All mathematical operations are executed in hidden layers. Hidden layers make the neural networks as superior to machine learning algorithms.\n",
        "- **Output Layer:**\n",
        "Output layer is the last layer of the neural network. It produces the final output results. The output layer takes the inputs which are passed in from the layers before it, and performs the calculations through its neurons and then the output is computed.\n",
        "- **Activation Function:**\n",
        "Activation functions are a crucial component of deep learning. They are used to determine the firing of neurons in a neural network. They are different types of activation functions in different neural network, basically, can be divided into linear activation function and non-linear activation function. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is7J8ZxOJkxU"
      },
      "source": [
        "Explain how back propagation works as if you were explaining it to a five year-old. Use your own words, but feel free to reference external materials for this question. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkSVM-cnPiIA"
      },
      "source": [
        "To understand back propagation, we need to know forward propagation first. In a neural network, the input data is fed in the forward direction through the network through input layer and hidden layers. There are several nodes in different layers. For each node in each layer, we need to give it a weight to help it do the calculation. Each hidden layer accepts the input data, processes it as per the weights and activation function, and then passes to the next layer. This process is called forward propagation. \n",
        "\n",
        "If we compare the result to our expected output, we will discover that our prediction is incorrect. Since we want to find the absolute best weight values that would help calculate the correct output based on any given input, we need to first calculate an error value using an error function, which should be minimized. This whole process of going back to track through the network is called back propagation. Gradient descent method is normally used to find out the minimum value of error function. This back propagation algorithm also can be treated as a training process. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS5HPS9LJkxa"
      },
      "source": [
        "Remember our Simple Perceptron Class from Monday. In a simple prediction describe the process of making a prediction. How do you go from inputs to predicted output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ikiO7-yRuQk"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrO6fX_MSvTm"
      },
      "source": [
        "The above picture is a simple perceptron. X1, x2, x3 are inputs, w1, w2 and w3 are weights, ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAdQAAAAoCAYAAABHAAu6AAAEq0lEQVR4Ae3dX6gVRRzA8a//Lc0UwVBSVAgpUHxRyyJCQyjC/z2IVhD0IBE9iD4IPQRipEYUhH8L7EGyh9AX/+A/IlIqyKIgiiJNpBS1KLAHjeQHc7nDer1393C8nHW/A8OZ3flzZj8cGHb3zAwYFFBAAQUUUEABBRSokcAkYBvwQYoja9R3u6qAAgoooEDHCMwAVqTenAKe7pie2REFFFBAAQVqJnAf8BJwELinZn23uwoooIACCnSMwHTgDeAH4IGO6ZUdUUABBRRQoEYC44GIEfYBq1PaDwUUUEABBRSoIPAM8CWwGfgsG1wrNGFRBRRQQAEFFAiBQcAIKRRQQAEFFFBAAQUUUEABBRToN4G4Ex3SQox6BgUUUEABBRRIAh8C/6f4G9BbPJeV3aWgAgoooIACCnQLTAaupIFyVffpW6YeBS4ADqi3JDJDAQUUUKCpAovTgPpPyTmn2x1Qm/pT8boVUEABBfoSeDsNql8Dw/oo/Aiwso8yZiuggAIKKNBIgaFp7mm8T323kQJetAIKKKCAAm0SmAL8me5UF7WpTZtRQAEFFFCgkQJL0oB6GZjYSAEvWgEFFFBAgTYJvJMG1Vh20PmmbUK1GQUUUECB5gnE+9Sv0qC6oXmX7xUroIACCijQPoGpwF/Af8C8ks2+DnyRHhXPAWJz8tgGLg+vAseyO98dwGzgLmAvsDEvbFoBBRRQQIE7QWBZuks9WeJiJgDLgUNpUPwceBG4u1A33svGP4nHAaOBa8DzqcwR4JVCeQ8VUEABBRSovcAYIP6c9FqFK1kD/A1My+qMBR5PxwOB68CDwFrgV2AdEGUiHXeqEfI66ZQfCiiggAIK1FPgE+A4EINg2bAFOFso/ASwPjt3HlgIfJoG67eAncBzWZlinSzLpAIKKKCAAvUReBm4WGFz8XiUuwLYCvwLxBrBDwP3p0fAM7JLjz88/QIsSI+FfwIOZPk91cmyTSqggAIKKFAPgZnAVeCpCt09DZxIyxbuB34Glqb63wIPZW1F/kfpOL7jEhDvYPNQrJPnmVZAAQUUUKDjBUYCPwKbK/Z0FDAg1Ym5q8NTOj5jd5quvDh9b7ZecOzFGsd56KlOnm9aAQUUUECBjhfYnaa+xEDXjjAXONzDv317a7uVOr21Z54CCiiggAL9KvBCmnsaa/q2KzwGnAE2VWiwlToVmreoAgoooIACt08gprnEfqjPlviKeCzcNXe0RHFGlClUKNNKnUITHiqggAIKKNC/AvHO8htgW8mvfTLddZYsbjEFFFBAAQWaIfAe8F22qEJvVx3vVvcAsRG5QQEFFFBAAQWSQExtiaUAfwdi6ktf8Y9U/qiCCiiggAIKKNAtEKsaxYBaNX7c3YQpBRRQQAEFFIit2lqJg6VTQAEFFFBAgZsFXIz+ZhPPKKCAAgooUFmg7GL0seXam8Csyt9gBQUUUEABBe5wgbKL0cd6u7Eh+PdATJ0xKKCAAgoooEBBoGsx+lilKDYUz+PeQtl9wPzCOQ8VUEABBRRovEC+GH382SgWus9jcdUiB9TG/2QEUEABBRToSSBfjD72MD1UiO8XKsWA6iPfAoqHCtRF4AYQ8KIbsW49gwAAAABJRU5ErkJggg==)is computation occurs in neuron, and y is the final output. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UQnlcIITw92"
      },
      "source": [
        "First, take the inputs from the input layer, and use the value of each node times each weight. Secondly, these input-weight products are summed and then the sum is passed through a nodeâ€™s so-called activation function, to determine whether and to what extent that signal should progress further through the network. The result we get after activation function calculation is the final output y.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL0XumFYJkxd"
      },
      "source": [
        "<a id=\"Q2\"></a>\n",
        "## 2. Simple Perceptron\n",
        "\n",
        "In this question, you will build two neural networks using Tensorflow Keras. After you build these two models, compare the results of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjswX8diJkxe"
      },
      "source": [
        "\"\"\"\n",
        "Our Dataset\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "xx, yy = np.meshgrid(np.linspace(-3, 3, 50),\n",
        "                     np.linspace(-3, 3, 50))\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "\"Use this X & y in the following 2 models\"\n",
        "X = rng.randn(300, 2)\n",
        "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
        "             dtype=int)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZvOG3qpXE6_",
        "outputId": "12324d9f-e176-4b4e-90bf-7c37696f286f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((300, 2), (300,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G6-YD8mJkxh"
      },
      "source": [
        "### Simple Perceptron\n",
        "Construct a simple perceptron using Keras. You model should have 1 dense layer with a single neuron and a sigmoid activation function. Your model should be called `model1` and make sure to save the results of your fit statement to a variable called `h1`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fzn9tI-Jkxh",
        "outputId": "79237e89-d4f3-407d-eb56-14e6b648421c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Instantiating Model\n",
        "model1 = Sequential([\n",
        "    Dense(3, activation=\"sigmoid\", input_dim=2),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model1.compile(optimizer=\"sgd\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Fitting and Results\n",
        "h1 = model1.fit(X, y, epochs=100, batch_size=10)\n",
        "\n",
        "# Scores\n",
        "scores = model1.evaluate(X, y)\n",
        "print(f\"{model1.metrics_names[1]}: {scores[1]}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 0s 964us/step - loss: 0.7447 - accuracy: 0.4733\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 917us/step - loss: 0.7338 - accuracy: 0.4733\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 951us/step - loss: 0.7254 - accuracy: 0.4733\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.4733\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 985us/step - loss: 0.7138 - accuracy: 0.4600\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7098 - accuracy: 0.4533\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 944us/step - loss: 0.7067 - accuracy: 0.4200\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 967us/step - loss: 0.7044 - accuracy: 0.4033\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 941us/step - loss: 0.7026 - accuracy: 0.4000\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 976us/step - loss: 0.7010 - accuracy: 0.3900\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 921us/step - loss: 0.7001 - accuracy: 0.4033\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 921us/step - loss: 0.6990 - accuracy: 0.4367\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 863us/step - loss: 0.6983 - accuracy: 0.4567\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 981us/step - loss: 0.6978 - accuracy: 0.4967\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 977us/step - loss: 0.6973 - accuracy: 0.5233\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 994us/step - loss: 0.6970 - accuracy: 0.5467\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6967 - accuracy: 0.5533\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.5667\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.5733\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.5633\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.5600\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6957 - accuracy: 0.5767\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 953us/step - loss: 0.6956 - accuracy: 0.5767\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 923us/step - loss: 0.6955 - accuracy: 0.5633\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.5500\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 981us/step - loss: 0.6953 - accuracy: 0.5567\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.5467\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 0s 963us/step - loss: 0.6951 - accuracy: 0.5367\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.5300\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.5367\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 0s 981us/step - loss: 0.6950 - accuracy: 0.5300\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.5300\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.5300\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.5233\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 0s 907us/step - loss: 0.6947 - accuracy: 0.5300\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 0s 986us/step - loss: 0.6945 - accuracy: 0.5267\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 951us/step - loss: 0.6946 - accuracy: 0.5267\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 0s 993us/step - loss: 0.6946 - accuracy: 0.5267\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 0s 998us/step - loss: 0.6944 - accuracy: 0.5267\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 913us/step - loss: 0.6944 - accuracy: 0.5267\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5333\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 986us/step - loss: 0.6943 - accuracy: 0.5200\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 0s 921us/step - loss: 0.6942 - accuracy: 0.5267\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 960us/step - loss: 0.6941 - accuracy: 0.5300\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 0s 840us/step - loss: 0.6941 - accuracy: 0.5300\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5300\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 927us/step - loss: 0.6940 - accuracy: 0.5233\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 0s 936us/step - loss: 0.6939 - accuracy: 0.5233\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 0s 908us/step - loss: 0.6938 - accuracy: 0.5267\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 0s 948us/step - loss: 0.6938 - accuracy: 0.5233\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 0s 955us/step - loss: 0.6937 - accuracy: 0.5300\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5267\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 0s 958us/step - loss: 0.6936 - accuracy: 0.5200\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 0s 929us/step - loss: 0.6937 - accuracy: 0.5233\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 0s 920us/step - loss: 0.6935 - accuracy: 0.5233\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 0s 885us/step - loss: 0.6935 - accuracy: 0.5233\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 0s 935us/step - loss: 0.6935 - accuracy: 0.5200\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 0s 855us/step - loss: 0.6934 - accuracy: 0.5267\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 0s 923us/step - loss: 0.6933 - accuracy: 0.5233\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5233\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 0s 998us/step - loss: 0.6931 - accuracy: 0.5267\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5233\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 0s 959us/step - loss: 0.6931 - accuracy: 0.5267\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5300\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 0s 968us/step - loss: 0.6931 - accuracy: 0.5267\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 0s 894us/step - loss: 0.6930 - accuracy: 0.5267\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 0s 953us/step - loss: 0.6930 - accuracy: 0.5267\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 0s 930us/step - loss: 0.6929 - accuracy: 0.5267\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 0s 927us/step - loss: 0.6930 - accuracy: 0.5267\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 0s 978us/step - loss: 0.6929 - accuracy: 0.5233\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 0s 983us/step - loss: 0.6928 - accuracy: 0.5267\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5267\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 0s 904us/step - loss: 0.6927 - accuracy: 0.5267\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 0s 974us/step - loss: 0.6927 - accuracy: 0.5267\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 0s 950us/step - loss: 0.6927 - accuracy: 0.5267\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 0s 853us/step - loss: 0.6925 - accuracy: 0.5267\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 0s 978us/step - loss: 0.6925 - accuracy: 0.5267\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 0s 974us/step - loss: 0.6926 - accuracy: 0.5267\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 0s 987us/step - loss: 0.6924 - accuracy: 0.5267\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 0s 933us/step - loss: 0.6924 - accuracy: 0.5267\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 0s 979us/step - loss: 0.6924 - accuracy: 0.5267\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 0s 898us/step - loss: 0.6923 - accuracy: 0.5267\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 0s 975us/step - loss: 0.6923 - accuracy: 0.5267\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 0s 983us/step - loss: 0.6923 - accuracy: 0.5267\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5267\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 0s 920us/step - loss: 0.6921 - accuracy: 0.5267\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 0s 923us/step - loss: 0.6921 - accuracy: 0.5267\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 0s 888us/step - loss: 0.6923 - accuracy: 0.5267\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 0s 946us/step - loss: 0.6920 - accuracy: 0.5267\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 0s 912us/step - loss: 0.6920 - accuracy: 0.5267\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 0s 932us/step - loss: 0.6920 - accuracy: 0.5267\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5267\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 0s 899us/step - loss: 0.6920 - accuracy: 0.5267\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 0s 871us/step - loss: 0.6919 - accuracy: 0.5267\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 0s 941us/step - loss: 0.6918 - accuracy: 0.5267\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 0s 859us/step - loss: 0.6918 - accuracy: 0.5267\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 0s 866us/step - loss: 0.6917 - accuracy: 0.5267\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 0s 816us/step - loss: 0.6917 - accuracy: 0.5267\n",
            "Epoch 99/100\n",
            "30/30 [==============================] - 0s 952us/step - loss: 0.6917 - accuracy: 0.5267\n",
            "Epoch 100/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5267\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5267\n",
            "accuracy: 0.5266666412353516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvrCXEPBJkxk"
      },
      "source": [
        "### Multi-Layer Perceptron\n",
        "Now construct a multi-layer perceptron using. Here are some architecture suggestions: \n",
        "- 2 Hidden Layers\n",
        "- 5-32 Neurons in the Hidden Layers\n",
        "- Your pick of activation function and optimizer\n",
        "- Incorporate the Callback function below into your model\n",
        "\n",
        "Your model should be called `model2` and make sure to save the results of your fit statement to a variable called `h2`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH6zgASmZkMb"
      },
      "source": [
        "from keras.optimizers import Adam, SGD"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atU_1rRRJkxk"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if(logs.get('accuracy') > .99999):   \n",
        "            self.model.stop_training = True"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAwR8R2PJkxn",
        "outputId": "495f305b-e73a-4bf5-9e99-f1bafd66535f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "mycallback = myCallback()\n",
        "model2 = Sequential([\n",
        "    Dense(32, activation=\"relu\", input_dim=2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "opt = Adam(learning_rate=0.001)\n",
        "# Compile\n",
        "model2.compile(optimizer=opt, \n",
        "               loss=\"binary_crossentropy\", \n",
        "               metrics=[\"accuracy\"]\n",
        "               )\n",
        "\n",
        "# Fitting and Results\n",
        "h2 = model2.fit(X, y, epochs=100, batch_size=10, callbacks=[mycallback])\n",
        "scores = model2.evaluate(X, y)\n",
        "print(f\"{model2.metrics_names[1]}: {scores[1]}\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6598 - accuracy: 0.6733\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6016 - accuracy: 0.7900\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5543 - accuracy: 0.8200\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5053 - accuracy: 0.8567\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.8967\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.4010 - accuracy: 0.9400\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.9600\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.3059 - accuracy: 0.9700\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2701 - accuracy: 0.9767\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2386 - accuracy: 0.9800\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2175 - accuracy: 0.9800\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.9667\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.9767\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1656 - accuracy: 0.9767\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9767\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1433 - accuracy: 0.9833\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1344 - accuracy: 0.9833\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1281 - accuracy: 0.9833\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.9833\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9900\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.9900\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9933\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1003 - accuracy: 0.9833\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 1.0000\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9933\n",
            "accuracy: 0.9933333396911621\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtNbhpQ2Jkxq"
      },
      "source": [
        "### Analyze and Compare\n",
        "\n",
        "**Before you Start**: You will need to install an additional library for this next segment. Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
        "\n",
        "\n",
        "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPH3uDStdEWD",
        "outputId": "c20d86fb-b7c3-4785-ccd5-eddef1e6bbe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "!pip install mlxtend"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.6/dist-packages (0.14.0)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.0.5)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from mlxtend) (50.3.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.1->mlxtend) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->mlxtend) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.17.1->mlxtend) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj3jvLWIJkxr",
        "outputId": "fd8b29f0-0f28-4933-fddf-bd983e9644f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "# Do Not change anything in this cell\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "h = .02  # step size in the mesh\n",
        "\n",
        "# create a mesh to plot in\n",
        "x_min, x_max = X[:, 0].min() - .2, X[:, 0].max() + .2\n",
        "y_min, y_max = X[:, 1].min() - .2, X[:, 1].max() + .2\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                     np.arange(y_min, y_max, h))\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "\n",
        "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
        "\n",
        "    ax = plt.subplot(1,2, grd)\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
        "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
        "    plt.title(title)\n",
        "\n",
        "plt.show();"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mlxtend/plotting/decision_regions.py:244: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
            "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLYzOgBUJkxu"
      },
      "source": [
        "Why does the Perceptron (`model1`) only achieve ~70% accuracy? What is the architectural property of the Multi-Layer Perceptron that allows it more accurately learn the relationship between X and y? \n",
        "\n",
        "Why might this property be useful in more complex data such as images?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gj3f5yVeC02"
      },
      "source": [
        "The added layers, and the ability to \"backpropagate\" account for why the score is so dramatically improved. A perceptron is limited to a feed-forward process, so it can't go back to implement back propagation (i.e. making adjustments on the error and the weights). The multilayer has better performance because it can \"learn\" from this error, which allows us to get these high accuracy scores in our predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3EYX_UzJkxw"
      },
      "source": [
        "## 3. Keras MMP <a id=\"Q3\"></a>\n",
        "\n",
        "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
        "Use the Heart Disease Dataset (binary classification)\n",
        "Use an appropriate loss function for a binary classification task\n",
        "Use an appropriate activation function on the final layer of your network.\n",
        "Train your model using verbose output for ease of grading.\n",
        "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
        "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
        "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
        "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "id": "fURbttd1Jkxx",
        "outputId": "76169965-8a91-4938-9da5-e3637e890aae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
        "df = df.sample(frac=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(303, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>114</td>\n",
              "      <td>318</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>269</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>121</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>340</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>254</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "1     37    1   2       130   250    0  ...      0      3.5      0   0     2       1\n",
              "291   58    1   0       114   318    0  ...      0      4.4      0   3     1       0\n",
              "129   74    0   1       120   269    0  ...      1      0.2      2   1     2       1\n",
              "16    58    0   2       120   340    0  ...      0      0.0      2   0     2       1\n",
              "197   67    1   0       125   254    1  ...      0      0.2      1   2     3       0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spC4FENZe6Y7"
      },
      "source": [
        "# import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3B8FW2XJkx0"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, Normalizer, OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owmQ6Skpe-Hm"
      },
      "source": [
        "# baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPfhX33ofDuC"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "df_transform = scaler.fit_transform(df)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ijsp9Yb7hRvH",
        "outputId": "29c93d1d-7692-4622-82df-2e06b6508727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_transform[:, :-1], df_transform[:, -1], \n",
        "test_size=0.20, random_state=42)\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(242, 13) (61, 13) (242,) (61,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbASjqNMjlOf"
      },
      "source": [
        "def create_model():\n",
        "  opt = Adam(learning_rate=0.01)\n",
        "  model = Sequential([\n",
        "                      Dense(32, input_dim=13, activation='relu'),\n",
        "                      Dense(20, activation='relu'),\n",
        "                      Dense(1, activation='sigmoid')               \n",
        "  ])\n",
        "  model.compile(optimizer=opt,\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1jPEwkDkEyr",
        "outputId": "e91b14a5-360b-4e14-e2a6-ec50d6862faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "baseline = create_model()\n",
        "baseline.fit(X_train, y_train, epochs=100, \n",
        "             batch_size=15,\n",
        "             validation_data=(X_test, y_test),\n",
        "             verbose=1,\n",
        "             callbacks = [mycallback])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_58 (Dense)             (None, 32)                448       \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 20)                660       \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 1,129\n",
            "Trainable params: 1,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.6028 - accuracy: 0.7025 - val_loss: 0.5120 - val_accuracy: 0.7377\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8264 - val_loss: 0.4715 - val_accuracy: 0.7869\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8388 - val_loss: 0.4526 - val_accuracy: 0.8197\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8347 - val_loss: 0.5234 - val_accuracy: 0.7869\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8636 - val_loss: 0.5182 - val_accuracy: 0.7869\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8512 - val_loss: 0.4648 - val_accuracy: 0.8197\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8843 - val_loss: 0.4801 - val_accuracy: 0.8197\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8554 - val_loss: 0.4584 - val_accuracy: 0.8033\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.8430 - val_loss: 0.4923 - val_accuracy: 0.8197\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8843 - val_loss: 0.5048 - val_accuracy: 0.8033\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3096 - accuracy: 0.8595 - val_loss: 0.5300 - val_accuracy: 0.7705\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3146 - accuracy: 0.8554 - val_loss: 0.5657 - val_accuracy: 0.7213\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2904 - accuracy: 0.8843 - val_loss: 0.4962 - val_accuracy: 0.7869\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2813 - accuracy: 0.8926 - val_loss: 0.4745 - val_accuracy: 0.8689\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.8843 - val_loss: 0.5229 - val_accuracy: 0.7705\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2543 - accuracy: 0.8802 - val_loss: 0.4872 - val_accuracy: 0.8361\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2578 - accuracy: 0.8843 - val_loss: 0.5051 - val_accuracy: 0.8197\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2593 - accuracy: 0.8926 - val_loss: 0.5396 - val_accuracy: 0.8033\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.8884 - val_loss: 0.5448 - val_accuracy: 0.7869\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.9008 - val_loss: 0.5225 - val_accuracy: 0.8361\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3178 - accuracy: 0.8430 - val_loss: 0.5352 - val_accuracy: 0.7869\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2630 - accuracy: 0.8926 - val_loss: 0.5422 - val_accuracy: 0.7541\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9091 - val_loss: 0.5774 - val_accuracy: 0.7705\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.8884 - val_loss: 0.6338 - val_accuracy: 0.7541\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.8926 - val_loss: 0.5343 - val_accuracy: 0.7705\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9256 - val_loss: 0.5746 - val_accuracy: 0.7541\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.2285 - accuracy: 0.9132 - val_loss: 0.5805 - val_accuracy: 0.7377\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2150 - accuracy: 0.9215 - val_loss: 0.5218 - val_accuracy: 0.8197\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1951 - accuracy: 0.9256 - val_loss: 0.5560 - val_accuracy: 0.8361\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.9298 - val_loss: 0.7167 - val_accuracy: 0.7541\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9256 - val_loss: 0.5648 - val_accuracy: 0.7869\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1715 - accuracy: 0.9380 - val_loss: 0.6019 - val_accuracy: 0.7705\n",
            "Epoch 33/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9380 - val_loss: 0.6158 - val_accuracy: 0.7705\n",
            "Epoch 34/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2268 - accuracy: 0.8967 - val_loss: 0.7297 - val_accuracy: 0.7377\n",
            "Epoch 35/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1951 - accuracy: 0.9256 - val_loss: 0.7040 - val_accuracy: 0.7541\n",
            "Epoch 36/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9256 - val_loss: 0.7408 - val_accuracy: 0.7377\n",
            "Epoch 37/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1652 - accuracy: 0.9339 - val_loss: 0.7027 - val_accuracy: 0.7541\n",
            "Epoch 38/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1642 - accuracy: 0.9380 - val_loss: 0.7075 - val_accuracy: 0.7377\n",
            "Epoch 39/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9380 - val_loss: 0.7199 - val_accuracy: 0.8033\n",
            "Epoch 40/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9463 - val_loss: 0.7981 - val_accuracy: 0.7541\n",
            "Epoch 41/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1284 - accuracy: 0.9587 - val_loss: 0.7720 - val_accuracy: 0.7705\n",
            "Epoch 42/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1327 - accuracy: 0.9463 - val_loss: 0.7370 - val_accuracy: 0.7705\n",
            "Epoch 43/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9545 - val_loss: 0.8734 - val_accuracy: 0.7705\n",
            "Epoch 44/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1232 - accuracy: 0.9545 - val_loss: 0.9935 - val_accuracy: 0.7705\n",
            "Epoch 45/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.9587 - val_loss: 0.8622 - val_accuracy: 0.7869\n",
            "Epoch 46/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9669 - val_loss: 1.0295 - val_accuracy: 0.7705\n",
            "Epoch 47/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1144 - accuracy: 0.9628 - val_loss: 0.9044 - val_accuracy: 0.7705\n",
            "Epoch 48/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1066 - accuracy: 0.9669 - val_loss: 1.0404 - val_accuracy: 0.7869\n",
            "Epoch 49/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9711 - val_loss: 0.9937 - val_accuracy: 0.7869\n",
            "Epoch 50/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1071 - accuracy: 0.9587 - val_loss: 1.1610 - val_accuracy: 0.7541\n",
            "Epoch 51/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1080 - accuracy: 0.9587 - val_loss: 0.9115 - val_accuracy: 0.7705\n",
            "Epoch 52/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9711 - val_loss: 0.8965 - val_accuracy: 0.7541\n",
            "Epoch 53/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9545 - val_loss: 1.0425 - val_accuracy: 0.7541\n",
            "Epoch 54/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.9339 - val_loss: 0.9452 - val_accuracy: 0.7705\n",
            "Epoch 55/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.9256 - val_loss: 0.8874 - val_accuracy: 0.7705\n",
            "Epoch 56/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1286 - accuracy: 0.9421 - val_loss: 1.0473 - val_accuracy: 0.7377\n",
            "Epoch 57/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1104 - accuracy: 0.9463 - val_loss: 1.0304 - val_accuracy: 0.7377\n",
            "Epoch 58/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9545 - val_loss: 1.0074 - val_accuracy: 0.7377\n",
            "Epoch 59/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9669 - val_loss: 1.2357 - val_accuracy: 0.7377\n",
            "Epoch 60/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.9752 - val_loss: 1.1958 - val_accuracy: 0.7213\n",
            "Epoch 61/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9793 - val_loss: 1.2542 - val_accuracy: 0.7377\n",
            "Epoch 62/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9752 - val_loss: 1.1872 - val_accuracy: 0.7541\n",
            "Epoch 63/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9711 - val_loss: 1.3264 - val_accuracy: 0.7049\n",
            "Epoch 64/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9793 - val_loss: 1.3034 - val_accuracy: 0.7213\n",
            "Epoch 65/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9793 - val_loss: 1.3018 - val_accuracy: 0.7377\n",
            "Epoch 66/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9793 - val_loss: 1.4877 - val_accuracy: 0.7049\n",
            "Epoch 67/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9380 - val_loss: 1.0691 - val_accuracy: 0.7377\n",
            "Epoch 68/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.9628 - val_loss: 1.1920 - val_accuracy: 0.7541\n",
            "Epoch 69/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1217 - accuracy: 0.9463 - val_loss: 1.3807 - val_accuracy: 0.7049\n",
            "Epoch 70/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9669 - val_loss: 1.3253 - val_accuracy: 0.7541\n",
            "Epoch 71/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9752 - val_loss: 1.2434 - val_accuracy: 0.7377\n",
            "Epoch 72/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9669 - val_loss: 1.3218 - val_accuracy: 0.7213\n",
            "Epoch 73/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9793 - val_loss: 1.4776 - val_accuracy: 0.7213\n",
            "Epoch 74/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9752 - val_loss: 1.7312 - val_accuracy: 0.7377\n",
            "Epoch 75/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9711 - val_loss: 1.5441 - val_accuracy: 0.7049\n",
            "Epoch 76/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9545 - val_loss: 1.5983 - val_accuracy: 0.7049\n",
            "Epoch 77/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9628 - val_loss: 1.3811 - val_accuracy: 0.7541\n",
            "Epoch 78/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9835 - val_loss: 1.3267 - val_accuracy: 0.7377\n",
            "Epoch 79/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9752 - val_loss: 1.4312 - val_accuracy: 0.7377\n",
            "Epoch 80/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9876 - val_loss: 1.6106 - val_accuracy: 0.7213\n",
            "Epoch 81/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9752 - val_loss: 1.5705 - val_accuracy: 0.7049\n",
            "Epoch 82/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.9876 - val_loss: 1.6324 - val_accuracy: 0.7541\n",
            "Epoch 83/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9835 - val_loss: 2.0823 - val_accuracy: 0.7049\n",
            "Epoch 84/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0916 - accuracy: 0.9669 - val_loss: 1.6745 - val_accuracy: 0.7541\n",
            "Epoch 85/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9339 - val_loss: 1.5887 - val_accuracy: 0.7213\n",
            "Epoch 86/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9504 - val_loss: 1.6432 - val_accuracy: 0.7049\n",
            "Epoch 87/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9752 - val_loss: 1.5322 - val_accuracy: 0.7377\n",
            "Epoch 88/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9793 - val_loss: 1.4970 - val_accuracy: 0.7213\n",
            "Epoch 89/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9876 - val_loss: 1.7170 - val_accuracy: 0.7049\n",
            "Epoch 90/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9793 - val_loss: 1.6313 - val_accuracy: 0.7213\n",
            "Epoch 91/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9793 - val_loss: 1.5542 - val_accuracy: 0.7541\n",
            "Epoch 92/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9876 - val_loss: 1.7422 - val_accuracy: 0.7049\n",
            "Epoch 93/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9876 - val_loss: 1.7065 - val_accuracy: 0.7377\n",
            "Epoch 94/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9959 - val_loss: 1.8312 - val_accuracy: 0.7213\n",
            "Epoch 95/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9876 - val_loss: 1.8216 - val_accuracy: 0.7377\n",
            "Epoch 96/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 1.8309 - val_accuracy: 0.7213\n",
            "Epoch 97/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 0.9917 - val_loss: 1.7976 - val_accuracy: 0.7377\n",
            "Epoch 98/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 0.9876 - val_loss: 1.8612 - val_accuracy: 0.7377\n",
            "Epoch 99/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9959 - val_loss: 1.8713 - val_accuracy: 0.7377\n",
            "Epoch 100/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9959 - val_loss: 1.9288 - val_accuracy: 0.6885\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7e2b06f978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1ukw-8AlJJC",
        "outputId": "2e130b2a-0861-4683-f52f-2ade2f811e72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "baseline_scores = baseline.evaluate(X_test, y_test)\n",
        "print(f\"{baseline.metrics_names[1]}: {baseline_scores[1]}\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 3ms/step - loss: 1.9288 - accuracy: 0.6885\n",
            "accuracy: 0.688524603843689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9Mmj6tTfJAa"
      },
      "source": [
        "# hyperparameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNP2Gn4woh_e"
      },
      "source": [
        "Since the baseline model is overfitting, accuracy rate of testing dataset is not good. Next I will do some tuning to reduce overfitting and improve accuracy of validation data.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX7csC8PnUsj"
      },
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIrP-eAonS9g"
      },
      "source": [
        "def create_model2():\n",
        "  opt = Adam(learning_rate=0.01)\n",
        "  wd = 0.001\n",
        "  model = Sequential([\n",
        "                      Dense(32, input_dim=13, activation='relu', kernel_regularizer=regularizers.l2(wd)),\n",
        "                      Dropout(0.3),\n",
        "                      Dense(20, activation='relu',kernel_regularizer=regularizers.l1(wd)),\n",
        "                      Dropout(0.3),\n",
        "                      Dense(1, activation='sigmoid')               \n",
        "  ])\n",
        "  model.compile(optimizer=opt,\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aSfhf7InkbA",
        "outputId": "8ec9e007-d3f2-4e11-b5b8-efcb64eea00d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model2 = create_model2()\n",
        "model2.fit(X_train, y_train, epochs=100, \n",
        "             batch_size=15,\n",
        "             validation_data=(X_test, y_test),\n",
        "             verbose=1)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_73 (Dense)             (None, 32)                448       \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 20)                660       \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 1,129\n",
            "Trainable params: 1,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.7198 - accuracy: 0.6818 - val_loss: 0.6198 - val_accuracy: 0.7541\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.7686 - val_loss: 0.5987 - val_accuracy: 0.7213\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7479 - val_loss: 0.5152 - val_accuracy: 0.8197\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7810 - val_loss: 0.4876 - val_accuracy: 0.8197\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.8099 - val_loss: 0.5122 - val_accuracy: 0.7541\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7851 - val_loss: 0.5342 - val_accuracy: 0.7869\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.8140 - val_loss: 0.4967 - val_accuracy: 0.7869\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.8306 - val_loss: 0.5004 - val_accuracy: 0.7869\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.8347 - val_loss: 0.5162 - val_accuracy: 0.8033\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8182 - val_loss: 0.5004 - val_accuracy: 0.8033\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.8223 - val_loss: 0.4796 - val_accuracy: 0.8033\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.8140 - val_loss: 0.4737 - val_accuracy: 0.8033\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8595 - val_loss: 0.4711 - val_accuracy: 0.8033\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.8388 - val_loss: 0.4681 - val_accuracy: 0.8197\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8017 - val_loss: 0.4808 - val_accuracy: 0.8033\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8347 - val_loss: 0.4802 - val_accuracy: 0.8197\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.8347 - val_loss: 0.4752 - val_accuracy: 0.8033\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8264 - val_loss: 0.4866 - val_accuracy: 0.8361\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8223 - val_loss: 0.4923 - val_accuracy: 0.8033\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8471 - val_loss: 0.4945 - val_accuracy: 0.8033\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.8099 - val_loss: 0.5141 - val_accuracy: 0.8033\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8306 - val_loss: 0.5054 - val_accuracy: 0.8033\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3885 - accuracy: 0.8678 - val_loss: 0.5139 - val_accuracy: 0.8033\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8430 - val_loss: 0.5102 - val_accuracy: 0.8033\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.8347 - val_loss: 0.5216 - val_accuracy: 0.7705\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8347 - val_loss: 0.5540 - val_accuracy: 0.7705\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8636 - val_loss: 0.5476 - val_accuracy: 0.7869\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8719 - val_loss: 0.5492 - val_accuracy: 0.7541\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 0.8678 - val_loss: 0.5566 - val_accuracy: 0.8033\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8512 - val_loss: 0.5640 - val_accuracy: 0.7869\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8595 - val_loss: 0.5305 - val_accuracy: 0.7869\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8719 - val_loss: 0.5640 - val_accuracy: 0.7869\n",
            "Epoch 33/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3399 - accuracy: 0.8760 - val_loss: 0.6065 - val_accuracy: 0.8197\n",
            "Epoch 34/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8636 - val_loss: 0.5772 - val_accuracy: 0.8033\n",
            "Epoch 35/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8595 - val_loss: 0.5812 - val_accuracy: 0.7869\n",
            "Epoch 36/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.8802 - val_loss: 0.5595 - val_accuracy: 0.7705\n",
            "Epoch 37/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3578 - accuracy: 0.9008 - val_loss: 0.5767 - val_accuracy: 0.7705\n",
            "Epoch 38/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8430 - val_loss: 0.5558 - val_accuracy: 0.7541\n",
            "Epoch 39/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8802 - val_loss: 0.5385 - val_accuracy: 0.8197\n",
            "Epoch 40/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3868 - accuracy: 0.8636 - val_loss: 0.5241 - val_accuracy: 0.8033\n",
            "Epoch 41/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8512 - val_loss: 0.5330 - val_accuracy: 0.8197\n",
            "Epoch 42/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3502 - accuracy: 0.8760 - val_loss: 0.5836 - val_accuracy: 0.7541\n",
            "Epoch 43/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3738 - accuracy: 0.8843 - val_loss: 0.5724 - val_accuracy: 0.7705\n",
            "Epoch 44/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8595 - val_loss: 0.5883 - val_accuracy: 0.7541\n",
            "Epoch 45/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8636 - val_loss: 0.6406 - val_accuracy: 0.7377\n",
            "Epoch 46/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8554 - val_loss: 0.6029 - val_accuracy: 0.7377\n",
            "Epoch 47/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8926 - val_loss: 0.5689 - val_accuracy: 0.8033\n",
            "Epoch 48/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8926 - val_loss: 0.5809 - val_accuracy: 0.8033\n",
            "Epoch 49/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.8802 - val_loss: 0.5583 - val_accuracy: 0.8197\n",
            "Epoch 50/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8760 - val_loss: 0.5856 - val_accuracy: 0.8033\n",
            "Epoch 51/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3348 - accuracy: 0.8843 - val_loss: 0.5822 - val_accuracy: 0.8033\n",
            "Epoch 52/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8719 - val_loss: 0.5910 - val_accuracy: 0.7705\n",
            "Epoch 53/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8802 - val_loss: 0.6375 - val_accuracy: 0.7705\n",
            "Epoch 54/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3916 - accuracy: 0.8802 - val_loss: 0.5873 - val_accuracy: 0.8033\n",
            "Epoch 55/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8802 - val_loss: 0.5680 - val_accuracy: 0.7869\n",
            "Epoch 56/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8926 - val_loss: 0.5709 - val_accuracy: 0.8033\n",
            "Epoch 57/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8843 - val_loss: 0.5815 - val_accuracy: 0.7705\n",
            "Epoch 58/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8595 - val_loss: 0.5186 - val_accuracy: 0.8033\n",
            "Epoch 59/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.8140 - val_loss: 0.6991 - val_accuracy: 0.7213\n",
            "Epoch 60/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3624 - accuracy: 0.8512 - val_loss: 0.5483 - val_accuracy: 0.7705\n",
            "Epoch 61/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8554 - val_loss: 0.5577 - val_accuracy: 0.7377\n",
            "Epoch 62/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8306 - val_loss: 0.5532 - val_accuracy: 0.7869\n",
            "Epoch 63/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8471 - val_loss: 0.5432 - val_accuracy: 0.8361\n",
            "Epoch 64/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.8595 - val_loss: 0.5695 - val_accuracy: 0.8033\n",
            "Epoch 65/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8678 - val_loss: 0.5570 - val_accuracy: 0.8033\n",
            "Epoch 66/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8719 - val_loss: 0.5794 - val_accuracy: 0.7705\n",
            "Epoch 67/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8760 - val_loss: 0.5653 - val_accuracy: 0.8033\n",
            "Epoch 68/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8595 - val_loss: 0.5340 - val_accuracy: 0.8197\n",
            "Epoch 69/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.8843 - val_loss: 0.5821 - val_accuracy: 0.8033\n",
            "Epoch 70/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8802 - val_loss: 0.5716 - val_accuracy: 0.8197\n",
            "Epoch 71/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8595 - val_loss: 0.5887 - val_accuracy: 0.8033\n",
            "Epoch 72/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3439 - accuracy: 0.8926 - val_loss: 0.6160 - val_accuracy: 0.7869\n",
            "Epoch 73/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.8843 - val_loss: 0.6108 - val_accuracy: 0.7869\n",
            "Epoch 74/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8636 - val_loss: 0.5917 - val_accuracy: 0.7705\n",
            "Epoch 75/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3323 - accuracy: 0.9050 - val_loss: 0.6333 - val_accuracy: 0.8033\n",
            "Epoch 76/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3660 - accuracy: 0.8678 - val_loss: 0.6407 - val_accuracy: 0.8033\n",
            "Epoch 77/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3465 - accuracy: 0.8760 - val_loss: 0.6028 - val_accuracy: 0.8197\n",
            "Epoch 78/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.8554 - val_loss: 0.6192 - val_accuracy: 0.8033\n",
            "Epoch 79/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8802 - val_loss: 0.5914 - val_accuracy: 0.7869\n",
            "Epoch 80/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8926 - val_loss: 0.5706 - val_accuracy: 0.8033\n",
            "Epoch 81/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8719 - val_loss: 0.6017 - val_accuracy: 0.8033\n",
            "Epoch 82/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8678 - val_loss: 0.6351 - val_accuracy: 0.7705\n",
            "Epoch 83/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8760 - val_loss: 0.5835 - val_accuracy: 0.7869\n",
            "Epoch 84/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8843 - val_loss: 0.6149 - val_accuracy: 0.7869\n",
            "Epoch 85/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8802 - val_loss: 0.5926 - val_accuracy: 0.7869\n",
            "Epoch 86/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8843 - val_loss: 0.6019 - val_accuracy: 0.7705\n",
            "Epoch 87/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3852 - accuracy: 0.8636 - val_loss: 0.6061 - val_accuracy: 0.8033\n",
            "Epoch 88/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8636 - val_loss: 0.6413 - val_accuracy: 0.7705\n",
            "Epoch 89/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3402 - accuracy: 0.8802 - val_loss: 0.6532 - val_accuracy: 0.8197\n",
            "Epoch 90/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8843 - val_loss: 0.6471 - val_accuracy: 0.7869\n",
            "Epoch 91/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8471 - val_loss: 0.6641 - val_accuracy: 0.7541\n",
            "Epoch 92/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3547 - accuracy: 0.8802 - val_loss: 0.6499 - val_accuracy: 0.7869\n",
            "Epoch 93/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8760 - val_loss: 0.6644 - val_accuracy: 0.7541\n",
            "Epoch 94/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8595 - val_loss: 0.6783 - val_accuracy: 0.7869\n",
            "Epoch 95/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8678 - val_loss: 0.6359 - val_accuracy: 0.8033\n",
            "Epoch 96/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.9008 - val_loss: 0.6729 - val_accuracy: 0.8033\n",
            "Epoch 97/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.8802 - val_loss: 0.6510 - val_accuracy: 0.7705\n",
            "Epoch 98/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.9091 - val_loss: 0.6391 - val_accuracy: 0.7869\n",
            "Epoch 99/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8554 - val_loss: 0.7071 - val_accuracy: 0.7705\n",
            "Epoch 100/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8802 - val_loss: 0.6788 - val_accuracy: 0.7705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7e203ef630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rvEnXvvn4vE",
        "outputId": "694e16fa-15ef-4679-ff71-d9fefc321482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model2_scores = model2.evaluate(X_test, y_test)\n",
        "print(f\"{model2.metrics_names[1]}: {model2_scores[1]}\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.7705\n",
            "accuracy: 0.7704917788505554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSCflyDhpCcP"
      },
      "source": [
        "Build another model for grid search parameter tuning purpose. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpD7xyYqpsOF"
      },
      "source": [
        "def gridsearch_create_model(lr=0.01):\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(10, input_dim=13, activation='relu'))\n",
        "  model.add(Dense(5, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # compile model\n",
        "  sgd = SGD(learning_rate=lr)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "  "
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCEhYjSyqr9n",
        "outputId": "7caa4a36-bac3-4ddd-99cf-ec45a67df0d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "baseline_grid_model = gridsearch_create_model()\n",
        "baseline_grid_model.fit(X_train, y_train, epochs=100, \n",
        "             batch_size=15,\n",
        "             validation_data=(X_test, y_test),\n",
        "             verbose=1)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.7508 - accuracy: 0.5372 - val_loss: 0.7232 - val_accuracy: 0.5738\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.7357 - accuracy: 0.5372 - val_loss: 0.7142 - val_accuracy: 0.5738\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.7241 - accuracy: 0.5372 - val_loss: 0.7094 - val_accuracy: 0.5738\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.7177 - accuracy: 0.5372 - val_loss: 0.7061 - val_accuracy: 0.5738\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.7135 - accuracy: 0.5372 - val_loss: 0.7026 - val_accuracy: 0.5738\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.7084 - accuracy: 0.5372 - val_loss: 0.7002 - val_accuracy: 0.5902\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.7046 - accuracy: 0.5372 - val_loss: 0.6986 - val_accuracy: 0.5902\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.7026 - accuracy: 0.5372 - val_loss: 0.6972 - val_accuracy: 0.5902\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.7006 - accuracy: 0.5413 - val_loss: 0.6958 - val_accuracy: 0.5902\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6987 - accuracy: 0.5413 - val_loss: 0.6948 - val_accuracy: 0.5902\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.5413 - val_loss: 0.6938 - val_accuracy: 0.5902\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.5413 - val_loss: 0.6927 - val_accuracy: 0.5902\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.5455 - val_loss: 0.6918 - val_accuracy: 0.5902\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5455 - val_loss: 0.6908 - val_accuracy: 0.5902\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5455 - val_loss: 0.6897 - val_accuracy: 0.5902\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5455 - val_loss: 0.6889 - val_accuracy: 0.5902\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.5496 - val_loss: 0.6880 - val_accuracy: 0.5902\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5537 - val_loss: 0.6870 - val_accuracy: 0.5902\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.5537 - val_loss: 0.6861 - val_accuracy: 0.5902\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5537 - val_loss: 0.6851 - val_accuracy: 0.6230\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.5537 - val_loss: 0.6842 - val_accuracy: 0.6230\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5537 - val_loss: 0.6828 - val_accuracy: 0.6230\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5537 - val_loss: 0.6822 - val_accuracy: 0.6230\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5579 - val_loss: 0.6811 - val_accuracy: 0.6230\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.5579 - val_loss: 0.6796 - val_accuracy: 0.6230\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.5579 - val_loss: 0.6788 - val_accuracy: 0.6393\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.5702 - val_loss: 0.6774 - val_accuracy: 0.6393\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6772 - accuracy: 0.5702 - val_loss: 0.6763 - val_accuracy: 0.6393\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6758 - accuracy: 0.5702 - val_loss: 0.6748 - val_accuracy: 0.6393\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6744 - accuracy: 0.5785 - val_loss: 0.6730 - val_accuracy: 0.6393\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6726 - accuracy: 0.5826 - val_loss: 0.6714 - val_accuracy: 0.6393\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6708 - accuracy: 0.5909 - val_loss: 0.6696 - val_accuracy: 0.6393\n",
            "Epoch 33/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6688 - accuracy: 0.5909 - val_loss: 0.6675 - val_accuracy: 0.6393\n",
            "Epoch 34/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6668 - accuracy: 0.5950 - val_loss: 0.6662 - val_accuracy: 0.6557\n",
            "Epoch 35/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6648 - accuracy: 0.5950 - val_loss: 0.6641 - val_accuracy: 0.6557\n",
            "Epoch 36/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6624 - accuracy: 0.6033 - val_loss: 0.6619 - val_accuracy: 0.6557\n",
            "Epoch 37/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.6074 - val_loss: 0.6599 - val_accuracy: 0.6557\n",
            "Epoch 38/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.6074 - val_loss: 0.6579 - val_accuracy: 0.6721\n",
            "Epoch 39/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.6281 - val_loss: 0.6553 - val_accuracy: 0.6721\n",
            "Epoch 40/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6364 - val_loss: 0.6520 - val_accuracy: 0.6885\n",
            "Epoch 41/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6529 - val_loss: 0.6479 - val_accuracy: 0.7049\n",
            "Epoch 42/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6409 - accuracy: 0.6777 - val_loss: 0.6428 - val_accuracy: 0.7049\n",
            "Epoch 43/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.6983 - val_loss: 0.6376 - val_accuracy: 0.7213\n",
            "Epoch 44/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.7190 - val_loss: 0.6314 - val_accuracy: 0.7213\n",
            "Epoch 45/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.7273 - val_loss: 0.6252 - val_accuracy: 0.7377\n",
            "Epoch 46/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.7231 - val_loss: 0.6192 - val_accuracy: 0.7377\n",
            "Epoch 47/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.7438 - val_loss: 0.6125 - val_accuracy: 0.7377\n",
            "Epoch 48/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.7562 - val_loss: 0.6072 - val_accuracy: 0.7705\n",
            "Epoch 49/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.7727 - val_loss: 0.6018 - val_accuracy: 0.7869\n",
            "Epoch 50/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.7727 - val_loss: 0.5955 - val_accuracy: 0.7705\n",
            "Epoch 51/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.7810 - val_loss: 0.5891 - val_accuracy: 0.7705\n",
            "Epoch 52/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7810 - val_loss: 0.5832 - val_accuracy: 0.7705\n",
            "Epoch 53/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7769 - val_loss: 0.5777 - val_accuracy: 0.7869\n",
            "Epoch 54/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7893 - val_loss: 0.5716 - val_accuracy: 0.7705\n",
            "Epoch 55/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7934 - val_loss: 0.5658 - val_accuracy: 0.7705\n",
            "Epoch 56/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7934 - val_loss: 0.5602 - val_accuracy: 0.7869\n",
            "Epoch 57/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.8017 - val_loss: 0.5556 - val_accuracy: 0.7869\n",
            "Epoch 58/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.8017 - val_loss: 0.5503 - val_accuracy: 0.7869\n",
            "Epoch 59/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.8017 - val_loss: 0.5447 - val_accuracy: 0.7869\n",
            "Epoch 60/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7975 - val_loss: 0.5385 - val_accuracy: 0.7869\n",
            "Epoch 61/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.8058 - val_loss: 0.5333 - val_accuracy: 0.8033\n",
            "Epoch 62/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.8140 - val_loss: 0.5285 - val_accuracy: 0.8033\n",
            "Epoch 63/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.8140 - val_loss: 0.5250 - val_accuracy: 0.8033\n",
            "Epoch 64/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8058 - val_loss: 0.5209 - val_accuracy: 0.8033\n",
            "Epoch 65/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8182 - val_loss: 0.5179 - val_accuracy: 0.8033\n",
            "Epoch 66/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.8058 - val_loss: 0.5132 - val_accuracy: 0.8033\n",
            "Epoch 67/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8182 - val_loss: 0.5106 - val_accuracy: 0.8033\n",
            "Epoch 68/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8058 - val_loss: 0.5078 - val_accuracy: 0.8033\n",
            "Epoch 69/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.8140 - val_loss: 0.5039 - val_accuracy: 0.8033\n",
            "Epoch 70/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8182 - val_loss: 0.4999 - val_accuracy: 0.8033\n",
            "Epoch 71/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.8182 - val_loss: 0.4973 - val_accuracy: 0.8033\n",
            "Epoch 72/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.8140 - val_loss: 0.4961 - val_accuracy: 0.8033\n",
            "Epoch 73/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8182 - val_loss: 0.4944 - val_accuracy: 0.8033\n",
            "Epoch 74/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8140 - val_loss: 0.4934 - val_accuracy: 0.8033\n",
            "Epoch 75/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8182 - val_loss: 0.4902 - val_accuracy: 0.8033\n",
            "Epoch 76/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8182 - val_loss: 0.4884 - val_accuracy: 0.8033\n",
            "Epoch 77/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8182 - val_loss: 0.4873 - val_accuracy: 0.8033\n",
            "Epoch 78/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8182 - val_loss: 0.4898 - val_accuracy: 0.8033\n",
            "Epoch 79/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8182 - val_loss: 0.4867 - val_accuracy: 0.7869\n",
            "Epoch 80/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8182 - val_loss: 0.4832 - val_accuracy: 0.8033\n",
            "Epoch 81/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8182 - val_loss: 0.4822 - val_accuracy: 0.8033\n",
            "Epoch 82/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8182 - val_loss: 0.4822 - val_accuracy: 0.8033\n",
            "Epoch 83/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8223 - val_loss: 0.4811 - val_accuracy: 0.8197\n",
            "Epoch 84/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8140 - val_loss: 0.4806 - val_accuracy: 0.8033\n",
            "Epoch 85/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8264 - val_loss: 0.4789 - val_accuracy: 0.7869\n",
            "Epoch 86/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8223 - val_loss: 0.4792 - val_accuracy: 0.7869\n",
            "Epoch 87/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8223 - val_loss: 0.4783 - val_accuracy: 0.7869\n",
            "Epoch 88/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8223 - val_loss: 0.4789 - val_accuracy: 0.7869\n",
            "Epoch 89/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8264 - val_loss: 0.4780 - val_accuracy: 0.7705\n",
            "Epoch 90/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8223 - val_loss: 0.4774 - val_accuracy: 0.7705\n",
            "Epoch 91/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8182 - val_loss: 0.4781 - val_accuracy: 0.7705\n",
            "Epoch 92/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8264 - val_loss: 0.4787 - val_accuracy: 0.7705\n",
            "Epoch 93/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8182 - val_loss: 0.4788 - val_accuracy: 0.7705\n",
            "Epoch 94/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8306 - val_loss: 0.4786 - val_accuracy: 0.7541\n",
            "Epoch 95/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8306 - val_loss: 0.4797 - val_accuracy: 0.7705\n",
            "Epoch 96/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8388 - val_loss: 0.4780 - val_accuracy: 0.7541\n",
            "Epoch 97/100\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8264 - val_loss: 0.4783 - val_accuracy: 0.7705\n",
            "Epoch 98/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7541\n",
            "Epoch 99/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8306 - val_loss: 0.4816 - val_accuracy: 0.7869\n",
            "Epoch 100/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8347 - val_loss: 0.4827 - val_accuracy: 0.7869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7e14c36da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "steoPUl8tm1I",
        "outputId": "a38b17e3-e642-4bad-e1d5-39c000e4210b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "baselinegrid_scores = baseline_grid_model.evaluate(X_test, y_test)\n",
        "print(f\"{baseline_grid_model.metrics_names[1]}: {baselinegrid_scores[1]}\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7869\n",
            "accuracy: 0.7868852615356445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJX9PB2liESk",
        "outputId": "c6e03503-b4d0-4af3-ead4-be7d486f7510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# create model\n",
        "gridsearch_model = KerasClassifier(build_fn=gridsearch_create_model, verbose=1)\n",
        "\n",
        "# define the grid search parameters\n",
        "param_grid = {\n",
        "    'epochs': [50,100],\n",
        "    'batch_size': [32, 64, 128],\n",
        "    'lr': [0.001, 0.01, 0.1]\n",
        "}\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=gridsearch_model, param_grid=param_grid, cv=3, n_jobs=-1)\n",
        "grid_result = grid.fit(X_train, y_train)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7033 - accuracy: 0.5372\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5455\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6752 - accuracy: 0.5620\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.6691 - accuracy: 0.5785\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.6622 - accuracy: 0.6653\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.7025\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.7107\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.7231\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.7438\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.6221 - accuracy: 0.7355\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.6134 - accuracy: 0.7438\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.6043 - accuracy: 0.7521\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.7603\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.7645\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7686\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.5444 - accuracy: 0.7769\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.7769\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7934\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7810\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8017\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8017\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.8140\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8058\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8388\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8140\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8264\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3857 - accuracy: 0.8347\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3803 - accuracy: 0.8223\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8388\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8595\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8388\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8554\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8512\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8595\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8512\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8595\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8430\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8388\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8388\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8678\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8554\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8388\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8471\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8430\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8471\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8347\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8595\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8430\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8636\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8636\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8554\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8430\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8678\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8636\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8430\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8554\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8512\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8678\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8678\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3208 - accuracy: 0.8719\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8430\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8554\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8595\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8595\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3091 - accuracy: 0.8636\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8636\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8636\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8843\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3183 - accuracy: 0.8719\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3119 - accuracy: 0.8678\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3165 - accuracy: 0.8802\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.8843\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8471\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8678\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8884\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8760\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8926\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8843\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3148 - accuracy: 0.8843\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8843\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8719\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8802\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8802\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8719\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8843\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8471\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8678\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8554\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8512\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.2981 - accuracy: 0.8802\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8884\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8471\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8678\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8719\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8636\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8595\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8471\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8760\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.8884\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28NEl6LgiwHM",
        "outputId": "52169786-a2b7-4a7a-aa87-c9e8d4186b6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "print(\"\\n\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(f\"Means: {mean}, Stdev: {stdev} with: {params}\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.8511316776275635 using {'batch_size': 32, 'epochs': 100, 'lr': 0.1}\n",
            "\n",
            "\n",
            "Means: 0.632253090540568, Stdev: 0.04049115237585761 with: [{'batch_size': 32, 'epochs': 50, 'lr': 0.001}, {'batch_size': 32, 'epochs': 50, 'lr': 0.01}, {'batch_size': 32, 'epochs': 50, 'lr': 0.1}, {'batch_size': 32, 'epochs': 100, 'lr': 0.001}, {'batch_size': 32, 'epochs': 100, 'lr': 0.01}, {'batch_size': 32, 'epochs': 100, 'lr': 0.1}, {'batch_size': 64, 'epochs': 50, 'lr': 0.001}, {'batch_size': 64, 'epochs': 50, 'lr': 0.01}, {'batch_size': 64, 'epochs': 50, 'lr': 0.1}, {'batch_size': 64, 'epochs': 100, 'lr': 0.001}, {'batch_size': 64, 'epochs': 100, 'lr': 0.01}, {'batch_size': 64, 'epochs': 100, 'lr': 0.1}, {'batch_size': 128, 'epochs': 50, 'lr': 0.001}, {'batch_size': 128, 'epochs': 50, 'lr': 0.01}, {'batch_size': 128, 'epochs': 50, 'lr': 0.1}, {'batch_size': 128, 'epochs': 100, 'lr': 0.001}, {'batch_size': 128, 'epochs': 100, 'lr': 0.01}, {'batch_size': 128, 'epochs': 100, 'lr': 0.1}]\n",
            "Means: 0.7190329233805338, Stdev: 0.020597202888826667 with: [{'batch_size': 32, 'epochs': 50, 'lr': 0.001}, {'batch_size': 32, 'epochs': 50, 'lr': 0.01}, {'batch_size': 32, 'epochs': 50, 'lr': 0.1}, {'batch_size': 32, 'epochs': 100, 'lr': 0.001}, {'batch_size': 32, 'epochs': 100, 'lr': 0.01}, {'batch_size': 32, 'epochs': 100, 'lr': 0.1}, {'batch_size': 64, 'epochs': 50, 'lr': 0.001}, {'batch_size': 64, 'epochs': 50, 'lr': 0.01}, {'batch_size': 64, 'epochs': 50, 'lr': 0.1}, {'batch_size': 64, 'epochs': 100, 'lr': 0.001}, {'batch_size': 64, 'epochs': 100, 'lr': 0.01}, {'batch_size': 64, 'epochs': 100, 'lr': 0.1}, {'batch_size': 128, 'epochs': 50, 'lr': 0.001}, {'batch_size': 128, 'epochs': 50, 'lr': 0.01}, {'batch_size': 128, 'epochs': 50, 'lr': 0.1}, {'batch_size': 128, 'epochs': 100, 'lr': 0.001}, {'batch_size': 128, 'epochs': 100, 'lr': 0.01}, {'batch_size': 128, 'epochs': 100, 'lr': 0.1}]\n",
            "Means: 0.8428498109181722, Stdev: 0.022044457643924015 with: [{'batch_size': 32, 'epochs': 50, 'lr': 0.001}, {'batch_size': 32, 'epochs': 50, 'lr': 0.01}, {'batch_size': 32, 'epochs': 50, 'lr': 0.1}, {'batch_size': 32, 'epochs': 100, 'lr': 0.001}, {'batch_size': 32, 'epochs': 100, 'lr': 0.01}, {'batch_size': 32, 'epochs': 100, 'lr': 0.1}, {'batch_size': 64, 'epochs': 50, 'lr': 0.001}, {'batch_size': 64, 'epochs': 50, 'lr': 0.01}, {'batch_size': 64, 'epochs': 50, 'lr': 0.1}, {'batch_size': 64, 'epochs': 100, 'lr': 0.001}, {'batch_size': 64, 'epochs': 100, 'lr': 0.01}, {'batch_size': 64, 'epochs': 100, 'lr': 0.1}, {'batch_size': 128, 'epochs': 50, 'lr': 0.001}, {'batch_size': 128, 'epochs': 50, 'lr': 0.01}, {'batch_size': 128, 'epochs': 50, 'lr': 0.1}, {'batch_size': 128, 'epochs': 100, 'lr': 0.001}, {'batch_size': 128, 'epochs': 100, 'lr': 0.01}, {'batch_size': 128, 'epochs': 100, 'lr': 0.1}]\n",
            "Means: 0.5905864238739014, Stdev: 0.06295427587370292 with: [{'batch_size': 32, 'epochs': 50, 'lr': 0.001}, {'batch_size': 32, 'epochs': 50, 'lr': 0.01}, {'batch_size': 32, 'epochs': 50, 'lr': 0.1}, {'batch_size': 32, 'epochs': 100, 'lr': 0.001}, {'batch_size': 32, 'epochs': 100, 'lr': 0.01}, {'batch_size': 32, 'epochs': 100, 'lr': 0.1}, {'batch_size': 64, 'epochs': 50, 'lr': 0.001}, {'batch_size': 64, 'epochs': 50, 'lr': 0.01}, {'batch_size': 64, 'epochs': 50, 'lr': 0.1}, {'batch_size': 64, 'epochs': 100, 'lr': 0.001}, {'batch_size': 64, 'epochs': 100, 'lr': 0.01}, {'batch_size': 64, 'epochs': 100, 'lr': 0.1}, {'batch_size': 128, 'epochs': 50, 'lr': 0.001}, {'batch_size': 128, 'epochs': 50, 'lr': 0.01}, {'batch_size': 128, 'epochs': 50, 'lr': 0.1}, {'batch_size': 128, 'epochs': 100, 'lr': 0.001}, {'batch_size': 128, 'epochs': 100, 'lr': 0.01}, {'batch_size': 128, 'epochs': 100, 'lr': 0.1}]\n",
            "Means: 0.7435699502627054, Stdev: 0.0530721098913964 with: [{'batch_size': 32, 'epochs': 50, 'lr': 0.001}, {'batch_size': 32, 'epochs': 50, 'lr': 0.01}, {'batch_size': 32, 'epochs': 50, 'lr': 0.1}, {'batch_size': 32, 'epochs': 100, 'lr': 0.001}, {'batch_size': 32, 'epochs': 100, 'lr': 0.01}, {'batch_size': 32, 'epochs': 100, 'lr': 0.1}, {'batch_size': 64, 'epochs': 50, 'lr': 0.001}, {'batch_size': 64, 'epochs': 50, 'lr': 0.01}, {'batch_size': 64, 'epochs': 50, 'lr': 0.1}, {'batch_size': 64, 'epochs': 100, 'lr': 0.001}, {'batch_size': 64, 'epochs': 100, 'lr': 0.01}, {'batch_size': 64, 'epochs': 100, 'lr': 0.1}, {'batch_size': 128, 'epochs': 50, 'lr': 0.001}, {'batch_size': 128, 'epochs': 50, 'lr': 0.01}, {'batch_size': 128, 'epochs': 50, 'lr': 0.1}, {'batch_size': 128, 'epochs': 100, 'lr': 0.001}, {'batch_size': 128, 'epochs': 100, 'lr': 0.01}, {'batch_size': 128, 'epochs': 100, 'lr': 0.1}]\n",
            "Means: 0.8511316776275635, Stdev: 0.02734730705867655 with: [{'batch_size': 32, 'epochs': 50, 'lr': 0.001}, {'batch_size': 32, 'epochs': 50, 'lr': 0.01}, {'batch_size': 32, 'epochs': 50, 'lr': 0.1}, {'batch_size': 32, 'epochs': 100, 'lr': 0.001}, {'batch_size': 32, 'epochs': 100, 'lr': 0.01}, {'batch_size': 32, 'epochs': 100, 'lr': 0.1}, {'batch_size': 64, 'epochs': 50, 'lr': 0.001}, {'batch_size': 64, 'epochs': 50, 'lr': 0.01}, {'batch_size': 64, 'epochs': 50, 'lr': 0.1}, {'batch_size': 64, 'epochs': 100, 'lr': 0.001}, {'batch_size': 64, 'epochs': 100, 'lr': 0.01}, {'batch_size': 64, 'epochs': 100, 'lr': 0.1}, {'batch_size': 128, 'epochs': 50, 'lr': 0.001}, {'batch_size': 128, 'epochs': 50, 'lr': 0.01}, {'batch_size': 128, 'epochs': 50, 'lr': 0.1}, {'batch_size': 128, 'epochs': 100, 'lr': 0.001}, {'batch_size': 128, 'epochs': 100, 'lr': 0.01}, {'batch_size': 128, 'epochs': 100, 'lr': 0.1}]\n",
            "Means: 0.467283954222997, Stdev: 0.08782947981948605 with: [{'batch_size': 32, 'epochs': 50, 'lr': 0.001}, {'batch_size': 32, 'epochs': 50, 'lr': 0.01}, {'batch_size': 32, 'epochs': 50, 'lr': 0.1}, {'batch_size': 32, 'epochs': 100, 'lr': 0.001}, {'batch_size': 32, 'epochs': 100, 'lr': 0.01}, {'batch_size': 32, 'epochs': 100, 'lr': 0.1}, {'batch_size': 64, 'epochs': 50, 'lr': 0.001}, {'batch_size': 64, 'epochs': 50, 'lr': 0.01}, {'batch_size': 64, 'epochs': 50, 'lr': 0.1}, {'batch_size': 64, 'epochs': 100, 'lr': 0.001}, {'batch_size': 64, 'epochs': 100, 'lr': 0.01}, {'batch_size': 64, 'epochs': 100, 'lr': 0.1}, {'batch_size': 128, 'epochs': 50, 'lr': 0.001}, {'batch_size': 128, 'epochs': 50, 'lr': 0.01}, {'batch_size': 128, 'epochs': 50, 'lr': 0.1}, {'batch_size': 128, 'epochs': 100, 'lr': 0.001}, {'batch_size': 128, 'epochs': 100, 'lr': 0.01}, {'batch_size': 128, 'epochs': 100, 'lr': 0.1}]\n",
            "Means: 0.586831271648407, Stdev: 0.04138207910438291 with: [{'batch_size': 32, 'epochs': 50, 'lr': 0.001}, {'batch_size': 32, 'epochs': 50, 'lr': 0.01}, {'batch_size': 32, 'epochs': 50, 'lr': 0.1}, {'batch_size': 32, 'epochs': 100, 'lr': 0.001}, {'batch_size': 32, 'epochs': 100, 'lr': 0.01}, {'batch_size': 32, 'epochs': 100, 'lr': 0.1}, {'batch_size': 64, 'epochs': 50, 'lr': 0.001}, {'batch_size': 64, 'epochs': 50, 'lr': 0.01}, {'batch_size': 64, 'epochs': 50, 'lr': 0.1}, {'batch_size': 64, 'epochs': 100, 'lr': 0.001}, {'batch_size': 64, 'epochs': 100, 'lr': 0.01}, {'batch_size': 64, 'epochs': 100, 'lr': 0.1}, {'batch_size': 128, 'epochs': 50, 'lr': 0.001}, {'batch_size': 128, 'epochs': 50, 'lr': 0.01}, {'batch_size': 128, 'epochs': 50, 'lr': 0.1}, {'batch_size': 128, 'epochs': 100, 'lr': 0.001}, {'batch_size': 128, 'epochs': 100, 'lr': 0.01}, {'batch_size': 128, 'epochs': 100, 'lr': 0.1}]\n",
            "Means: 0.834567924340566, Stdev: 0.02444320528338803 with: [{'batch_size': 32, 'epochs': 50, 'lr': 0.001}, {'batch_size': 32, 'epochs': 50, 'lr': 0.01}, {'batch_size': 32, 'epochs': 50, 'lr': 0.1}, {'batch_size': 32, 'epochs': 100, 'lr': 0.001}, {'batch_size': 32, 'epochs': 100, 'lr': 0.01}, {'batch_size': 32, 'epochs': 100, 'lr': 0.1}, {'batch_size': 64, 'epochs': 50, 'lr': 0.001}, {'batch_size': 64, 'epochs': 50, 'lr': 0.01}, {'batch_size': 64, 'epochs': 50, 'lr': 0.1}, {'batch_size': 64, 'epochs': 100, 'lr': 0.001}, {'batch_size': 64, 'epochs': 100, 'lr': 0.01}, {'batch_size': 64, 'epochs': 100, 'lr': 0.1}, {'batch_size': 128, 'epochs': 50, 'lr': 0.001}, {'batch_size': 128, 'epochs': 50, 'lr': 0.01}, {'batch_size': 128, 'epochs': 50, 'lr': 0.1}, {'batch_size': 128, 'epochs': 100, 'lr': 0.001}, {'batch_size': 128, 'epochs': 100, 'lr': 0.01}, {'batch_size': 128, 'epochs': 100, 'lr': 0.1}]\n",
            "Means: 0.5668209890524546, Stdev: 0.17087298664430775 with: [{'batch_size': 32, 'epochs': 50, 'lr': 0.001}, {'batch_size': 32, 'epochs': 50, 'lr': 0.01}, {'batch_size': 32, 'epochs': 50, 'lr': 0.1}, {'batch_size': 32, 'epochs': 100, 'lr': 0.001}, {'batch_size': 32, 'epochs': 100, 'lr': 0.01}, {'batch_size': 32, 'epochs': 100, 'lr': 0.1}, {'batch_size': 64, 'epochs': 50, 'lr': 0.001}, {'batch_size': 64, 'epochs': 50, 'lr': 0.01}, {'batch_size': 64, 'epochs': 50, 'lr': 0.1}, {'batch_size': 64, 'epochs': 100, 'lr': 0.001}, {'batch_size': 64, 'epochs': 100, 'lr': 0.01}, {'batch_size': 64, 'epochs': 100, 'lr': 0.1}, {'batch_size': 128, 'epochs': 50, 'lr': 0.001}, {'batch_size': 128, 'epochs': 50, 'lr': 0.01}, {'batch_size': 128, 'epochs': 50, 'lr': 0.1}, {'batch_size': 128, 'epochs': 100, 'lr': 0.001}, {'batch_size': 128, 'epochs': 100, 'lr': 0.01}, {'batch_size': 128, 'epochs': 100, 'lr': 0.1}]\n",
            "Means: 0.6652777791023254, Stdev: 0.06051310198257165 with: [{'batch_size': 32, 'epochs': 50, 'lr': 0.001}, {'batch_size': 32, 'epochs': 50, 'lr': 0.01}, {'batch_size': 32, 'epochs': 50, 'lr': 0.1}, {'batch_size': 32, 'epochs': 100, 'lr': 0.001}, {'batch_size': 32, 'epochs': 100, 'lr': 0.01}, {'batch_size': 32, 'epochs': 100, 'lr': 0.1}, {'batch_size': 64, 'epochs': 50, 'lr': 0.001}, {'batch_size': 64, 'epochs': 50, 'lr': 0.01}, {'batch_size': 64, 'epochs': 50, 'lr': 0.1}, {'batch_size': 64, 'epochs': 100, 'lr': 0.001}, {'batch_size': 64, 'epochs': 100, 'lr': 0.01}, {'batch_size': 64, 'epochs': 100, 'lr': 0.1}, {'batch_size': 128, 'epochs': 50, 'lr': 0.001}, {'batch_size': 128, 'epochs': 50, 'lr': 0.01}, {'batch_size': 128, 'epochs': 50, 'lr': 0.1}, {'batch_size': 128, 'epochs': 100, 'lr': 0.001}, {'batch_size': 128, 'epochs': 100, 'lr': 0.01}, {'batch_size': 128, 'epochs': 100, 'lr': 0.1}]\n",
            "Means: 0.8388374447822571, Stdev: 0.020182591884899025 with: [{'batch_size': 32, 'epochs': 50, 'lr': 0.001}, {'batch_size': 32, 'epochs': 50, 'lr': 0.01}, {'batch_size': 32, 'epochs': 50, 'lr': 0.1}, {'batch_size': 32, 'epochs': 100, 'lr': 0.001}, {'batch_size': 32, 'epochs': 100, 'lr': 0.01}, {'batch_size': 32, 'epochs': 100, 'lr': 0.1}, {'batch_size': 64, 'epochs': 50, 'lr': 0.001}, {'batch_size': 64, 'epochs': 50, 'lr': 0.01}, {'batch_size': 64, 'epochs': 50, 'lr': 0.1}, {'batch_size': 64, 'epochs': 100, 'lr': 0.001}, {'batch_size': 64, 'epochs': 100, 'lr': 0.01}, {'batch_size': 64, 'epochs': 100, 'lr': 0.1}, {'batch_size': 128, 'epochs': 50, 'lr': 0.001}, {'batch_size': 128, 'epochs': 50, 'lr': 0.01}, {'batch_size': 128, 'epochs': 50, 'lr': 0.1}, {'batch_size': 128, 'epochs': 100, 'lr': 0.001}, {'batch_size': 128, 'epochs': 100, 'lr': 0.01}, {'batch_size': 128, 'epochs': 100, 'lr': 0.1}]\n",
            "Means: 0.4917181134223938, Stdev: 0.002982648175418949 with: [{'batch_size': 32, 'epochs': 50, 'lr': 0.001}, {'batch_size': 32, 'epochs': 50, 'lr': 0.01}, {'batch_size': 32, 'epochs': 50, 'lr': 0.1}, {'batch_size': 32, 'epochs': 100, 'lr': 0.001}, {'batch_size': 32, 'epochs': 100, 'lr': 0.01}, {'batch_size': 32, 'epochs': 100, 'lr': 0.1}, {'batch_size': 64, 'epochs': 50, 'lr': 0.001}, {'batch_size': 64, 'epochs': 50, 'lr': 0.01}, {'batch_size': 64, 'epochs': 50, 'lr': 0.1}, {'batch_size': 64, 'epochs': 100, 'lr': 0.001}, {'batch_size': 64, 'epochs': 100, 'lr': 0.01}, {'batch_size': 64, 'epochs': 100, 'lr': 0.1}, {'batch_size': 128, 'epochs': 50, 'lr': 0.001}, {'batch_size': 128, 'epochs': 50, 'lr': 0.01}, {'batch_size': 128, 'epochs': 50, 'lr': 0.1}, {'batch_size': 128, 'epochs': 100, 'lr': 0.001}, {'batch_size': 128, 'epochs': 100, 'lr': 0.01}, {'batch_size': 128, 'epochs': 100, 'lr': 0.1}]\n",
            "Means: 0.6446502010027567, Stdev: 0.010766658878293093 with: [{'batch_size': 32, 'epochs': 50, 'lr': 0.001}, {'batch_size': 32, 'epochs': 50, 'lr': 0.01}, {'batch_size': 32, 'epochs': 50, 'lr': 0.1}, {'batch_size': 32, 'epochs': 100, 'lr': 0.001}, {'batch_size': 32, 'epochs': 100, 'lr': 0.01}, {'batch_size': 32, 'epochs': 100, 'lr': 0.1}, {'batch_size': 64, 'epochs': 50, 'lr': 0.001}, {'batch_size': 64, 'epochs': 50, 'lr': 0.01}, {'batch_size': 64, 'epochs': 50, 'lr': 0.1}, {'batch_size': 64, 'epochs': 100, 'lr': 0.001}, {'batch_size': 64, 'epochs': 100, 'lr': 0.01}, {'batch_size': 64, 'epochs': 100, 'lr': 0.1}, {'batch_size': 128, 'epochs': 50, 'lr': 0.001}, {'batch_size': 128, 'epochs': 50, 'lr': 0.01}, {'batch_size': 128, 'epochs': 50, 'lr': 0.1}, {'batch_size': 128, 'epochs': 100, 'lr': 0.001}, {'batch_size': 128, 'epochs': 100, 'lr': 0.01}, {'batch_size': 128, 'epochs': 100, 'lr': 0.1}]\n",
            "Means: 0.7727880676587423, Stdev: 0.02268619473157857 with: [{'batch_size': 32, 'epochs': 50, 'lr': 0.001}, {'batch_size': 32, 'epochs': 50, 'lr': 0.01}, {'batch_size': 32, 'epochs': 50, 'lr': 0.1}, {'batch_size': 32, 'epochs': 100, 'lr': 0.001}, {'batch_size': 32, 'epochs': 100, 'lr': 0.01}, {'batch_size': 32, 'epochs': 100, 'lr': 0.1}, {'batch_size': 64, 'epochs': 50, 'lr': 0.001}, {'batch_size': 64, 'epochs': 50, 'lr': 0.01}, {'batch_size': 64, 'epochs': 50, 'lr': 0.1}, {'batch_size': 64, 'epochs': 100, 'lr': 0.001}, {'batch_size': 64, 'epochs': 100, 'lr': 0.01}, {'batch_size': 64, 'epochs': 100, 'lr': 0.1}, {'batch_size': 128, 'epochs': 50, 'lr': 0.001}, {'batch_size': 128, 'epochs': 50, 'lr': 0.01}, {'batch_size': 128, 'epochs': 50, 'lr': 0.1}, {'batch_size': 128, 'epochs': 100, 'lr': 0.001}, {'batch_size': 128, 'epochs': 100, 'lr': 0.01}, {'batch_size': 128, 'epochs': 100, 'lr': 0.1}]\n",
            "Means: 0.5576131741205851, Stdev: 0.04345414052766029 with: [{'batch_size': 32, 'epochs': 50, 'lr': 0.001}, {'batch_size': 32, 'epochs': 50, 'lr': 0.01}, {'batch_size': 32, 'epochs': 50, 'lr': 0.1}, {'batch_size': 32, 'epochs': 100, 'lr': 0.001}, {'batch_size': 32, 'epochs': 100, 'lr': 0.01}, {'batch_size': 32, 'epochs': 100, 'lr': 0.1}, {'batch_size': 64, 'epochs': 50, 'lr': 0.001}, {'batch_size': 64, 'epochs': 50, 'lr': 0.01}, {'batch_size': 64, 'epochs': 50, 'lr': 0.1}, {'batch_size': 64, 'epochs': 100, 'lr': 0.001}, {'batch_size': 64, 'epochs': 100, 'lr': 0.01}, {'batch_size': 64, 'epochs': 100, 'lr': 0.1}, {'batch_size': 128, 'epochs': 50, 'lr': 0.001}, {'batch_size': 128, 'epochs': 50, 'lr': 0.01}, {'batch_size': 128, 'epochs': 50, 'lr': 0.1}, {'batch_size': 128, 'epochs': 100, 'lr': 0.001}, {'batch_size': 128, 'epochs': 100, 'lr': 0.01}, {'batch_size': 128, 'epochs': 100, 'lr': 0.1}]\n",
            "Means: 0.5658436218897501, Stdev: 0.06500235690186759 with: [{'batch_size': 32, 'epochs': 50, 'lr': 0.001}, {'batch_size': 32, 'epochs': 50, 'lr': 0.01}, {'batch_size': 32, 'epochs': 50, 'lr': 0.1}, {'batch_size': 32, 'epochs': 100, 'lr': 0.001}, {'batch_size': 32, 'epochs': 100, 'lr': 0.01}, {'batch_size': 32, 'epochs': 100, 'lr': 0.1}, {'batch_size': 64, 'epochs': 50, 'lr': 0.001}, {'batch_size': 64, 'epochs': 50, 'lr': 0.01}, {'batch_size': 64, 'epochs': 50, 'lr': 0.1}, {'batch_size': 64, 'epochs': 100, 'lr': 0.001}, {'batch_size': 64, 'epochs': 100, 'lr': 0.01}, {'batch_size': 64, 'epochs': 100, 'lr': 0.1}, {'batch_size': 128, 'epochs': 50, 'lr': 0.001}, {'batch_size': 128, 'epochs': 50, 'lr': 0.01}, {'batch_size': 128, 'epochs': 50, 'lr': 0.1}, {'batch_size': 128, 'epochs': 100, 'lr': 0.001}, {'batch_size': 128, 'epochs': 100, 'lr': 0.01}, {'batch_size': 128, 'epochs': 100, 'lr': 0.1}]\n",
            "Means: 0.8346193432807922, Stdev: 0.016432757538044913 with: [{'batch_size': 32, 'epochs': 50, 'lr': 0.001}, {'batch_size': 32, 'epochs': 50, 'lr': 0.01}, {'batch_size': 32, 'epochs': 50, 'lr': 0.1}, {'batch_size': 32, 'epochs': 100, 'lr': 0.001}, {'batch_size': 32, 'epochs': 100, 'lr': 0.01}, {'batch_size': 32, 'epochs': 100, 'lr': 0.1}, {'batch_size': 64, 'epochs': 50, 'lr': 0.001}, {'batch_size': 64, 'epochs': 50, 'lr': 0.01}, {'batch_size': 64, 'epochs': 50, 'lr': 0.1}, {'batch_size': 64, 'epochs': 100, 'lr': 0.001}, {'batch_size': 64, 'epochs': 100, 'lr': 0.01}, {'batch_size': 64, 'epochs': 100, 'lr': 0.1}, {'batch_size': 128, 'epochs': 50, 'lr': 0.001}, {'batch_size': 128, 'epochs': 50, 'lr': 0.01}, {'batch_size': 128, 'epochs': 50, 'lr': 0.1}, {'batch_size': 128, 'epochs': 100, 'lr': 0.001}, {'batch_size': 128, 'epochs': 100, 'lr': 0.01}, {'batch_size': 128, 'epochs': 100, 'lr': 0.1}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVtwZHRBubz1"
      },
      "source": [
        "# Summary\n",
        "\n",
        "**No Grid Search:**\n",
        "\n",
        "1st overfitting model(learning rate: 0.01, epochs=100, batchsize=15, two dense layers, one is 32 units, the other is 20): \n",
        "\n",
        "    accuracy rate for training dataset: 1, \n",
        "    accuracy rate for testing dataset: 0.6885\n",
        "\n",
        "with dropout layer and L2 regularizer(dropout: 0.3, l2):\n",
        "\n",
        "    accuracy rate for training dataset: 0.8802, \n",
        "    accuracy rate for testing dataset: 0.77\n",
        "\n",
        "**With Grid Search:**\n",
        "\n",
        "baseline model(learning rate: 0.01, epochs=100, batchsize=15, two dense layers, one is 10 units, the other is 5):\n",
        "\n",
        "    accuracy rate for training dataset: 0.8347, \n",
        "    accuracy rate for testing dataset: 0.7868\n",
        "\n",
        "after grid search tuning (batchsize: 32, epochs: 100, learning rate: 0.1):\n",
        "\n",
        "    accuracy rate for training dataset: 0.8719, \n",
        "    accuracy rate for testing dataset: 0.8511\n"
      ]
    }
  ]
}