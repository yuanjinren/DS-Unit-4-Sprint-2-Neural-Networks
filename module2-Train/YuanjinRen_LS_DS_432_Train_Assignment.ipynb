{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YuanjinRen_LS_DS_432_Train_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "nteract": {
      "version": "0.22.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuanjinren/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/module2-Train/YuanjinRen_LS_DS_432_Train_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NGGrt9EYlCqY"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Train Practice\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 2*\n",
        "\n",
        "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Please build a baseline classification model then run a few experiments with different optimizers and learning rates. \n",
        "\n",
        "*Don't forgot to switch to GPU on Colab!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptJ2b3wk62Ud",
        "colab_type": "text"
      },
      "source": [
        "### Write a function to load your data\n",
        "\n",
        "Wrap yesterday's preprocessing steps into a function that returns four items:\n",
        "* X_train\n",
        "* y_train\n",
        "* X_test\n",
        "* y_test\n",
        "\n",
        "Your function should accept a `path` to the data as a argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1OztRoraAGi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f05e68b5-3436-4611-b103-dfe508a3cf6d"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf \n",
        "\n",
        "DATA_URL = 'https://github.com/yuanjinren/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/quickdraw10.npz?raw=true'\n",
        "path = tf.keras.utils.get_file('quickdraw10.npz', DATA_URL)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/yuanjinren/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/quickdraw10.npz?raw=true\n",
            "25427968/25421363 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqBP7InuaYil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJsIsrvp7O3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_quickdraw10(path):\n",
        "  with np.load(path) as data:\n",
        "    X = data['arr_0']\n",
        "    y = data['arr_1']\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle= True)\n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzk_KZZRahub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train, X_test, y_test = load_quickdraw10(path)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSQ_YyfHaKaQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d83894c4-4276-4a4b-a1bc-48cf57ebf4f3"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((80000, 784), (80000,), (20000, 784), (20000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-6PxI6H5__2",
        "colab_type": "text"
      },
      "source": [
        "### Write a Model Function\n",
        "Using your model from yesterday, write a function called `create_model` which returns a compiled TensorFlow Keras Sequential Model suitable for classifying the QuickDraw-10 dataset. Include parameters for the following: \n",
        "* Learning Rate\n",
        "* Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvhP5amAcPqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nEREYT-3wI1f",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####\n",
        "\n",
        "def create_model():\n",
        "  opt = SGD()\n",
        "  model = Sequential([\n",
        "                      Dense(units=32, activation='relu',input_dim=784),\n",
        "                      Dense(units=20, activation='relu'),\n",
        "                      Dense(units=10, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer=opt,\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tqWNi1wc_Lc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "855f20e6-478e-4377-ad88-312eb1d707eb"
      },
      "source": [
        "model = create_model()\n",
        "bt_default = model.fit(X_train,\n",
        "          y_train,\n",
        "          epochs=30,\n",
        "          batch_size=32,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.9727 - accuracy: 0.0995 - val_loss: 2.3052 - val_accuracy: 0.0966\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3039 - accuracy: 0.0999 - val_loss: 2.3028 - val_accuracy: 0.0991\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3026 - accuracy: 0.0991 - val_loss: 2.3028 - val_accuracy: 0.0985\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3027 - accuracy: 0.1004 - val_loss: 2.3028 - val_accuracy: 0.1009\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3028 - val_accuracy: 0.0966\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3027 - accuracy: 0.1006 - val_loss: 2.3028 - val_accuracy: 0.0985\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3027 - accuracy: 0.0980 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3026 - accuracy: 0.1003 - val_loss: 2.3028 - val_accuracy: 0.0978\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3026 - accuracy: 0.0990 - val_loss: 2.3029 - val_accuracy: 0.0966\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3028 - val_accuracy: 0.0978\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3027 - accuracy: 0.0979 - val_loss: 2.3028 - val_accuracy: 0.0978\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3026 - accuracy: 0.0990 - val_loss: 2.3028 - val_accuracy: 0.0966\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3028 - val_accuracy: 0.0985\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3027 - accuracy: 0.0996 - val_loss: 2.3029 - val_accuracy: 0.0978\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3027 - accuracy: 0.0982 - val_loss: 2.3028 - val_accuracy: 0.0966\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3028 - val_accuracy: 0.0966\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3028 - val_accuracy: 0.0966\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3027 - accuracy: 0.0992 - val_loss: 2.3028 - val_accuracy: 0.0966\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3027 - accuracy: 0.0992 - val_loss: 2.3027 - val_accuracy: 0.0985\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3027 - accuracy: 0.0977 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3027 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.0984\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3026 - accuracy: 0.1015 - val_loss: 2.3028 - val_accuracy: 0.0984\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3027 - accuracy: 0.1009 - val_loss: 2.3028 - val_accuracy: 0.0966\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3026 - accuracy: 0.0983 - val_loss: 2.3027 - val_accuracy: 0.0976\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3026 - accuracy: 0.0973 - val_loss: 2.3026 - val_accuracy: 0.0976\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3026 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.0966\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0973 - val_loss: 2.3024 - val_accuracy: 0.1025\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3024 - accuracy: 0.0985 - val_loss: 2.3025 - val_accuracy: 0.0852\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 2.3014 - accuracy: 0.1004 - val_loss: 2.2988 - val_accuracy: 0.1443\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 2.2768 - accuracy: 0.1512 - val_loss: 2.2316 - val_accuracy: 0.1703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeMzvaYFfFOo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "13b9e536-dd71-4ad0-9b1a-d1ab24cffd3a"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 1s 1ms/step - loss: 2.2316 - accuracy: 0.1703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.231595754623413, 0.17030000686645508]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0pCkh8C7eGL",
        "colab_type": "text"
      },
      "source": [
        "### Experiment with Batch Size\n",
        "* Run 5 experiments with various batch sizes of your choice. \n",
        "* Visualize the results\n",
        "* Write up an analysis of the experiments and select the \"best\" performing model among your experiments. Make sure to compare against your model's performance yesterday. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USXjs7Hk71Hy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2fb787ec-94a3-4ae4-a55e-ab9018e4e710"
      },
      "source": [
        "model = create_model()\n",
        "bt_small = model.fit(X_train,\n",
        "          y_train,\n",
        "          epochs=30,\n",
        "          batch_size=8,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 4.9419 - accuracy: 0.0993 - val_loss: 2.3028 - val_accuracy: 0.0967\n",
            "Epoch 2/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3480 - accuracy: 0.1000 - val_loss: 2.3024 - val_accuracy: 0.0967\n",
            "Epoch 3/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3097 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.0985\n",
            "Epoch 4/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3026 - accuracy: 0.0997 - val_loss: 2.3027 - val_accuracy: 0.0979\n",
            "Epoch 5/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3026 - accuracy: 0.0994 - val_loss: 2.3025 - val_accuracy: 0.0979\n",
            "Epoch 6/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 2.3026 - accuracy: 0.0992 - val_loss: 2.3024 - val_accuracy: 0.0985\n",
            "Epoch 7/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3026 - accuracy: 0.0988 - val_loss: 2.3024 - val_accuracy: 0.1032\n",
            "Epoch 8/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3026 - accuracy: 0.0983 - val_loss: 2.3024 - val_accuracy: 0.1016\n",
            "Epoch 9/30\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 2.3025 - accuracy: 0.1023 - val_loss: 2.3023 - val_accuracy: 0.1010\n",
            "Epoch 10/30\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 2.3026 - accuracy: 0.1009 - val_loss: 2.3025 - val_accuracy: 0.0979\n",
            "Epoch 11/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3026 - accuracy: 0.0996 - val_loss: 2.3027 - val_accuracy: 0.0987\n",
            "Epoch 12/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3026 - accuracy: 0.0987 - val_loss: 2.3025 - val_accuracy: 0.1016\n",
            "Epoch 13/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3026 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1028\n",
            "Epoch 14/30\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 2.3026 - accuracy: 0.0988 - val_loss: 2.3032 - val_accuracy: 0.0987\n",
            "Epoch 15/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3026 - accuracy: 0.1024 - val_loss: 2.3029 - val_accuracy: 0.0987\n",
            "Epoch 16/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3026 - accuracy: 0.0982 - val_loss: 2.3025 - val_accuracy: 0.0967\n",
            "Epoch 17/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3026 - accuracy: 0.0985 - val_loss: 2.3025 - val_accuracy: 0.0979\n",
            "Epoch 18/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3026 - accuracy: 0.0990 - val_loss: 2.3028 - val_accuracy: 0.0979\n",
            "Epoch 19/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3026 - accuracy: 0.0996 - val_loss: 2.3030 - val_accuracy: 0.0985\n",
            "Epoch 20/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3026 - accuracy: 0.0994 - val_loss: 2.3031 - val_accuracy: 0.0985\n",
            "Epoch 21/30\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3025 - val_accuracy: 0.1010\n",
            "Epoch 22/30\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 2.3026 - accuracy: 0.1011 - val_loss: 2.3024 - val_accuracy: 0.1016\n",
            "Epoch 23/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3025 - val_accuracy: 0.0993\n",
            "Epoch 24/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3026 - accuracy: 0.0996 - val_loss: 2.3023 - val_accuracy: 0.0979\n",
            "Epoch 25/30\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 2.3026 - accuracy: 0.0998 - val_loss: 2.3031 - val_accuracy: 0.0993\n",
            "Epoch 26/30\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.0979\n",
            "Epoch 27/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3026 - accuracy: 0.1009 - val_loss: 2.3025 - val_accuracy: 0.0985\n",
            "Epoch 28/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 2.3025 - accuracy: 0.1019 - val_loss: 2.3029 - val_accuracy: 0.0985\n",
            "Epoch 29/30\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3024 - val_accuracy: 0.1032\n",
            "Epoch 30/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3026 - accuracy: 0.0990 - val_loss: 2.3025 - val_accuracy: 0.0979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmoi6DJ6onzf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "20c2ee17-260f-4450-9d75-5a929739ec29"
      },
      "source": [
        "model = create_model()\n",
        "bt_large = model.fit(X_train,\n",
        "          y_train,\n",
        "          epochs=30,\n",
        "          batch_size=500,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 29.1063 - accuracy: 0.1102 - val_loss: 2.2905 - val_accuracy: 0.1132\n",
            "Epoch 2/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2757 - accuracy: 0.1171 - val_loss: 2.3044 - val_accuracy: 0.1175\n",
            "Epoch 3/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2659 - accuracy: 0.1210 - val_loss: 2.3016 - val_accuracy: 0.1200\n",
            "Epoch 4/30\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 2.2615 - accuracy: 0.1217 - val_loss: 2.2960 - val_accuracy: 0.1235\n",
            "Epoch 5/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2548 - accuracy: 0.1241 - val_loss: 2.3022 - val_accuracy: 0.1256\n",
            "Epoch 6/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2478 - accuracy: 0.1262 - val_loss: 2.2915 - val_accuracy: 0.1253\n",
            "Epoch 7/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2485 - accuracy: 0.1265 - val_loss: 2.2856 - val_accuracy: 0.1253\n",
            "Epoch 8/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2401 - accuracy: 0.1310 - val_loss: 2.2914 - val_accuracy: 0.1278\n",
            "Epoch 9/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2359 - accuracy: 0.1327 - val_loss: 2.2845 - val_accuracy: 0.1265\n",
            "Epoch 10/30\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 2.2305 - accuracy: 0.1341 - val_loss: 2.2720 - val_accuracy: 0.1303\n",
            "Epoch 11/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2330 - accuracy: 0.1336 - val_loss: 2.2653 - val_accuracy: 0.1275\n",
            "Epoch 12/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2248 - accuracy: 0.1378 - val_loss: 2.2696 - val_accuracy: 0.1329\n",
            "Epoch 13/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2214 - accuracy: 0.1388 - val_loss: 2.2584 - val_accuracy: 0.1341\n",
            "Epoch 14/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2183 - accuracy: 0.1403 - val_loss: 2.2586 - val_accuracy: 0.1346\n",
            "Epoch 15/30\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 2.2145 - accuracy: 0.1421 - val_loss: 2.2507 - val_accuracy: 0.1371\n",
            "Epoch 16/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2117 - accuracy: 0.1434 - val_loss: 2.2304 - val_accuracy: 0.1373\n",
            "Epoch 17/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2103 - accuracy: 0.1445 - val_loss: 2.2309 - val_accuracy: 0.1364\n",
            "Epoch 18/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2033 - accuracy: 0.1466 - val_loss: 2.2292 - val_accuracy: 0.1404\n",
            "Epoch 19/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2017 - accuracy: 0.1467 - val_loss: 2.2332 - val_accuracy: 0.1405\n",
            "Epoch 20/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2015 - accuracy: 0.1465 - val_loss: 2.2275 - val_accuracy: 0.1412\n",
            "Epoch 21/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1973 - accuracy: 0.1492 - val_loss: 2.2230 - val_accuracy: 0.1453\n",
            "Epoch 22/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1960 - accuracy: 0.1495 - val_loss: 2.2187 - val_accuracy: 0.1461\n",
            "Epoch 23/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1946 - accuracy: 0.1504 - val_loss: 2.2179 - val_accuracy: 0.1424\n",
            "Epoch 24/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1926 - accuracy: 0.1505 - val_loss: 2.2180 - val_accuracy: 0.1468\n",
            "Epoch 25/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1880 - accuracy: 0.1531 - val_loss: 2.2077 - val_accuracy: 0.1465\n",
            "Epoch 26/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1870 - accuracy: 0.1531 - val_loss: 2.2090 - val_accuracy: 0.1460\n",
            "Epoch 27/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1838 - accuracy: 0.1552 - val_loss: 2.2007 - val_accuracy: 0.1488\n",
            "Epoch 28/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1844 - accuracy: 0.1549 - val_loss: 2.2021 - val_accuracy: 0.1488\n",
            "Epoch 29/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1808 - accuracy: 0.1556 - val_loss: 2.2024 - val_accuracy: 0.1480\n",
            "Epoch 30/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1785 - accuracy: 0.1564 - val_loss: 2.2084 - val_accuracy: 0.1526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAVWrm5roytE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34e42447-1ffe-47f5-e728-0df8faf7062a"
      },
      "source": [
        "model = create_model()\n",
        "bt_medium = model.fit(X_train,\n",
        "          y_train,\n",
        "          epochs=30,\n",
        "          batch_size=250,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 135.7528 - accuracy: 0.1004 - val_loss: 2.3042 - val_accuracy: 0.0978\n",
            "Epoch 2/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3162 - accuracy: 0.0996 - val_loss: 2.3043 - val_accuracy: 0.0978\n",
            "Epoch 3/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3059 - accuracy: 0.0997 - val_loss: 2.3043 - val_accuracy: 0.0978\n",
            "Epoch 4/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3039 - accuracy: 0.1000 - val_loss: 2.3043 - val_accuracy: 0.0978\n",
            "Epoch 5/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3035 - accuracy: 0.0998 - val_loss: 2.3043 - val_accuracy: 0.0978\n",
            "Epoch 6/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3031 - accuracy: 0.0998 - val_loss: 2.3043 - val_accuracy: 0.0966\n",
            "Epoch 7/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.1006 - val_loss: 2.3043 - val_accuracy: 0.0966\n",
            "Epoch 8/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3022 - accuracy: 0.1011 - val_loss: 2.3040 - val_accuracy: 0.0968\n",
            "Epoch 9/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3017 - accuracy: 0.1005 - val_loss: 2.3032 - val_accuracy: 0.0971\n",
            "Epoch 10/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3012 - accuracy: 0.1020 - val_loss: 2.2973 - val_accuracy: 0.1006\n",
            "Epoch 11/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2969 - accuracy: 0.1045 - val_loss: 2.2946 - val_accuracy: 0.1010\n",
            "Epoch 12/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2927 - accuracy: 0.1076 - val_loss: 2.2957 - val_accuracy: 0.1006\n",
            "Epoch 13/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2785 - accuracy: 0.1141 - val_loss: 2.2776 - val_accuracy: 0.1183\n",
            "Epoch 14/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2597 - accuracy: 0.1250 - val_loss: 2.2612 - val_accuracy: 0.1229\n",
            "Epoch 15/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2461 - accuracy: 0.1307 - val_loss: 2.2502 - val_accuracy: 0.1271\n",
            "Epoch 16/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2301 - accuracy: 0.1377 - val_loss: 2.2253 - val_accuracy: 0.1378\n",
            "Epoch 17/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2187 - accuracy: 0.1427 - val_loss: 2.2268 - val_accuracy: 0.1356\n",
            "Epoch 18/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2079 - accuracy: 0.1471 - val_loss: 2.2092 - val_accuracy: 0.1427\n",
            "Epoch 19/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1981 - accuracy: 0.1509 - val_loss: 2.2016 - val_accuracy: 0.1453\n",
            "Epoch 20/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1882 - accuracy: 0.1547 - val_loss: 2.1920 - val_accuracy: 0.1490\n",
            "Epoch 21/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1826 - accuracy: 0.1563 - val_loss: 2.1825 - val_accuracy: 0.1506\n",
            "Epoch 22/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1747 - accuracy: 0.1592 - val_loss: 2.1812 - val_accuracy: 0.1523\n",
            "Epoch 23/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1738 - accuracy: 0.1589 - val_loss: 2.1851 - val_accuracy: 0.1488\n",
            "Epoch 24/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1747 - accuracy: 0.1587 - val_loss: 2.1749 - val_accuracy: 0.1538\n",
            "Epoch 25/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1661 - accuracy: 0.1610 - val_loss: 2.2170 - val_accuracy: 0.1540\n",
            "Epoch 26/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1567 - accuracy: 0.1691 - val_loss: 2.0952 - val_accuracy: 0.2084\n",
            "Epoch 27/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.0569 - accuracy: 0.2168 - val_loss: 2.0583 - val_accuracy: 0.2139\n",
            "Epoch 28/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9904 - accuracy: 0.2382 - val_loss: 1.9617 - val_accuracy: 0.2398\n",
            "Epoch 29/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9217 - accuracy: 0.2562 - val_loss: 1.9130 - val_accuracy: 0.2529\n",
            "Epoch 30/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8871 - accuracy: 0.2558 - val_loss: 1.8870 - val_accuracy: 0.2441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABBZOG3Zo6ja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9db26b86-29cb-475c-9b6a-bbf5fd8fed5d"
      },
      "source": [
        "model = create_model()\n",
        "bt_medium2 = model.fit(X_train,\n",
        "          y_train,\n",
        "          epochs=30,\n",
        "          batch_size=150,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 565.3075 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.0978\n",
            "Epoch 2/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 3.3575 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.0978\n",
            "Epoch 3/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3034 - accuracy: 0.0989 - val_loss: 2.3027 - val_accuracy: 0.0978\n",
            "Epoch 4/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3031 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 5/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 6/30\n",
            "534/534 [==============================] - 1s 3ms/step - loss: 2.3028 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 7/30\n",
            "534/534 [==============================] - 1s 3ms/step - loss: 2.3027 - accuracy: 0.0987 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 8/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 9/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 10/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 11/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0993 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 12/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 13/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.0991 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 14/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 15/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 16/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 17/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 18/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 19/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 20/30\n",
            "534/534 [==============================] - 1s 3ms/step - loss: 2.3025 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 21/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 22/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.1006 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 23/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 24/30\n",
            "534/534 [==============================] - 1s 3ms/step - loss: 2.3025 - accuracy: 0.0997 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 25/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 26/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 27/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 28/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 29/30\n",
            "534/534 [==============================] - 1s 3ms/step - loss: 2.3025 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 30/30\n",
            "534/534 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.0966\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSOvEJ5GpCKy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "624e45b9-5f5c-48d7-915b-0e84d31d749c"
      },
      "source": [
        "model = create_model()\n",
        "bt_huge = model.fit(X_train,\n",
        "          y_train,\n",
        "          epochs=30,\n",
        "          batch_size=1000,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 16.4944 - accuracy: 0.1013 - val_loss: 2.3026 - val_accuracy: 0.0966\n",
            "Epoch 2/30\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 2.3028 - accuracy: 0.1007 - val_loss: 2.3026 - val_accuracy: 0.0966\n",
            "Epoch 3/30\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 2.3028 - accuracy: 0.1005 - val_loss: 2.3026 - val_accuracy: 0.0966\n",
            "Epoch 4/30\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 2.3028 - accuracy: 0.1008 - val_loss: 2.3026 - val_accuracy: 0.0966\n",
            "Epoch 5/30\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 2.3027 - accuracy: 0.1008 - val_loss: 2.3026 - val_accuracy: 0.0966\n",
            "Epoch 6/30\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 2.3027 - accuracy: 0.1008 - val_loss: 2.3026 - val_accuracy: 0.0966\n",
            "Epoch 7/30\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 2.3027 - accuracy: 0.1008 - val_loss: 2.3026 - val_accuracy: 0.0966\n",
            "Epoch 8/30\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 2.3027 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 9/30\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 2.3027 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 10/30\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 2.3027 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 11/30\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 12/30\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 13/30\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 14/30\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 15/30\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 16/30\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 17/30\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 18/30\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 19/30\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 20/30\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 21/30\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 22/30\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 23/30\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 24/30\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 25/30\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 26/30\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 27/30\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 28/30\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 29/30\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 30/30\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJtxkOrDpHZD",
        "colab_type": "text"
      },
      "source": [
        "Visualization of Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HDN3dMYqioT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c5631e88-16c6-4900-bd9a-0b465201dd58"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF0OQVQ5pPEB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "84691c77-ba9c-4887-d07b-5f91bfd41dbb"
      },
      "source": [
        "batch_sizes = []\n",
        "\n",
        "for exp, result in zip([bt_default, bt_small, bt_large, bt_medium, bt_medium2, bt_huge], [\"32_\", \"8_\", \"500_\", \"250_\", \"150_\", \"1000_\"]):\n",
        "  df = pd.DataFrame.from_dict(exp.history)\n",
        "  df['epoch'] = df.index.values\n",
        "  df['Batch Size'] = result\n",
        "  batch_sizes.append(df)\n",
        "\n",
        "df = pd.concat(batch_sizes)\n",
        "df['Batch Size'] = df['Batch Size'].astype('str')\n",
        "df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "      <th>Batch Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.972741</td>\n",
              "      <td>0.099487</td>\n",
              "      <td>2.305208</td>\n",
              "      <td>0.09660</td>\n",
              "      <td>0</td>\n",
              "      <td>32_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.303943</td>\n",
              "      <td>0.099875</td>\n",
              "      <td>2.302815</td>\n",
              "      <td>0.09910</td>\n",
              "      <td>1</td>\n",
              "      <td>32_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.302646</td>\n",
              "      <td>0.099050</td>\n",
              "      <td>2.302797</td>\n",
              "      <td>0.09855</td>\n",
              "      <td>2</td>\n",
              "      <td>32_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.302650</td>\n",
              "      <td>0.100437</td>\n",
              "      <td>2.302760</td>\n",
              "      <td>0.10085</td>\n",
              "      <td>3</td>\n",
              "      <td>32_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.302663</td>\n",
              "      <td>0.098800</td>\n",
              "      <td>2.302790</td>\n",
              "      <td>0.09660</td>\n",
              "      <td>4</td>\n",
              "      <td>32_</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy  val_loss  val_accuracy  epoch Batch Size\n",
              "0  2.972741  0.099487  2.305208       0.09660      0        32_\n",
              "1  2.303943  0.099875  2.302815       0.09910      1        32_\n",
              "2  2.302646  0.099050  2.302797       0.09855      2        32_\n",
              "3  2.302650  0.100437  2.302760       0.10085      3        32_\n",
              "4  2.302663  0.098800  2.302790       0.09660      4        32_"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_V9XWHZqWFj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "479a7241-673a-48e2-b346-ea359b5399e5"
      },
      "source": [
        "sns.lineplot(x='epoch', y='val_accuracy', hue='Batch Size', data=df);"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om-X8-ctmruw",
        "colab_type": "text"
      },
      "source": [
        "Based on the above visulization, the model with batch size of 250 has the best performance. The best accuracy is about 25%. Compared with the default model (model from assignment 1), the accuracy rate has big improvement. \n",
        "\n",
        "Model with batch size of 8 , 150 and 1000, the smallest size and the biggest size basically have the same accuracy rate, all very low. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8b-r70o8p2Dm"
      },
      "source": [
        "### Experiment with Learning Rate\n",
        "* Run 5 experiments with various learning rate magnitudes: 1, .1, .01, .001, .0001.\n",
        "* Use the \"best\" batch size from the previous experiment\n",
        "* Visualize the results\n",
        "* Write up an analysis of the experiments and select the \"best\" performing model among your experiments. Make sure to compare against the previous experiments and your model's performance yesterday. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SA144xx8Luf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model_lr(lr):\n",
        "  opt = SGD(learning_rate=lr)\n",
        "  model = Sequential([\n",
        "                      Dense(units=32, activation='relu',input_dim=784),\n",
        "                      Dense(units=20, activation='relu'),\n",
        "                      Dense(units=10, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer=opt,\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2OS9PojoEEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "628d516e-909f-43e1-cfb7-cf8b9a19f7e4"
      },
      "source": [
        "model_lr_1 = create_model_lr(1)\n",
        "lr_1 = model_lr_1.fit(X_train,\n",
        "          y_train,\n",
        "          epochs=30,\n",
        "          batch_size=250,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 322258.0625 - accuracy: 0.1005 - val_loss: 2.3032 - val_accuracy: 0.0991\n",
            "Epoch 2/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3036 - accuracy: 0.1008 - val_loss: 2.3036 - val_accuracy: 0.0978\n",
            "Epoch 3/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3035 - accuracy: 0.0991 - val_loss: 2.3033 - val_accuracy: 0.0966\n",
            "Epoch 4/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3036 - accuracy: 0.0997 - val_loss: 2.3036 - val_accuracy: 0.1009\n",
            "Epoch 5/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3035 - accuracy: 0.1002 - val_loss: 2.3028 - val_accuracy: 0.0991\n",
            "Epoch 6/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3035 - accuracy: 0.0985 - val_loss: 2.3039 - val_accuracy: 0.0985\n",
            "Epoch 7/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3037 - accuracy: 0.0971 - val_loss: 2.3033 - val_accuracy: 0.1031\n",
            "Epoch 8/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3036 - accuracy: 0.1006 - val_loss: 2.3035 - val_accuracy: 0.0966\n",
            "Epoch 9/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3036 - accuracy: 0.1019 - val_loss: 2.3032 - val_accuracy: 0.1015\n",
            "Epoch 10/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3036 - accuracy: 0.1004 - val_loss: 2.3036 - val_accuracy: 0.0985\n",
            "Epoch 11/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3035 - accuracy: 0.0995 - val_loss: 2.3049 - val_accuracy: 0.1015\n",
            "Epoch 12/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3037 - accuracy: 0.0991 - val_loss: 2.3028 - val_accuracy: 0.0991\n",
            "Epoch 13/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3037 - accuracy: 0.0997 - val_loss: 2.3030 - val_accuracy: 0.1009\n",
            "Epoch 14/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3035 - accuracy: 0.0991 - val_loss: 2.3031 - val_accuracy: 0.1009\n",
            "Epoch 15/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3035 - accuracy: 0.1011 - val_loss: 2.3043 - val_accuracy: 0.0966\n",
            "Epoch 16/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3036 - accuracy: 0.0998 - val_loss: 2.3043 - val_accuracy: 0.1015\n",
            "Epoch 17/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3036 - accuracy: 0.0997 - val_loss: 2.3044 - val_accuracy: 0.0985\n",
            "Epoch 18/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3037 - accuracy: 0.1004 - val_loss: 2.3035 - val_accuracy: 0.1015\n",
            "Epoch 19/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3034 - accuracy: 0.0997 - val_loss: 2.3040 - val_accuracy: 0.1009\n",
            "Epoch 20/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3035 - accuracy: 0.1006 - val_loss: 2.3036 - val_accuracy: 0.1015\n",
            "Epoch 21/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3035 - accuracy: 0.0999 - val_loss: 2.3035 - val_accuracy: 0.1015\n",
            "Epoch 22/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3034 - accuracy: 0.1003 - val_loss: 2.3036 - val_accuracy: 0.0966\n",
            "Epoch 23/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3036 - accuracy: 0.1010 - val_loss: 2.3033 - val_accuracy: 0.1009\n",
            "Epoch 24/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3037 - accuracy: 0.0990 - val_loss: 2.3033 - val_accuracy: 0.0991\n",
            "Epoch 25/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3035 - accuracy: 0.1010 - val_loss: 2.3031 - val_accuracy: 0.1031\n",
            "Epoch 26/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3035 - accuracy: 0.1000 - val_loss: 2.3028 - val_accuracy: 0.0991\n",
            "Epoch 27/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3034 - accuracy: 0.1016 - val_loss: 2.3047 - val_accuracy: 0.0985\n",
            "Epoch 28/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3035 - accuracy: 0.1000 - val_loss: 2.3030 - val_accuracy: 0.0966\n",
            "Epoch 29/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3034 - accuracy: 0.1017 - val_loss: 2.3034 - val_accuracy: 0.1015\n",
            "Epoch 30/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3036 - accuracy: 0.1015 - val_loss: 2.3039 - val_accuracy: 0.0991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfKVpYZyo3iz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "546ec51c-0df2-430d-e169-9d6ff6ec22fb"
      },
      "source": [
        "model_lr_01 = create_model_lr(0.1)\n",
        "lr_01 = model_lr_01.fit(X_train,\n",
        "          y_train,\n",
        "          epochs=30,\n",
        "          batch_size=250,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 485148.0938 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.1009\n",
            "Epoch 2/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.0978\n",
            "Epoch 3/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 4/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3028 - val_accuracy: 0.0991\n",
            "Epoch 5/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0981 - val_loss: 2.3028 - val_accuracy: 0.0991\n",
            "Epoch 6/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3028 - val_accuracy: 0.0985\n",
            "Epoch 7/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 8/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3028 - val_accuracy: 0.0966\n",
            "Epoch 9/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0990 - val_loss: 2.3028 - val_accuracy: 0.0966\n",
            "Epoch 10/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0979 - val_loss: 2.3028 - val_accuracy: 0.0966\n",
            "Epoch 11/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.0985\n",
            "Epoch 12/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 13/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.1006 - val_loss: 2.3027 - val_accuracy: 0.0978\n",
            "Epoch 14/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3028 - val_accuracy: 0.1015\n",
            "Epoch 15/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0982 - val_loss: 2.3028 - val_accuracy: 0.0991\n",
            "Epoch 16/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.0985\n",
            "Epoch 17/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.1003 - val_loss: 2.3027 - val_accuracy: 0.1015\n",
            "Epoch 18/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.0978\n",
            "Epoch 19/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 20/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3028 - val_accuracy: 0.0978\n",
            "Epoch 21/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3028 - val_accuracy: 0.0978\n",
            "Epoch 22/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3027 - val_accuracy: 0.0978\n",
            "Epoch 23/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0992 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 24/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.1009 - val_loss: 2.3028 - val_accuracy: 0.0978\n",
            "Epoch 25/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3029 - val_accuracy: 0.0966\n",
            "Epoch 26/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0984 - val_loss: 2.3027 - val_accuracy: 0.0991\n",
            "Epoch 27/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.1009\n",
            "Epoch 28/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.0985\n",
            "Epoch 29/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3027 - val_accuracy: 0.1015\n",
            "Epoch 30/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.1005 - val_loss: 2.3028 - val_accuracy: 0.0978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZwCBTgco9gM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4aacde17-5c65-46ef-b645-02f2ad78dc77"
      },
      "source": [
        "model_lr_001 = create_model_lr(0.01)\n",
        "lr_001 = model_lr_001.fit(X_train,\n",
        "          y_train,\n",
        "          epochs=30,\n",
        "          batch_size=250,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 46.1218 - accuracy: 0.1001 - val_loss: 2.3076 - val_accuracy: 0.0966\n",
            "Epoch 2/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3228 - accuracy: 0.0993 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 3/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3114 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 4/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3068 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 5/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3051 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 6/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3042 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 7/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3039 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 8/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3037 - accuracy: 0.1004 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 9/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3040 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 10/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3037 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 11/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3033 - accuracy: 0.1003 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 12/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3032 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 13/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 14/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3030 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 15/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.1003 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 16/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3028 - accuracy: 0.1007 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 17/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3028 - accuracy: 0.1004 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 18/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 19/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.1003 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 20/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 21/30\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 22/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.1006 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 23/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 24/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.1006 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 25/30\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 2.3025 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 26/30\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 2.3025 - accuracy: 0.0997 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 27/30\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 2.3025 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 28/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 29/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.1004 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
            "Epoch 30/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.0966\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCahRDKdpHrN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f46504c-80e6-43cc-f433-c13c1628f54f"
      },
      "source": [
        "model_lr_0001 = create_model_lr(0.001)\n",
        "lr_0001 = model_lr_0001.fit(X_train,\n",
        "          y_train,\n",
        "          epochs=30,\n",
        "          batch_size=250,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 3.1714 - accuracy: 0.1042 - val_loss: 2.3057 - val_accuracy: 0.1020\n",
            "Epoch 2/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2911 - accuracy: 0.1186 - val_loss: 2.2605 - val_accuracy: 0.1378\n",
            "Epoch 3/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2157 - accuracy: 0.1606 - val_loss: 2.1650 - val_accuracy: 0.1784\n",
            "Epoch 4/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1478 - accuracy: 0.1861 - val_loss: 2.1315 - val_accuracy: 0.1884\n",
            "Epoch 5/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1190 - accuracy: 0.1953 - val_loss: 2.1125 - val_accuracy: 0.1959\n",
            "Epoch 6/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.0955 - accuracy: 0.2076 - val_loss: 2.0886 - val_accuracy: 0.2105\n",
            "Epoch 7/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.0716 - accuracy: 0.2203 - val_loss: 2.0675 - val_accuracy: 0.2219\n",
            "Epoch 8/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.0472 - accuracy: 0.2331 - val_loss: 2.0437 - val_accuracy: 0.2372\n",
            "Epoch 9/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.0248 - accuracy: 0.2408 - val_loss: 2.0229 - val_accuracy: 0.2422\n",
            "Epoch 10/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.0042 - accuracy: 0.2469 - val_loss: 2.0044 - val_accuracy: 0.2466\n",
            "Epoch 11/30\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.9841 - accuracy: 0.2516 - val_loss: 1.9871 - val_accuracy: 0.2518\n",
            "Epoch 12/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9655 - accuracy: 0.2551 - val_loss: 1.9684 - val_accuracy: 0.2575\n",
            "Epoch 13/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9483 - accuracy: 0.2593 - val_loss: 1.9520 - val_accuracy: 0.2615\n",
            "Epoch 14/30\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.9309 - accuracy: 0.2639 - val_loss: 1.9349 - val_accuracy: 0.2634\n",
            "Epoch 15/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9142 - accuracy: 0.2673 - val_loss: 1.9201 - val_accuracy: 0.2649\n",
            "Epoch 16/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8973 - accuracy: 0.2732 - val_loss: 1.9022 - val_accuracy: 0.2698\n",
            "Epoch 17/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8796 - accuracy: 0.2819 - val_loss: 1.8831 - val_accuracy: 0.2837\n",
            "Epoch 18/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8624 - accuracy: 0.2884 - val_loss: 1.8645 - val_accuracy: 0.2882\n",
            "Epoch 19/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8456 - accuracy: 0.2961 - val_loss: 1.8474 - val_accuracy: 0.2930\n",
            "Epoch 20/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8322 - accuracy: 0.3013 - val_loss: 1.8361 - val_accuracy: 0.2968\n",
            "Epoch 21/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8212 - accuracy: 0.3067 - val_loss: 1.8264 - val_accuracy: 0.3034\n",
            "Epoch 22/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8115 - accuracy: 0.3106 - val_loss: 1.8139 - val_accuracy: 0.3070\n",
            "Epoch 23/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8017 - accuracy: 0.3153 - val_loss: 1.8059 - val_accuracy: 0.3105\n",
            "Epoch 24/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7925 - accuracy: 0.3192 - val_loss: 1.7961 - val_accuracy: 0.3199\n",
            "Epoch 25/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7835 - accuracy: 0.3256 - val_loss: 1.7861 - val_accuracy: 0.3266\n",
            "Epoch 26/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7729 - accuracy: 0.3310 - val_loss: 1.7729 - val_accuracy: 0.3297\n",
            "Epoch 27/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7620 - accuracy: 0.3379 - val_loss: 1.7586 - val_accuracy: 0.3392\n",
            "Epoch 28/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7504 - accuracy: 0.3451 - val_loss: 1.7576 - val_accuracy: 0.3455\n",
            "Epoch 29/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7390 - accuracy: 0.3519 - val_loss: 1.7352 - val_accuracy: 0.3614\n",
            "Epoch 30/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7266 - accuracy: 0.3586 - val_loss: 1.7400 - val_accuracy: 0.3392\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EPhfdhTpPzG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "add60742-ebb4-4d08-909e-5d16fc047a25"
      },
      "source": [
        "model_lr_00001 = create_model_lr(0.0001)\n",
        "lr_00001 = model_lr_00001.fit(X_train,\n",
        "          y_train,\n",
        "          epochs=30,\n",
        "          batch_size=250,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 11.4997 - accuracy: 0.1660 - val_loss: 3.3160 - val_accuracy: 0.1688\n",
            "Epoch 2/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.8677 - accuracy: 0.1588 - val_loss: 2.5675 - val_accuracy: 0.1481\n",
            "Epoch 3/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.4879 - accuracy: 0.1638 - val_loss: 2.3849 - val_accuracy: 0.1843\n",
            "Epoch 4/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3581 - accuracy: 0.1888 - val_loss: 2.2955 - val_accuracy: 0.1984\n",
            "Epoch 5/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2884 - accuracy: 0.2008 - val_loss: 2.2410 - val_accuracy: 0.2063\n",
            "Epoch 6/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2421 - accuracy: 0.2147 - val_loss: 2.2024 - val_accuracy: 0.2205\n",
            "Epoch 7/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2067 - accuracy: 0.2291 - val_loss: 2.1698 - val_accuracy: 0.2296\n",
            "Epoch 8/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1756 - accuracy: 0.2386 - val_loss: 2.1420 - val_accuracy: 0.2395\n",
            "Epoch 9/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1477 - accuracy: 0.2486 - val_loss: 2.1165 - val_accuracy: 0.2495\n",
            "Epoch 10/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1215 - accuracy: 0.2599 - val_loss: 2.0904 - val_accuracy: 0.2620\n",
            "Epoch 11/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.0957 - accuracy: 0.2709 - val_loss: 2.0645 - val_accuracy: 0.2731\n",
            "Epoch 12/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.0702 - accuracy: 0.2817 - val_loss: 2.0402 - val_accuracy: 0.2846\n",
            "Epoch 13/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.0461 - accuracy: 0.2923 - val_loss: 2.0176 - val_accuracy: 0.2937\n",
            "Epoch 14/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.0228 - accuracy: 0.3031 - val_loss: 1.9975 - val_accuracy: 0.3024\n",
            "Epoch 15/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.0000 - accuracy: 0.3112 - val_loss: 1.9792 - val_accuracy: 0.3097\n",
            "Epoch 16/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9801 - accuracy: 0.3178 - val_loss: 1.9606 - val_accuracy: 0.3155\n",
            "Epoch 17/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9614 - accuracy: 0.3240 - val_loss: 1.9430 - val_accuracy: 0.3228\n",
            "Epoch 18/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9441 - accuracy: 0.3306 - val_loss: 1.9270 - val_accuracy: 0.3278\n",
            "Epoch 19/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9280 - accuracy: 0.3357 - val_loss: 1.9122 - val_accuracy: 0.3342\n",
            "Epoch 20/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9133 - accuracy: 0.3402 - val_loss: 1.8986 - val_accuracy: 0.3375\n",
            "Epoch 21/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8996 - accuracy: 0.3448 - val_loss: 1.8857 - val_accuracy: 0.3419\n",
            "Epoch 22/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8858 - accuracy: 0.3509 - val_loss: 1.8740 - val_accuracy: 0.3461\n",
            "Epoch 23/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8719 - accuracy: 0.3561 - val_loss: 1.8629 - val_accuracy: 0.3505\n",
            "Epoch 24/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8586 - accuracy: 0.3609 - val_loss: 1.8515 - val_accuracy: 0.3555\n",
            "Epoch 25/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8460 - accuracy: 0.3663 - val_loss: 1.8407 - val_accuracy: 0.3599\n",
            "Epoch 26/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8340 - accuracy: 0.3708 - val_loss: 1.8305 - val_accuracy: 0.3645\n",
            "Epoch 27/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8232 - accuracy: 0.3746 - val_loss: 1.8209 - val_accuracy: 0.3679\n",
            "Epoch 28/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8131 - accuracy: 0.3785 - val_loss: 1.8124 - val_accuracy: 0.3711\n",
            "Epoch 29/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8036 - accuracy: 0.3816 - val_loss: 1.8047 - val_accuracy: 0.3735\n",
            "Epoch 30/30\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7951 - accuracy: 0.3847 - val_loss: 1.7972 - val_accuracy: 0.3753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg4qhmgnKbJz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c3bf6c11-c3fd-4b93-cd9c-1e0a6365dbd8"
      },
      "source": [
        "test = pd.DataFrame.from_records(lr_1.history)\n",
        "test.head()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.100488</td>\n",
              "      <td>322258.062500</td>\n",
              "      <td>0.09910</td>\n",
              "      <td>2.303169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.100775</td>\n",
              "      <td>2.303611</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>2.303603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.099113</td>\n",
              "      <td>2.303515</td>\n",
              "      <td>0.09660</td>\n",
              "      <td>2.303324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.099750</td>\n",
              "      <td>2.303580</td>\n",
              "      <td>0.10085</td>\n",
              "      <td>2.303632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.100200</td>\n",
              "      <td>2.303493</td>\n",
              "      <td>0.09910</td>\n",
              "      <td>2.302751</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   accuracy           loss  val_accuracy  val_loss\n",
              "0  0.100488  322258.062500       0.09910  2.303169\n",
              "1  0.100775       2.303611       0.09780  2.303603\n",
              "2  0.099113       2.303515       0.09660  2.303324\n",
              "3  0.099750       2.303580       0.10085  2.303632\n",
              "4  0.100200       2.303493       0.09910  2.302751"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnVVEBOIqsMN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "da3b4e2b-1815-4f94-8bcd-845e2f552903"
      },
      "source": [
        "batch_sizes = []\n",
        "for exp, result in zip([lr_1, lr_01, lr_001, lr_0001, lr_00001], [\"1\",\"0.1_\",\"0.01_\", \"0.001_\", \"0.0001_\"]):\n",
        "    df = pd.DataFrame.from_dict(exp.history)\n",
        "    df['epoch'] = df.index.values\n",
        "    df['Learning Rate'] = result\n",
        "    batch_sizes.append(df)\n",
        "\n",
        "df = pd.concat(batch_sizes)\n",
        "df['Learning Rate'] = df['Learning Rate'].astype('str')\n",
        "df.tail(10)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "      <th>Learning Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1.899624</td>\n",
              "      <td>0.344825</td>\n",
              "      <td>1.885744</td>\n",
              "      <td>0.34185</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0001_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1.885818</td>\n",
              "      <td>0.350925</td>\n",
              "      <td>1.874027</td>\n",
              "      <td>0.34610</td>\n",
              "      <td>21</td>\n",
              "      <td>0.0001_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1.871947</td>\n",
              "      <td>0.356088</td>\n",
              "      <td>1.862853</td>\n",
              "      <td>0.35045</td>\n",
              "      <td>22</td>\n",
              "      <td>0.0001_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1.858593</td>\n",
              "      <td>0.360950</td>\n",
              "      <td>1.851503</td>\n",
              "      <td>0.35545</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0001_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1.846038</td>\n",
              "      <td>0.366313</td>\n",
              "      <td>1.840721</td>\n",
              "      <td>0.35990</td>\n",
              "      <td>24</td>\n",
              "      <td>0.0001_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1.834044</td>\n",
              "      <td>0.370800</td>\n",
              "      <td>1.830507</td>\n",
              "      <td>0.36455</td>\n",
              "      <td>25</td>\n",
              "      <td>0.0001_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1.823206</td>\n",
              "      <td>0.374588</td>\n",
              "      <td>1.820887</td>\n",
              "      <td>0.36790</td>\n",
              "      <td>26</td>\n",
              "      <td>0.0001_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1.813129</td>\n",
              "      <td>0.378475</td>\n",
              "      <td>1.812389</td>\n",
              "      <td>0.37110</td>\n",
              "      <td>27</td>\n",
              "      <td>0.0001_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1.803625</td>\n",
              "      <td>0.381625</td>\n",
              "      <td>1.804720</td>\n",
              "      <td>0.37350</td>\n",
              "      <td>28</td>\n",
              "      <td>0.0001_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1.795063</td>\n",
              "      <td>0.384725</td>\n",
              "      <td>1.797154</td>\n",
              "      <td>0.37525</td>\n",
              "      <td>29</td>\n",
              "      <td>0.0001_</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy  epoch Learning Rate\n",
              "20  1.899624  0.344825  1.885744       0.34185     20       0.0001_\n",
              "21  1.885818  0.350925  1.874027       0.34610     21       0.0001_\n",
              "22  1.871947  0.356088  1.862853       0.35045     22       0.0001_\n",
              "23  1.858593  0.360950  1.851503       0.35545     23       0.0001_\n",
              "24  1.846038  0.366313  1.840721       0.35990     24       0.0001_\n",
              "25  1.834044  0.370800  1.830507       0.36455     25       0.0001_\n",
              "26  1.823206  0.374588  1.820887       0.36790     26       0.0001_\n",
              "27  1.813129  0.378475  1.812389       0.37110     27       0.0001_\n",
              "28  1.803625  0.381625  1.804720       0.37350     28       0.0001_\n",
              "29  1.795063  0.384725  1.797154       0.37525     29       0.0001_"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvY9HP-cswvq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "df643f38-1e40-46a8-84a0-6636af7d0b5a"
      },
      "source": [
        "sns.lineplot(x='epoch', y='val_accuracy', hue='Learning Rate', data=df);"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp0Hfvm-tET1",
        "colab_type": "text"
      },
      "source": [
        "The lowest learning rate 0.0001 has the best performance. Models with learning rate of 1, 0.1 and 0.01 have the almost same accuracy rate. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxMtSRhV9Q7I",
        "colab_type": "text"
      },
      "source": [
        "### Experiment with different Optimizers\n",
        "* Run 5 experiments with various optimizers available in TensorFlow. See list [here](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)\n",
        "* Visualize the results\n",
        "* Write up an analysis of the experiments and select the \"best\" performing model among your experiments. Make sure to compare against the previous experiments and your model's performance yesterday.\n",
        "* Repeat the experiment combining Learning Rate and different optimizers. Does the best performing model change? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCkECQby4tKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model_optimizer(opt):\n",
        "  model = Sequential([\n",
        "                      Dense(32, activation='relu',input_dim=784),\n",
        "                      Dense(32, activation='relu'),\n",
        "                      Dense(10, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer=opt,\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCIgE2Lwet7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6bf7e001-543f-4d8b-ac4c-2c317f4d8095"
      },
      "source": [
        "model_adam = create_model_optimizer(tf.keras.optimizers.Adam(learning_rate=0.0001))\n",
        "adam = model_adam.fit(X_train,\n",
        "           y_train,\n",
        "           epochs=30,\n",
        "           batch_size=8,\n",
        "           validation_data=(X_test, y_test))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 3.8701 - accuracy: 0.1997 - val_loss: 1.8947 - val_accuracy: 0.3119\n",
            "Epoch 2/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 1.6767 - accuracy: 0.4198 - val_loss: 1.5179 - val_accuracy: 0.4800\n",
            "Epoch 3/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 1.3979 - accuracy: 0.5270 - val_loss: 1.3130 - val_accuracy: 0.5809\n",
            "Epoch 4/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.1959 - accuracy: 0.6151 - val_loss: 1.1377 - val_accuracy: 0.6381\n",
            "Epoch 5/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 1.0635 - accuracy: 0.6597 - val_loss: 1.0536 - val_accuracy: 0.6602\n",
            "Epoch 6/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.9743 - accuracy: 0.6862 - val_loss: 0.9799 - val_accuracy: 0.6956\n",
            "Epoch 7/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.9020 - accuracy: 0.7111 - val_loss: 0.9367 - val_accuracy: 0.7145\n",
            "Epoch 8/30\n",
            "10000/10000 [==============================] - 21s 2ms/step - loss: 0.8421 - accuracy: 0.7336 - val_loss: 0.8750 - val_accuracy: 0.7379\n",
            "Epoch 9/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.7927 - accuracy: 0.7525 - val_loss: 0.8236 - val_accuracy: 0.7530\n",
            "Epoch 10/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 0.7487 - accuracy: 0.7676 - val_loss: 0.7910 - val_accuracy: 0.7649\n",
            "Epoch 11/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.7126 - accuracy: 0.7803 - val_loss: 0.7617 - val_accuracy: 0.7756\n",
            "Epoch 12/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.6797 - accuracy: 0.7919 - val_loss: 0.7333 - val_accuracy: 0.7859\n",
            "Epoch 13/30\n",
            "10000/10000 [==============================] - 21s 2ms/step - loss: 0.6553 - accuracy: 0.7999 - val_loss: 0.7175 - val_accuracy: 0.7899\n",
            "Epoch 14/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.6313 - accuracy: 0.8084 - val_loss: 0.7089 - val_accuracy: 0.8025\n",
            "Epoch 15/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.6142 - accuracy: 0.8166 - val_loss: 0.6963 - val_accuracy: 0.7988\n",
            "Epoch 16/30\n",
            "10000/10000 [==============================] - 21s 2ms/step - loss: 0.5978 - accuracy: 0.8214 - val_loss: 0.6741 - val_accuracy: 0.8083\n",
            "Epoch 17/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.5849 - accuracy: 0.8258 - val_loss: 0.6947 - val_accuracy: 0.8037\n",
            "Epoch 18/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.5738 - accuracy: 0.8286 - val_loss: 0.6790 - val_accuracy: 0.8073\n",
            "Epoch 19/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.5637 - accuracy: 0.8329 - val_loss: 0.6672 - val_accuracy: 0.8135\n",
            "Epoch 20/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.5551 - accuracy: 0.8360 - val_loss: 0.6602 - val_accuracy: 0.8150\n",
            "Epoch 21/30\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 0.5475 - accuracy: 0.8378 - val_loss: 0.6590 - val_accuracy: 0.8181\n",
            "Epoch 22/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.5395 - accuracy: 0.8408 - val_loss: 0.6638 - val_accuracy: 0.8123\n",
            "Epoch 23/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.5326 - accuracy: 0.8432 - val_loss: 0.6728 - val_accuracy: 0.8166\n",
            "Epoch 24/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.5271 - accuracy: 0.8433 - val_loss: 0.6662 - val_accuracy: 0.8202\n",
            "Epoch 25/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.5206 - accuracy: 0.8465 - val_loss: 0.6669 - val_accuracy: 0.8169\n",
            "Epoch 26/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.5162 - accuracy: 0.8482 - val_loss: 0.6614 - val_accuracy: 0.8187\n",
            "Epoch 27/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.5117 - accuracy: 0.8484 - val_loss: 0.6825 - val_accuracy: 0.8117\n",
            "Epoch 28/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.5073 - accuracy: 0.8497 - val_loss: 0.6647 - val_accuracy: 0.8224\n",
            "Epoch 29/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.5022 - accuracy: 0.8512 - val_loss: 0.6745 - val_accuracy: 0.8168\n",
            "Epoch 30/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.4989 - accuracy: 0.8520 - val_loss: 0.6688 - val_accuracy: 0.8196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwjkYs7lQAqE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "24056cef-bb8b-4ae7-87a0-5291c01860b7"
      },
      "source": [
        "model_adam2 = create_model_optimizer(tf.keras.optimizers.Adam(learning_rate=0.001))\n",
        "adam2 = model_adam2.fit(X_train,\n",
        "           y_train,\n",
        "           epochs=30,\n",
        "           batch_size=8,\n",
        "           validation_data=(X_test, y_test))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 1.7462 - accuracy: 0.4615 - val_loss: 1.3885 - val_accuracy: 0.5210\n",
            "Epoch 2/30\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 1.3364 - accuracy: 0.5252 - val_loss: 1.2729 - val_accuracy: 0.5655\n",
            "Epoch 3/30\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 1.2164 - accuracy: 0.5666 - val_loss: 1.1824 - val_accuracy: 0.5818\n",
            "Epoch 4/30\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 1.1462 - accuracy: 0.5888 - val_loss: 1.1280 - val_accuracy: 0.5982\n",
            "Epoch 5/30\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 1.0896 - accuracy: 0.6179 - val_loss: 1.0715 - val_accuracy: 0.6316\n",
            "Epoch 6/30\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 1.0436 - accuracy: 0.6368 - val_loss: 1.0262 - val_accuracy: 0.6435\n",
            "Epoch 7/30\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 0.9991 - accuracy: 0.6534 - val_loss: 1.0131 - val_accuracy: 0.6447\n",
            "Epoch 8/30\n",
            "10000/10000 [==============================] - 23s 2ms/step - loss: 0.9617 - accuracy: 0.6768 - val_loss: 0.9736 - val_accuracy: 0.6993\n",
            "Epoch 9/30\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 0.9065 - accuracy: 0.7053 - val_loss: 0.9188 - val_accuracy: 0.7090\n",
            "Epoch 10/30\n",
            "10000/10000 [==============================] - 24s 2ms/step - loss: 0.8884 - accuracy: 0.7146 - val_loss: 0.9094 - val_accuracy: 0.7161\n",
            "Epoch 11/30\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 0.8776 - accuracy: 0.7184 - val_loss: 0.9425 - val_accuracy: 0.7045\n",
            "Epoch 12/30\n",
            "10000/10000 [==============================] - 23s 2ms/step - loss: 0.8728 - accuracy: 0.7201 - val_loss: 0.9148 - val_accuracy: 0.7110\n",
            "Epoch 13/30\n",
            "10000/10000 [==============================] - 23s 2ms/step - loss: 0.8674 - accuracy: 0.7199 - val_loss: 0.8958 - val_accuracy: 0.7077\n",
            "Epoch 14/30\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 0.8631 - accuracy: 0.7203 - val_loss: 0.9094 - val_accuracy: 0.7078\n",
            "Epoch 15/30\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 0.8614 - accuracy: 0.7205 - val_loss: 0.8775 - val_accuracy: 0.7149\n",
            "Epoch 16/30\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 0.8515 - accuracy: 0.7263 - val_loss: 0.8927 - val_accuracy: 0.7165\n",
            "Epoch 17/30\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 0.8550 - accuracy: 0.7227 - val_loss: 0.8830 - val_accuracy: 0.7185\n",
            "Epoch 18/30\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 0.8438 - accuracy: 0.7344 - val_loss: 0.8892 - val_accuracy: 0.7235\n",
            "Epoch 19/30\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 0.8474 - accuracy: 0.7307 - val_loss: 0.9542 - val_accuracy: 0.7005\n",
            "Epoch 20/30\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 0.8431 - accuracy: 0.7318 - val_loss: 0.8729 - val_accuracy: 0.7225\n",
            "Epoch 21/30\n",
            "10000/10000 [==============================] - 21s 2ms/step - loss: 0.8319 - accuracy: 0.7375 - val_loss: 0.9140 - val_accuracy: 0.7207\n",
            "Epoch 22/30\n",
            "10000/10000 [==============================] - 21s 2ms/step - loss: 0.8333 - accuracy: 0.7315 - val_loss: 0.8647 - val_accuracy: 0.7208\n",
            "Epoch 23/30\n",
            "10000/10000 [==============================] - 21s 2ms/step - loss: 0.8294 - accuracy: 0.7335 - val_loss: 0.8693 - val_accuracy: 0.7265\n",
            "Epoch 24/30\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 0.8274 - accuracy: 0.7363 - val_loss: 0.8887 - val_accuracy: 0.7187\n",
            "Epoch 25/30\n",
            "10000/10000 [==============================] - 21s 2ms/step - loss: 0.8222 - accuracy: 0.7383 - val_loss: 0.8761 - val_accuracy: 0.7176\n",
            "Epoch 26/30\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 0.8198 - accuracy: 0.7359 - val_loss: 0.8637 - val_accuracy: 0.7216\n",
            "Epoch 27/30\n",
            "10000/10000 [==============================] - 21s 2ms/step - loss: 0.8069 - accuracy: 0.7464 - val_loss: 0.8500 - val_accuracy: 0.7475\n",
            "Epoch 28/30\n",
            "10000/10000 [==============================] - 21s 2ms/step - loss: 0.7863 - accuracy: 0.7560 - val_loss: 0.8942 - val_accuracy: 0.7368\n",
            "Epoch 29/30\n",
            "10000/10000 [==============================] - 21s 2ms/step - loss: 0.7767 - accuracy: 0.7612 - val_loss: 0.8328 - val_accuracy: 0.7537\n",
            "Epoch 30/30\n",
            "10000/10000 [==============================] - 21s 2ms/step - loss: 0.7684 - accuracy: 0.7656 - val_loss: 0.8361 - val_accuracy: 0.7551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koRJjpJl8uEv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a62633e5-b888-42c4-b2b9-0c90c4248513"
      },
      "source": [
        "model_adamax = create_model_optimizer(opt =tf.keras.optimizers.Adamax(learning_rate=0.1))\n",
        "adamax = model_adamax.fit(X_train,\n",
        "           y_train,\n",
        "           epochs=30,\n",
        "           batch_size=32,\n",
        "           validation_data=(X_test, y_test))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 6.8034 - accuracy: 0.1014 - val_loss: 2.3062 - val_accuracy: 0.1009\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 2.3070 - accuracy: 0.1008 - val_loss: 2.3119 - val_accuracy: 0.0985\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3072 - accuracy: 0.1007 - val_loss: 2.3044 - val_accuracy: 0.0985\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3071 - accuracy: 0.1008 - val_loss: 2.3058 - val_accuracy: 0.1026\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3069 - accuracy: 0.0997 - val_loss: 2.3053 - val_accuracy: 0.0966\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3073 - accuracy: 0.1010 - val_loss: 2.3070 - val_accuracy: 0.0985\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3069 - accuracy: 0.1000 - val_loss: 2.3083 - val_accuracy: 0.0966\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3071 - accuracy: 0.0983 - val_loss: 2.3090 - val_accuracy: 0.1015\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3069 - accuracy: 0.1016 - val_loss: 2.3092 - val_accuracy: 0.0985\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3069 - accuracy: 0.0994 - val_loss: 2.3050 - val_accuracy: 0.0985\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3070 - accuracy: 0.0979 - val_loss: 2.3035 - val_accuracy: 0.1026\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3073 - accuracy: 0.0985 - val_loss: 2.3061 - val_accuracy: 0.0985\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3066 - accuracy: 0.1004 - val_loss: 2.3037 - val_accuracy: 0.0966\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3070 - accuracy: 0.0998 - val_loss: 2.3065 - val_accuracy: 0.0985\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3067 - accuracy: 0.1019 - val_loss: 2.3049 - val_accuracy: 0.1009\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3069 - accuracy: 0.1000 - val_loss: 2.3104 - val_accuracy: 0.0985\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3071 - accuracy: 0.0990 - val_loss: 2.3041 - val_accuracy: 0.1026\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3071 - accuracy: 0.1006 - val_loss: 2.3069 - val_accuracy: 0.1026\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3071 - accuracy: 0.1004 - val_loss: 2.3053 - val_accuracy: 0.1031\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3070 - accuracy: 0.1004 - val_loss: 2.3062 - val_accuracy: 0.0991\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 2.3073 - accuracy: 0.0987 - val_loss: 2.3088 - val_accuracy: 0.1031\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 2.3071 - accuracy: 0.0989 - val_loss: 2.3076 - val_accuracy: 0.0978\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3073 - accuracy: 0.0987 - val_loss: 2.3077 - val_accuracy: 0.0966\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3070 - accuracy: 0.1005 - val_loss: 2.3046 - val_accuracy: 0.0991\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3071 - accuracy: 0.0979 - val_loss: 2.3088 - val_accuracy: 0.0985\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3071 - accuracy: 0.1002 - val_loss: 2.3052 - val_accuracy: 0.0966\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3070 - accuracy: 0.0988 - val_loss: 2.3037 - val_accuracy: 0.1009\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3069 - accuracy: 0.0998 - val_loss: 2.3056 - val_accuracy: 0.0978\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3067 - accuracy: 0.1004 - val_loss: 2.3050 - val_accuracy: 0.0985\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3072 - accuracy: 0.0996 - val_loss: 2.3046 - val_accuracy: 0.0966\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npx0nIt0-Qlp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "270a7168-c118-4106-cb11-aea7f808562c"
      },
      "source": [
        "model_adamax2 = create_model_optimizer(opt =tf.keras.optimizers.Adamax(learning_rate=0.01))\n",
        "adamax2 = model_adamax2.fit(X_train,\n",
        "           y_train,\n",
        "           epochs=30,\n",
        "           batch_size=32,\n",
        "           validation_data=(X_test, y_test))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3525 - accuracy: 0.3049 - val_loss: 1.6903 - val_accuracy: 0.3937\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5378 - accuracy: 0.4510 - val_loss: 1.4012 - val_accuracy: 0.4839\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2495 - accuracy: 0.5793 - val_loss: 1.1564 - val_accuracy: 0.6033\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1320 - accuracy: 0.6193 - val_loss: 1.1046 - val_accuracy: 0.6457\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0805 - accuracy: 0.6457 - val_loss: 1.0480 - val_accuracy: 0.6668\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0110 - accuracy: 0.6796 - val_loss: 1.0048 - val_accuracy: 0.6956\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9858 - accuracy: 0.6899 - val_loss: 0.9968 - val_accuracy: 0.6874\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9629 - accuracy: 0.6966 - val_loss: 1.0203 - val_accuracy: 0.6841\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9539 - accuracy: 0.7049 - val_loss: 1.0020 - val_accuracy: 0.6892\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9407 - accuracy: 0.7087 - val_loss: 0.9434 - val_accuracy: 0.7103\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9229 - accuracy: 0.7163 - val_loss: 0.9302 - val_accuracy: 0.7125\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9081 - accuracy: 0.7202 - val_loss: 0.9238 - val_accuracy: 0.7145\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9053 - accuracy: 0.7209 - val_loss: 0.9727 - val_accuracy: 0.6956\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9059 - accuracy: 0.7207 - val_loss: 0.9219 - val_accuracy: 0.7198\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8988 - accuracy: 0.7202 - val_loss: 0.9103 - val_accuracy: 0.7203\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8950 - accuracy: 0.7235 - val_loss: 0.9266 - val_accuracy: 0.7151\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8952 - accuracy: 0.7240 - val_loss: 0.9380 - val_accuracy: 0.7186\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8904 - accuracy: 0.7241 - val_loss: 0.9308 - val_accuracy: 0.7017\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8924 - accuracy: 0.7232 - val_loss: 0.9576 - val_accuracy: 0.7135\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8910 - accuracy: 0.7248 - val_loss: 0.9212 - val_accuracy: 0.7164\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8913 - accuracy: 0.7226 - val_loss: 0.9448 - val_accuracy: 0.7128\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8868 - accuracy: 0.7254 - val_loss: 0.9781 - val_accuracy: 0.7064\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8903 - accuracy: 0.7265 - val_loss: 0.9118 - val_accuracy: 0.7243\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8838 - accuracy: 0.7266 - val_loss: 0.9189 - val_accuracy: 0.7207\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8858 - accuracy: 0.7273 - val_loss: 0.9325 - val_accuracy: 0.7043\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8796 - accuracy: 0.7299 - val_loss: 0.9257 - val_accuracy: 0.7265\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8772 - accuracy: 0.7296 - val_loss: 0.9381 - val_accuracy: 0.7128\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8780 - accuracy: 0.7312 - val_loss: 0.9201 - val_accuracy: 0.7279\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8760 - accuracy: 0.7322 - val_loss: 0.9247 - val_accuracy: 0.7201\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8740 - accuracy: 0.7289 - val_loss: 0.9323 - val_accuracy: 0.7209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6SPXJpB_G9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a9ab1e3-a544-4dba-ea4f-576c840923b0"
      },
      "source": [
        "model_adamax3 = create_model_optimizer(opt =tf.keras.optimizers.Adamax(learning_rate=0.1))\n",
        "adamax3 = model_adamax3.fit(X_train,\n",
        "           y_train,\n",
        "           epochs=30,\n",
        "           batch_size=32,\n",
        "           validation_data=(X_test, y_test))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 5.4623 - accuracy: 0.2468 - val_loss: 1.7159 - val_accuracy: 0.3786\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7037 - accuracy: 0.3518 - val_loss: 1.7220 - val_accuracy: 0.3113\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5373 - accuracy: 0.4063 - val_loss: 1.4478 - val_accuracy: 0.4134\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5996 - accuracy: 0.3688 - val_loss: 1.6230 - val_accuracy: 0.3269\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6486 - accuracy: 0.3456 - val_loss: 1.6073 - val_accuracy: 0.3501\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.6388 - accuracy: 0.3461 - val_loss: 1.6371 - val_accuracy: 0.3514\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6310 - accuracy: 0.3466 - val_loss: 1.5985 - val_accuracy: 0.3485\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7778 - accuracy: 0.2819 - val_loss: 1.6886 - val_accuracy: 0.3047\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7732 - accuracy: 0.2721 - val_loss: 1.7550 - val_accuracy: 0.2739\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.8136 - accuracy: 0.2707 - val_loss: 1.8106 - val_accuracy: 0.2725\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7804 - accuracy: 0.2720 - val_loss: 1.7706 - val_accuracy: 0.2799\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7758 - accuracy: 0.2734 - val_loss: 1.8001 - val_accuracy: 0.2815\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8060 - accuracy: 0.2758 - val_loss: 1.9960 - val_accuracy: 0.1779\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 2.0229 - accuracy: 0.1773 - val_loss: 1.9993 - val_accuracy: 0.1771\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.0068 - accuracy: 0.1801 - val_loss: 2.0049 - val_accuracy: 0.1798\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9941 - accuracy: 0.1827 - val_loss: 1.9925 - val_accuracy: 0.1901\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.9877 - accuracy: 0.1842 - val_loss: 1.9762 - val_accuracy: 0.1857\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.9975 - accuracy: 0.1843 - val_loss: 2.0199 - val_accuracy: 0.1815\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.0653 - accuracy: 0.1853 - val_loss: 1.9794 - val_accuracy: 0.1907\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.9833 - accuracy: 0.1848 - val_loss: 1.9755 - val_accuracy: 0.1883\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.9843 - accuracy: 0.1865 - val_loss: 1.9799 - val_accuracy: 0.1882\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.9800 - accuracy: 0.1834 - val_loss: 1.9740 - val_accuracy: 0.1811\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.9771 - accuracy: 0.1855 - val_loss: 1.9700 - val_accuracy: 0.1891\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.9863 - accuracy: 0.1859 - val_loss: 1.9968 - val_accuracy: 0.1820\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.9883 - accuracy: 0.1869 - val_loss: 1.9720 - val_accuracy: 0.1890\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.9777 - accuracy: 0.1869 - val_loss: 1.9791 - val_accuracy: 0.1880\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9805 - accuracy: 0.1864 - val_loss: 1.9746 - val_accuracy: 0.1769\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9805 - accuracy: 0.1874 - val_loss: 1.9746 - val_accuracy: 0.1900\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.1164 - accuracy: 0.1872 - val_loss: 1.9809 - val_accuracy: 0.1798\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9819 - accuracy: 0.1849 - val_loss: 1.9736 - val_accuracy: 0.1859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKrtRbl53z_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2b523c73-2740-4200-d7cd-297136278ca3"
      },
      "source": [
        "model_ftrl = create_model_optimizer(opt = tf.keras.optimizers.Ftrl(learning_rate=0.001))\n",
        "ftrl = model_ftrl.fit(X_train,\n",
        "           y_train,\n",
        "           epochs=30,\n",
        "           batch_size=32,\n",
        "           validation_data=(X_test, y_test))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 3.9980 - accuracy: 0.2880 - val_loss: 1.9546 - val_accuracy: 0.3377\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8242 - accuracy: 0.3701 - val_loss: 1.7360 - val_accuracy: 0.4006\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6648 - accuracy: 0.4300 - val_loss: 1.6127 - val_accuracy: 0.4552\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5644 - accuracy: 0.4702 - val_loss: 1.5292 - val_accuracy: 0.4913\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4918 - accuracy: 0.5019 - val_loss: 1.4642 - val_accuracy: 0.5184\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4303 - accuracy: 0.5269 - val_loss: 1.4103 - val_accuracy: 0.5378\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3774 - accuracy: 0.5457 - val_loss: 1.3665 - val_accuracy: 0.5541\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3345 - accuracy: 0.5589 - val_loss: 1.3304 - val_accuracy: 0.5685\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2976 - accuracy: 0.5722 - val_loss: 1.2967 - val_accuracy: 0.5784\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2657 - accuracy: 0.5818 - val_loss: 1.2667 - val_accuracy: 0.5846\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2353 - accuracy: 0.5891 - val_loss: 1.2396 - val_accuracy: 0.5910\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2105 - accuracy: 0.5956 - val_loss: 1.2187 - val_accuracy: 0.5988\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1900 - accuracy: 0.6045 - val_loss: 1.1999 - val_accuracy: 0.6059\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1721 - accuracy: 0.6159 - val_loss: 1.1844 - val_accuracy: 0.6134\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1560 - accuracy: 0.6213 - val_loss: 1.1696 - val_accuracy: 0.6184\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1413 - accuracy: 0.6259 - val_loss: 1.1558 - val_accuracy: 0.6227\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1278 - accuracy: 0.6299 - val_loss: 1.1432 - val_accuracy: 0.6269\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1155 - accuracy: 0.6343 - val_loss: 1.1320 - val_accuracy: 0.6306\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1038 - accuracy: 0.6379 - val_loss: 1.1213 - val_accuracy: 0.6338\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0930 - accuracy: 0.6410 - val_loss: 1.1107 - val_accuracy: 0.6372\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0831 - accuracy: 0.6440 - val_loss: 1.1016 - val_accuracy: 0.6401\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0737 - accuracy: 0.6473 - val_loss: 1.0928 - val_accuracy: 0.6428\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0649 - accuracy: 0.6498 - val_loss: 1.0848 - val_accuracy: 0.6459\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0566 - accuracy: 0.6522 - val_loss: 1.0775 - val_accuracy: 0.6480\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0490 - accuracy: 0.6549 - val_loss: 1.0709 - val_accuracy: 0.6501\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0418 - accuracy: 0.6571 - val_loss: 1.0641 - val_accuracy: 0.6518\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0350 - accuracy: 0.6590 - val_loss: 1.0580 - val_accuracy: 0.6544\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0287 - accuracy: 0.6610 - val_loss: 1.0524 - val_accuracy: 0.6562\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0228 - accuracy: 0.6637 - val_loss: 1.0470 - val_accuracy: 0.6571\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0172 - accuracy: 0.6650 - val_loss: 1.0420 - val_accuracy: 0.6583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozMWTu9w7kGW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5e532446-6151-4293-ab07-afae8723a3af"
      },
      "source": [
        "model_Adadelta = create_model_optimizer(opt = tf.keras.optimizers.Adadelta(learning_rate=0.01))\n",
        "adadelta = model_Adadelta.fit(X_train,\n",
        "           y_train,\n",
        "           epochs=30,\n",
        "           batch_size=32,\n",
        "           validation_data=(X_test, y_test))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 34.3878 - accuracy: 0.1534 - val_loss: 7.0229 - val_accuracy: 0.2106\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 4.1023 - accuracy: 0.2061 - val_loss: 2.9447 - val_accuracy: 0.1997\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.6436 - accuracy: 0.2117 - val_loss: 2.4491 - val_accuracy: 0.2377\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3430 - accuracy: 0.2443 - val_loss: 2.2632 - val_accuracy: 0.2591\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.2085 - accuracy: 0.2652 - val_loss: 2.1621 - val_accuracy: 0.2758\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.1228 - accuracy: 0.2828 - val_loss: 2.0910 - val_accuracy: 0.2904\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.0580 - accuracy: 0.2986 - val_loss: 2.0346 - val_accuracy: 0.3065\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.0041 - accuracy: 0.3153 - val_loss: 1.9870 - val_accuracy: 0.3210\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.9562 - accuracy: 0.3300 - val_loss: 1.9444 - val_accuracy: 0.3349\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.9147 - accuracy: 0.3442 - val_loss: 1.9050 - val_accuracy: 0.3480\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8771 - accuracy: 0.3558 - val_loss: 1.8704 - val_accuracy: 0.3601\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8430 - accuracy: 0.3675 - val_loss: 1.8384 - val_accuracy: 0.3726\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8105 - accuracy: 0.3796 - val_loss: 1.8084 - val_accuracy: 0.3830\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7801 - accuracy: 0.3905 - val_loss: 1.7781 - val_accuracy: 0.3940\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7496 - accuracy: 0.4002 - val_loss: 1.7479 - val_accuracy: 0.4044\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7193 - accuracy: 0.4110 - val_loss: 1.7175 - val_accuracy: 0.4169\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6906 - accuracy: 0.4214 - val_loss: 1.6916 - val_accuracy: 0.4263\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6660 - accuracy: 0.4310 - val_loss: 1.6704 - val_accuracy: 0.4333\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6443 - accuracy: 0.4391 - val_loss: 1.6512 - val_accuracy: 0.4388\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6243 - accuracy: 0.4462 - val_loss: 1.6348 - val_accuracy: 0.4466\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6064 - accuracy: 0.4538 - val_loss: 1.6185 - val_accuracy: 0.4550\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5892 - accuracy: 0.4595 - val_loss: 1.6041 - val_accuracy: 0.4611\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.5733 - accuracy: 0.4651 - val_loss: 1.5906 - val_accuracy: 0.4668\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.5581 - accuracy: 0.4707 - val_loss: 1.5769 - val_accuracy: 0.4746\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5444 - accuracy: 0.4777 - val_loss: 1.5634 - val_accuracy: 0.4796\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5301 - accuracy: 0.4822 - val_loss: 1.5513 - val_accuracy: 0.4852\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5172 - accuracy: 0.4879 - val_loss: 1.5391 - val_accuracy: 0.4906\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5038 - accuracy: 0.4929 - val_loss: 1.5271 - val_accuracy: 0.4963\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4912 - accuracy: 0.4987 - val_loss: 1.5159 - val_accuracy: 0.5015\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4789 - accuracy: 0.5045 - val_loss: 1.5053 - val_accuracy: 0.5039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzxNrd9c46vG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3501f66a-80f6-44c2-eddd-705690b11b09"
      },
      "source": [
        "model_RMSprop = create_model_optimizer(opt = tf.keras.optimizers.RMSprop(learning_rate=0.001))\n",
        "rmsprop = model_RMSprop.fit(X_train,\n",
        "           y_train,\n",
        "           epochs=30,\n",
        "           batch_size=32,\n",
        "           validation_data=(X_test, y_test))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.8343 - accuracy: 0.5268 - val_loss: 1.2103 - val_accuracy: 0.6392\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1262 - accuracy: 0.6528 - val_loss: 1.0780 - val_accuracy: 0.6995\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9754 - accuracy: 0.7069 - val_loss: 0.9878 - val_accuracy: 0.7143\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9254 - accuracy: 0.7233 - val_loss: 0.9672 - val_accuracy: 0.7288\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8870 - accuracy: 0.7319 - val_loss: 0.8987 - val_accuracy: 0.7321\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8784 - accuracy: 0.7388 - val_loss: 0.8968 - val_accuracy: 0.7301\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8582 - accuracy: 0.7519 - val_loss: 0.9154 - val_accuracy: 0.7642\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8340 - accuracy: 0.7709 - val_loss: 0.9081 - val_accuracy: 0.7672\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8261 - accuracy: 0.7784 - val_loss: 0.9354 - val_accuracy: 0.7656\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8234 - accuracy: 0.7862 - val_loss: 0.8838 - val_accuracy: 0.7781\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8234 - accuracy: 0.7872 - val_loss: 0.8679 - val_accuracy: 0.7706\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8197 - accuracy: 0.7891 - val_loss: 0.9418 - val_accuracy: 0.7818\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8157 - accuracy: 0.7897 - val_loss: 0.9103 - val_accuracy: 0.7742\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8209 - accuracy: 0.7893 - val_loss: 0.9369 - val_accuracy: 0.7830\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8097 - accuracy: 0.7914 - val_loss: 0.9797 - val_accuracy: 0.7882\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8114 - accuracy: 0.7921 - val_loss: 0.9117 - val_accuracy: 0.7765\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7931 - accuracy: 0.7947 - val_loss: 0.8864 - val_accuracy: 0.7868\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7933 - accuracy: 0.7962 - val_loss: 1.0289 - val_accuracy: 0.7933\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.7774 - accuracy: 0.7974 - val_loss: 0.8890 - val_accuracy: 0.7861\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7588 - accuracy: 0.7987 - val_loss: 1.1520 - val_accuracy: 0.7674\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7780 - accuracy: 0.7971 - val_loss: 0.8749 - val_accuracy: 0.7739\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7823 - accuracy: 0.7974 - val_loss: 0.8493 - val_accuracy: 0.7825\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7867 - accuracy: 0.7940 - val_loss: 0.9221 - val_accuracy: 0.7814\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8070 - accuracy: 0.7925 - val_loss: 0.8943 - val_accuracy: 0.7911\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8230 - accuracy: 0.7935 - val_loss: 0.9242 - val_accuracy: 0.7819\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8347 - accuracy: 0.7919 - val_loss: 1.0057 - val_accuracy: 0.7797\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8449 - accuracy: 0.7906 - val_loss: 1.0188 - val_accuracy: 0.7817\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8333 - accuracy: 0.7925 - val_loss: 1.1100 - val_accuracy: 0.7760\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8374 - accuracy: 0.7902 - val_loss: 0.9981 - val_accuracy: 0.7775\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8467 - accuracy: 0.7904 - val_loss: 1.1207 - val_accuracy: 0.7754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiYNwtsQBrG4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1530649-0f4e-4308-e014-dd85cc8d830f"
      },
      "source": [
        "model_RMSprop2 = create_model_optimizer(opt = tf.keras.optimizers.RMSprop(learning_rate=0.01))\n",
        "rmsprop2 = model_RMSprop2.fit(X_train,\n",
        "           y_train,\n",
        "           epochs=30,\n",
        "           batch_size=32,\n",
        "           validation_data=(X_test, y_test))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 3.2986 - accuracy: 0.1592 - val_loss: 2.0342 - val_accuracy: 0.1704\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 2.0087 - accuracy: 0.1917 - val_loss: 1.9801 - val_accuracy: 0.1933\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 2.0352 - accuracy: 0.1920 - val_loss: 2.0043 - val_accuracy: 0.1784\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 2.0091 - accuracy: 0.1852 - val_loss: 2.0749 - val_accuracy: 0.1812\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.0158 - accuracy: 0.1855 - val_loss: 1.9717 - val_accuracy: 0.1924\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9946 - accuracy: 0.1851 - val_loss: 2.0001 - val_accuracy: 0.1907\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 2.0160 - accuracy: 0.1830 - val_loss: 1.9967 - val_accuracy: 0.1822\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9910 - accuracy: 0.1852 - val_loss: 1.9820 - val_accuracy: 0.1855\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9805 - accuracy: 0.1858 - val_loss: 1.9711 - val_accuracy: 0.1900\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9903 - accuracy: 0.1895 - val_loss: 2.0316 - val_accuracy: 0.1942\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9967 - accuracy: 0.1905 - val_loss: 1.9891 - val_accuracy: 0.1875\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9945 - accuracy: 0.1911 - val_loss: 1.9909 - val_accuracy: 0.1943\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9894 - accuracy: 0.1899 - val_loss: 2.0099 - val_accuracy: 0.1936\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9788 - accuracy: 0.1888 - val_loss: 1.9682 - val_accuracy: 0.1919\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9752 - accuracy: 0.1880 - val_loss: 1.9729 - val_accuracy: 0.1878\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9786 - accuracy: 0.1895 - val_loss: 1.9606 - val_accuracy: 0.1906\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 2.0407 - accuracy: 0.1841 - val_loss: 2.0573 - val_accuracy: 0.1867\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.0023 - accuracy: 0.1903 - val_loss: 1.9676 - val_accuracy: 0.1913\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.9752 - accuracy: 0.1908 - val_loss: 1.9863 - val_accuracy: 0.1911\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9634 - accuracy: 0.1927 - val_loss: 1.9423 - val_accuracy: 0.1931\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9555 - accuracy: 0.1918 - val_loss: 1.9627 - val_accuracy: 0.1815\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9563 - accuracy: 0.1898 - val_loss: 1.9580 - val_accuracy: 0.1910\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9563 - accuracy: 0.1930 - val_loss: 1.9564 - val_accuracy: 0.1933\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9538 - accuracy: 0.1940 - val_loss: 1.9461 - val_accuracy: 0.1960\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9491 - accuracy: 0.1909 - val_loss: 1.9462 - val_accuracy: 0.1951\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9425 - accuracy: 0.1925 - val_loss: 1.9424 - val_accuracy: 0.1913\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 1.9412 - accuracy: 0.1875 - val_loss: 1.9348 - val_accuracy: 0.1892\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 1.9386 - accuracy: 0.1901 - val_loss: 1.9346 - val_accuracy: 0.1952\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9390 - accuracy: 0.1903 - val_loss: 1.9361 - val_accuracy: 0.1930\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9392 - accuracy: 0.1905 - val_loss: 1.9345 - val_accuracy: 0.1931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RxwY937aMKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_adam = pd.DataFrame.from_records(adam.history)\n",
        "df_adam['epoch'] = df_adam.index.values\n",
        "df_adam['model'] = 'adam'"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zs2hEUbb6-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_adam2 = pd.DataFrame.from_records(adam2.history)\n",
        "df_adam2['epoch'] = df_adam2.index.values\n",
        "df_adam2['model'] = 'adam2'"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjKwDxGGeqoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_ftrl = pd.DataFrame.from_records(ftrl.history)\n",
        "df_ftrl['epoch'] = df_ftrl.index.values\n",
        "df_ftrl['model'] = 'ftrl'"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crredEPMe0QU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_adamax = pd.DataFrame.from_records(adamax.history)\n",
        "df_adamax['epoch'] = df_adamax.index.values\n",
        "df_adamax['model'] = 'adamax'"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyRM0HtsfE6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_adamax2 = pd.DataFrame.from_records(adamax2.history)\n",
        "df_adamax2['epoch'] = df_adamax2.index.values\n",
        "df_adamax2['model'] = 'adamax2'"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WVDOJHifJmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_adamax3 = pd.DataFrame.from_records(adamax3.history)\n",
        "df_adamax3['epoch'] = df_adamax3.index.values\n",
        "df_adamax3['model'] = 'adamax3'"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jjZB0HneUJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_adadelta = pd.DataFrame.from_records(adadelta.history)\n",
        "df_adadelta['epoch'] = df_adadelta.index.values\n",
        "df_adadelta['model'] = 'adadelta'"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_atbFUBdTRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_rmsprop = pd.DataFrame.from_records(rmsprop.history)\n",
        "df_rmsprop['epoch'] = df_rmsprop.index.values\n",
        "df_rmsprop['model'] = 'rmsprop'"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJP6UmcfdEdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_rmsprop2 = pd.DataFrame.from_records(rmsprop2.history)\n",
        "df_rmsprop2['epoch'] = df_rmsprop2.index.values\n",
        "df_rmsprop2['model'] = 'rmsprop2'"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0YU3wg9cGwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_total = pd.concat([df_adam, df_adam2, df_ftrl, df_adamax, df_adamax2, df_adamax3, df_adadelta, df_rmsprop, df_rmsprop2])"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzLK1CT4Iszo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "96313d2c-2c29-43b2-8512-f97561cdecc9"
      },
      "source": [
        "sns.lineplot(x='epoch', y='val_accuracy', hue='model', data=df_total);"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEGCAYAAABlxeIAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9d3hc1bnv/9nTm8qoF6valix344aDDcY0m55CJwVOLoeQkHZvEnJugp1yIIdz8uOGdOIQUgwhBEI3HQy4V7lILuq9zahM3zN71u+PLY0lW7JlWyO57M/zrGeXWbP3OyPN+137XWu9SxJCoKGhoaGhoZtoAzQ0NDQ0zg40QdDQ0NDQADRB0NDQ0NDoRxMEDQ0NDQ1AEwQNDQ0NjX4ME23A6ZCWliYKCwsn2gwNDQ2Nc4qdO3d2CSHSR3r9nBSEwsJCduzYMdFmaGhoaJxTSJJUf6LXtZCRhoaGhgagCYKGhoaGRj+aIGhoaGhoAJogaGhoaGj0owmChoaGhgagCYKGhoaGRj+aIGhoaGhoAOfoPAQNDQ2Ns5WwEmVXfTe7GnpItZsoTLNTmGYj3WFGkqSJNu+EaIKgoaFxUvxyBLdPptsXxuULoddJFKXZyUmyotONjZOLRgU9gTBd3hCdnlBs2xk7lun0hOj2yTgsBlLtJtISzKTZTaQ6zKQ5zKQ6TKQ5TP37ZswGHX5ZwS9H8IWO2coK/pC6DUUU8lNsTMtKpDDVhkF/asGTepePjw53suFwF5uru/DJynF1HGYDhWk2ClPtFKWppTDNTlGqHYfFQI8/TI9fpicQptsnq8cBmW5/OPZat1/mO9eUMr8gZUy+82PRBEFD4zwmrERx+2QCskIwohCQFQJhhWBYISBHCYT7j2UFv6zQ3e903D65XwBk3H6ZYDg67PXNBl3MuRWn2ylKc1CUZmdyup1kmylWTwiB2yfT0hOkpTdAa0+A1t4gLb1BWnrU4w5PiEj0+AW7THod6Qlm0hwmcpMtzMhJxBuM4PKFqGzpo9MbwhOMjNl3ZjboKMlMYFpWAqVZCZRlJzItK4FUhzlWxxuKsKmqi4+OdPLxkS7qXX4AJjmt3DQvl0unprO4KIW+YJjaLh91XT7qXH5qunzsberljX2tDPNRh8Wgk0i2mXDajCTbjESU+C1qJp2LK6YtWLBAaKkrNDSOEgwr1HT6ONLhoarDS1WHlyMdXuq6fMM62ZFIsBhIsZtw2kyk2I8W9diI02Yi1WFCjghqu3zUdnmp6fRR2+Wjwe0fci+nzUh+io3eQJjW3iChyFBRMel1ZCdbyE6ykJNkJTPJQrrDTHqCuV8A1G2ixXDSUEsoouD2ybi8Mp3eEC6vjMsbIhSJYjcbsJv02Aa2JgM2kx67Wd23mwwY9BK1XT4Otnk42NrHoXYPla0euryh2D3SE8xMy0ogFFFDQpGowGbSs6Q4lUtL0rm0JJ3CVNuowkJyJEpjt5/aTh91Lh9+WcFpM5LU7/idNhNJViNOuwm7ST9moSZJknYKIRaM+Hq8BUGSpJXALwA9sFYI8bNjXs8H/gwk99d5SAjxxomuqQmCxtmOEIIjHV621rjY09hLgsVAbrKVXKc1tk21m0b9Q1eiApevP4TiCdHRF6K6y0tVu5eqTi8Nbj8DP2WdBIWpdiZnOJia4SAn2YrNpMdq1GPp31qNeqwD5/r3LQbdKYdKBhNWojS6/TGBqOny0ugOkGQzkpNkISfZSnaSlZxkC9lJ6ucfq3BTvOj0hDjU5uFgWx8H2zxUtvahkySWTk1j2dQ05hc4MRv0E23mqJlQQZAkSQ8cBq4CmoDtwB1CiIpBdZ4EdgshfitJ0nTgDSFE4YmuqwmCRrzwhSKYT8MxRqOCQ+0etta42FLjZludG7dPBiDNYSYYVvCGhoY1LEYdOcmqQExyWslJsmI16WOx8oHYeacnhNsXOi7EYNKr4ZopmQ6mpDuYmulgakYChWm2c8pJaYwfJxOEePchLAKqhBA1/cb8HbgJqBhURwCJ/ftJQEucbdLQGEJrb4A397exfl8b2+vdAKTYTLHQRUaChYxEM+kO86CtBV8owpYaF1tr3Wyvc9PjDwNqHPny0gwWF6dwcVEqeSlWJEmiNxCmuTtAc0+A5m6/uu0J0Nwd4J3WPrq8qoDEYuYJZnKTrczNS1ZtcRy1Kd1hISfZckYteg2NY4m3IOQCjYOOm4DFx9RZA7wtSdKDgB24crgLSZJ0H3AfQH5+/pgbqnFh0ej28+b+Nt7Y38ruhh4ASjMT+OryKeh1Ep1eNSzT6QlS3eGl0xsiPEJnXkGqjaunZ7K4KJXFxSlMctqGrZdkNZJkNTI9J3HY14NhhVA4SqL15DFzDY14cDaMMroDeFoI8XNJkpYAf5UkaaYQYkgPlBDiSeBJUENGE2CnxjlObZeP9ftbWb+vjX3NvQDMyEnkO9eUsnJmFpPTHSO+NxoV9AbCdAzE8D1BDHodiwpTyEqyjIl9lv54/kgEg0E6Ojro7OzE7XaTlJREZmYmmZmZWCxjY4PGhU28BaEZyBt0PKn/3GD+DVgJIITYLEmSBUgDOuJsm8Z5hhCCbn+Ytt4g7Z4g7b1B2vtCtPUF2d3QzcE2DwBz8pL5/qpprJqZTX7q8K35Y9HpJJx2E067iakZdjweD5IkkZg49o44FArR2dlJZ2cnHR0dMRHo6+uL1ZEkicH9f06nk6ysLDIzM8nKyiIrK4ukpKTz4kkjEonQ3NxMbW0tdXV1tLS0kJKSQkFBAfn5+RQUFOBwjCzmGqMn3oKwHZgqSVIRqhDcDtx5TJ0G4ArgaUmSygAL0BlnuzTOYfxyhK21brbUuGhyB2jvC9LWF6SjL4SsHD9ePtVuYnK6gx9eP52VM7PITbae9B6yLNPd3T2kuN1uuru76enpQVHUiUeZmZmUlpZSUlJCTk4OOt2px/Tdbje1tbXU1NTQ3NxMT09P7DWDwUBaWhqFhYWkp6eTkZFBeno6ycnJeDwe2tvbaWtri5XKysrYey0WC1lZWRQUFLBo0SLsdvsp2zYRKIpCS0sLdXV11NbW0tDQQCSidshnZWUxa9YsXC4XO3fuZOvWrQCkpqbGxCE/Px+n03leiOF4Mx7DTq8F/h/qkNKnhBD/KUnSj4EdQohX+kcW/QFwoHYwf1cI8faJrqmNMrqwUKKCfc29fNI/CWhXgxtbNECuwYvNbseSlEZachKZSVYyEy1kJlrISjKTmWghPcF80hE3Pp+PxsZGGhoaaG5uxuVy4fV6h9Qxm804nU6cTicpKSk4nU5CoRCHDx+moaEBIQQOh4OSkhJKS0spKirCZDKNeL8BAaipqYkJQEJCAvn5+WRmZsacv9PpPCWRCYVCdHR00NbWRnt7O62trTQ3N2M0GlmwYAFLliwhMXH4PoyxIhqN0tHRQWNjI21tbQghMBgM6PV6DAbDiPt9fX0xAZBltYM9IyODwsJCioqKKCgowGY7+kQXiURobW2loaGB+vp6GhoaCAaDgPpdFhQUxMJpZrMZs9kc2x98bvD3K4QgEokQCoWQZZlQKHTcvsFgIDU1ldTU1CH2nAtM+DyEeKAJwrlFb28v1dXVOBwOsrOzSUhIOOl76l0+Pj7SxSdHuthU3YUvKJOl62N2QoBM0Q2yb0h9u91OdnY2OTk5sW1iYuJxrcRoNIrL5aKhoSEmAm63OrJIp9ORnZ1Nenp6zOkPCIDVah2xxen3+zly5AiHDh2iqqoKWZYxGAwUFxdTWlpKcXExLpcrJgBtbW2AKjKFhYUUFxdTXFxMWlpaXFq1nZ2dfPzxx+zbtw+dTsdFF13EJZdcQnJy8phc3+fz0dTUFCvNzc0xh261WtHr9SiKQiQSIRKJcCKfM/A0NCAApxIKikajdHZ2xsShvr4ej8dz0veZTCbMZjPhcBhZlolGh5+VPRxWqzUmDgMlJSWF1NTU4xoEiqIQDodjJRKJxPZB/X8YsMVkMmE0Gsf8/0ETBI0Jwe12U1FRQWVlJc3NQ7uNBoQhOzubrKwssrOz0VnsbK52seFwF59UddLoDmAnxAyHj1KrF4O/C6EoGI1GioqKKCkpobi4GJ/PR0tLC62trbS0tNDZ2RlzODabjZycHHJycjAYDDQ1NdHY2EggEADUH3NeXh75+fnk5eWRk5OD0Wg8o88diUSor6/n0KFDHD58eEj4R6/Xk5eXFxOA7Oxs9Prxmy/gdrvZuHEju3fvBmDOnDksXbqU1NTUUV9joH+jtbU19n0OCKokSWRlZTFp0iTy8vKYNGnSsKGbaDQaE4fBQmGxWEbVWDgVwuEwwWCQUCg04nagGI3GIQ554Ani2P1wOIzL5cLlcuF2u2P7g/t4gFiIbsD5n4rQgPp9Dnf/5cuXn/ZIS00QNMaNjo4OKisrqaiooL29HYDs7GymT59OSUkJwWCQ1tbWWBnsvENCjytqx6NTZ9amKC7CXtWZOp1Opk6dSklJCQUFBSd02rIs097ePqxIDMSZ8/LyyMvLi1uLfAAhBB0dHdTV1cXuPVIYaTzp7e1l06ZN7Ny5E0VRmDFjBsuWLSMzMzNWJxQK0dXVFevQHtj29vbG6tjt9iHOPycn56z4fBOFLMtDBKKnpwdJkjAajbFiMBiGPQZOGKYavH/11VdTUFBwWjZqgqAxItFolFAohM/nw+/3x0ogEECn08X+aQceX4c77u3tjT0JdHV1AZCXl0dZWRllZWU4nc7Y/dr7gnx0uJOPjnTxyZFO+vwhnDo/s52CYnsYu+LB2+NCCEFBQUFMBFJTU8/IccuyjKIoWK0n70y+kPB6vWzevJnt27cjyzJTp04F1BDTsU82aWlpQzq1MzMztY7bcxBNEDQAOHz4MLt37x7i+P1+/wnjuaNFkiQKCgqYPn0606ZNi3VaCqF2Br9T0c47Fe2xYZ/pCWaWTU3jspJ0lk5JG5JFUlEUFEW5oFua443f72fr1q3s2rULq9Uac/oDW6fTOa6hLY34oQmCBtu2beONN94gISGBlJQUbDbbkGK324ccW61WotHokA4wWZaH3TebzZSUlMTipaGIwpYaN+9UtPFuRQdtfUF0EiwsTOHyaRlcOjWdsuwErWWpoTEBTHQuI40JJBqN8t5777Fx40ZKS0v57Gc/e0ot79GGWHoDYV7e08zbFe1sONSJNxTBZtJz6dR0rpqeyYppGTjtWotfQ+OUUcIQ9kM4CJEAhAOQmAuW+Awd1gThPCUSifDSSy+xf/9+Fi5cyKpVq05r0tRIeEMRXitv4dW9LWytcROJCtIcZm6Yk81V0zP51OS0E6Zh0NDQANorYOvvoHWP6vTDgX7HH1SFQBy/8hq3PwPTrouLOZognIcEAgGee+456urquPLKK7nkkkvGJEQjhGB3Yw/PbWvk1b0t+GWF4jQ7X15WzFXTM5mXl3zW57fX0DgjhABFBoP55HVHIhqFqndhy2+g5gMwWKHwEjA5wGgFgwWMNjBa1NeM1kH7FsiZN3af5xg0QTjP6OnpYd26dbhcLj7zmc8we/bsM76m2yfzr93NPLe9gcPtXmwmPTfMzuG2RXnMy0vW+gM0Lgwat8NLX4HuOihYApOvgClXQOZMGM1vQPbBnmfUJwJXFSRkwxUPw/x7wBafNZJPFa1T+Tyira2NdevWIcsyt99+O0VFRad9rWhUsKnaxd+3N/D2gXZkJcrcvGRuX5jH9XNycJi1toTGBUI4CB8+CpueUOP3ZTdA7UfQvl993ZEFk1eo4jB5xfHOvbcJtj0JO5+GYC/kXARLvgrTbwL9mU2EPFW0TuULhOrqap577jksFgv33nvvkElGp0JAVnhqYy3PbmugqTtAss3IXRfnc9vCPKZlxTcHjobGWUfzTnjpAeg8CBd9Ea7+6dEO3b5WqH5fDf8cXg/lzwCSGtKZciVkz4H9L0DFy4CAshvh4gcgb9HonigmAO0J4TygvLycl19+mfT0dO68806SkpJO6zrvVLSz5pUDNPcE+NTkVG5flM/V0zO1zmGNC49ICDY8Bp88Do5MuOmXqpMfiagCLXtUcah+D5q2g4iCOQnmfwEW3QfJE7+wl/aEcBYRjUbx+/34fL6TlkgkgslkGpJb5dg8KyaTib6+PrZs2UJRURG33XbbaS2U0uj286NXD/BuZQclmQ6eu+9iFhePPr+NhsZ5Rcse9amg4wDMvQuueQSsJ0kEqNPDpPlqWf49CHRD617InQ/mc2etBk0Q4kw0GqWhoYE9e/Zw4MCBWGbDwUiShN1uj00Qy83NxWg0IstyLIdJX19fLKfJwMSwAWbPns2NN96IwXBqf85QROEPH9Xwy/er0Osk/uPaadxzSRFGbZ1ejfEiIkNPPbiq1RZ19hxIzBnXkIoSjtJQ6SYty0TCgV/Dx/8DtjS44zkoXXnK1wsFIhzZ7qe2PBmHs4mMggTS8xNIzXWgN5zdvy1NEOJEd3c35eXllJeX093djclkYubMmWRnZ8ec/0CxWCynPEcgGo0iyzKRSOS0Vov65EgXD7+8n5ouH9fOyuKH108nO0nL9XPWEvKqjrO7DrrrwdcBMz8LWbPG5vpCQMNmdSKUyQEmO5hsR/f1ptN30lFF7Vh1VYG7Rt26qtVtTwM94XTKfTfijuRj0+/AZg5hc9qxpadjy83DVliKLTsHa4JpTIc1CyGoLe9i4wtV9HWqGXBzjA6mTvkuU+68B0t6xildq7Wql4qNLVTv7CASjpKUYaW9tpeKT1oA0BkkUnMcMYHIKEgkJcd+VomE1ocwhsiyTGVlJbt376aurg6AoqIi5s2bx7Rp086K/DztfUF+8loFr+1tpSDVxo9unMHy0tH/45/PBL1h9n7QSNAbJipAREWsRIVARI+ei0YFBpOexDQLiWlWktKsJKZbsSebR++0hIBIiGjQQ7C7l0C3B1O0mwSlvt/59wtATz34Xce8WVId9MIvw+X/9+QhjRPRtAPefEiNe4+EztAvEgMCYUZdz6r/c4y0Hw2rYqDIR69ltEPqZDqMi9jVupjqplT0eomMbB2BviB+v4QcOX70jUQUiyWCI9FA8TQjM+ZbsSZa1DkBeqNqk8GsitfANhICb5vaAexpBU8beFpxtfj5uGIWzX35OI1NLLI/Q4+uhMPcSLdbh04vkT8jlZJFmRTOTsNoGr4fzd8nc3BLK5UbW+lp92O06ClZlMX0S7JJz1dTefd1Bels8NBR39e/9SAHIv1fq0RaroOEFAuKIogqgqgS7d/270fFkOPld04jb/rpDVPVchnFGSHEkJCQLMs4nU7mzp3LnDlzxmwRkjMlokT58+Z6Hn/nMLIS5YHlk7n/ssnx7TBWwtB1GNr2g+sIZJSpHXOW0+v0HkBEBeGQghKJYnGc+SIiQggOb23jk39WEfKFMdkM6HQSkiQh6SQkHUOPJZCIEA6E8fZFEeLo/XW6KAm2EEk2P4lWD4nmHhzGbiLBCP6ggUDQiF+2EAhbCUQc+KNJBKMJCAb+DlEKzTuY41hPbnovUkoBJBeAsxCcBZDcv5V08MEjsOOPYE2BK9eo8e4RnjSFUL+zoC9MyBch4JUJdrYT3PUaweYjBPVZhNIXYU5MwGYNYzeHsJn82Iw+bIZerLpedGGfOpY+7FMd7YAoDRDbH3Re0kPSJEidDKlTECmTaWw0suvtRpoPdWOyGph5WS6zL5+EPenoZK+wrBBw9eCrPYS/sQZ/Wyt+Vw9+T5TuSA6t4RnoCDPV8gmz7G+Qaawa1d86EE1gm+9uDviuxKQPsWjyXmZO86BLzoE5dyBsKXQ1ejm8vZ0j29vx9YQwmvUUz0unZFEmk0qdIEk0Vrqp/KSF2vIuolFB9pQkpl+Sw+SLMjCaT/ybEkLQ2xmIiUNnfR9+TxidXkKvl9DpJXR6Xf/22H2JOSvyyCg4vRF/miDEib6+PsrLy9m9ezdutxuTycSMGTOYO3cu+fn5Z81krbAS5V+7m/nNB1XUufxcVpLOj2+aQUHqGK+v63er47Lb9vdv96lD9Qa1DBVhIEQicvZS5EmXI2dejGxMRw5ECAUihIMRQgEFORghHFQIByPIQYVw6Og5OaQQCR2dzp9ZYGXBdZMpmJV+Wt95T4efDc8coulgN5lFiVx+9zRScweF4MJB6Kwc9Ln6t8Ge/s+kx6uk0adk9pcs+pQM+pRsepVMQtGh4TyDPozNFMJqCWOzKlitYHNIWB0GrAkm3L129u+VCPoUUnPtzF6RR8nCTAwjtFBpLYc3vgONW2HSQrj2vyFnHr6eELV7u6gt78LV5CHgCxONjPxbN1v1mKxGQoFIrPU6GEknYU0wYks0YU8y40ixkJJtw5ltJyXbji3RdMLvP6pEqdrVwe63G+hq9GJPNjPnijxmLM3BZD2FyHXIC52HcLf2sX+HwsEKiXBYIiNDZnZZH1MKetCLICghtX9Cb4KELBR7NvsrE9m+IYAcijLz0lwWXV+ExTHyPIBoVNBypIcj29qo3t1JyB/BmmhCr5fwdoewJhgpvTib6Zdk48w6N9arnnBBkCRpJfAL1DWV1wohfnbM648Dl/cf2oAMIcQJm9UTJQiRSCSWRrqqqiqWt3/evHmUlZVhNp/BdPYxJhRR+OfOJn77YTVN3QFm5CTyzStLuLIs48zFKiJDyy6o+1gNN7Tth76mo6/bMyBrJmTOJJI2i331RezeGCTgPb5D/Vj0Rh0mix6jxaBuzXpMehmj8GJSujGGuzCG2jAFm4gqgv3+a/BGM0g31bEg+yOKMjuRHGlgTwN7OthS1a05gaOhDFAU2L0DdmyR0Ovg4qVRZsyOohP9TzXtB1TH33XkaD4Zox0yp6szUzNnQEqxel2j7Wi83WhTS39LPeQP4+1WW5nWBNNJW48AkbDC4W3t7H2/CVezF4vDyIxlOcy6bBL25GH+x6JRRPnfcb3+e+p6plKrv5aOXvUnlJhuJWdqMlaHEYvNgKW3HMuhZ7AE67GULMZyxdex5BShGzSQICIr+PtkfL0y/r4Q/l4ZX28If5+Mv1fG3yfT1xUg5D8qHCarYYhADGwtdiOVm1rZ824DHlcQZ5aNeVfnU7Ioa0xi53IgwsEtbez7sImedj/WBCPTl+Yw89JcHE51xF3dvi42/rOKnnY/edNTuORzU0jNObV+NyUcpf6Ai8Pb2lHCCqUXZ1M0J+2siv+PhgkVBEmS9MBh4CqgCdgO3CGEqBih/oPAPCHEvSe67ngLQkdHB7t376a8vBy/309CQgJz585l7ty5p7T84HgQDCs8u62B32+ooa0vyNy8ZL5+xRQuLz0DIVDC0LJbnZ1Z94naGg371dfSp6kdm5kz+0VgFiRkIqKCw9vb2fpyDR53kPzpKWRPTcZsVR29SXFh6tyBqeVjTG2bMOHBZLeiL7kCUqeoTrmjUnXIkcBRWxInQcY09b5pU1HkMIcqYOeBLPr8dlKtHSxIfYvJhg+Rgu5hP06rXMqHfQ/gjuQz2byJZYlrseu7h1ZKyo+JWmzrLBoxJBMPhBA0H+5h7/uN1O7tQidJTFmQwewVeWQWJqIoUVqO9FBX3kXt3i48riAgyDQepsixn6IVS3CuuB1Jb1DTLrz5EDTvgOy5sPJnavqFM7DN3yfT3erD3eqnu9VHd5sPd6uPgGeQ8EuAgKziJC66Jp/CWWlIcch3JaKCpoPd7P2wibp9XUiSRPHcNMIhhYYDbpIyrCz93FQKZp3ZYkvnOhMtCEuANUKIa/qPvw8ghHh0hPqbgNVCiHdOdN3xEIRgMMj+/fvZvXs3zc3N6HQ6SktLmTdvHpMnTz7rFgzxhSKs21rPkx/V0uUNsagoha+vmMolU07jB6BE1OyLAwLQsEWNGwNkTIfCZVC4VC3D5GBpOuhm04vVdDZ4SM9PYMlnJpM37QSdYMFeqHoPDr8JR95Wx3An5kJ6KaSX9QtAmXo8QtrfqBLlyPZ2dqyvp6fdjzPbzoJrJjGlTIcu4IKQh1AINn8Q5sDuCI5EiUuvsVBUYuiPd/d/Rzqd6vjPpJM2DvR2+tn3QTMVm1oIBxVSJznwuILIgQh6o468shSKZqdRMCsVe+AIrP8u1G9UZ82mFKszZh1ZcOVqmH17XIUt4JXpbvXjbvXhcQcpnJlK9pTx+z77ugLs39BMxcYWRFSw4LoiZl8+6ZxrzceDiRaEzwErhRBf7j/+PLBYCPG1YeoWAFuASUIMl/P1KPEWhN7eXn7/+9/j9/tJT0/noosuYvbs2bFFYM4mPMEwf9lcz9qPa+j2h1k6JY0HV0w5/Yll3fXwx6vVkRmgOuLCpVC0DAouUUMxI+Bq9rLpxWoaDrhISLGw+KZiShZmnlqLUImoTwTm01tsPRoVVO/sYMf6OtwtPpIyrMxfWYjBpOOTfxwh4JGZvSKPRTcUYbKce6Ou5UCEys2tHNnejjPbTtHsNPLKUo4PRQkB+/4Jb/9AFdhPPQhLv3VOTZI6U5RwFIHAoM20j3EuCcL3UMXgwRGudR9wH0B+fv78+vr6uNgshODZZ5+ltraWu++++6zqID6Wd9+rY/uL1QSFQEo1sXhBNgvnZ5OSYz+98dpRBZ6+To2fX/84FF0GjvSTvs3bHWTrq7Uc3NyK2Wpg/qpCZi3PndAfoogKavZ0sv2NOlxNXgDS8xNYflfpaY/QOCcJB9WO/TgtqKJxbjHRqSuagbxBx5P6zw3H7cBXR7qQEOJJ4ElQnxDGysBjOXDgAIcPH+bqq6+moKAgXrc5IxQlyvN/2o9rRxfCJFE6KQl/m5+a9Y3UrG/EYNaTkZ9AZmEimUWJZBQm4nCaTy5snzyuTk769JMw63MntiEcpc8V4NCWNsrfayQqBHOvyGP+qkIs9vHN4Dgckk5i8kUZFM9Lp36/i5A/wtQFGUM6Ty8IjBa1aGiMgngLwnZgqiRJRahCcDtw57GVJEmaBjiBzXG254T4/X7Wr19PTk4OixcvnkhTRsTjDvL3X+xCbg9Sn6zjW99dRHaKTR3b3BGgva5PLbV9lH/QSPQdVTttSSbSch1YE03YEkxYE0xYE41YE/qPfYewfvDf6Gd8BmbfihCCoDdMb1eAvq4AfZ1B+roC9Haqx96eUGzQTsmiTBbfWExi2tk301mSJApnjRzm0tDQOMkl9HkAACAASURBVEpcBUEIEZEk6WvAW6jDTp8SQhyQJOnHwA4hxCv9VW8H/i4meFLE22+/jd/v5/Of//xZ12kMULe3i9fX7keWFaoLTTzyzYtJtKitcUmSSM60kZxpo3RxFqC24ruavP0i0UtPmx93m49AXxglEh3mDs9i7tFjLt9MwBMmHBralWNLMpGUZiW3xKnO0E23kpGvTr/X0NA494l7r5oQ4g3gjWPOPXzM8Zp423Eyampq2LNnD0uXLiUrK2uizRmCokTZ8lI1e95ppEMXpWteAj+/d8FJZxnrjToyi9SwkRqtUxmYtervkwl4wgTe/w3+I7sJzH6AgCGboFfGmmAisT8dw0B6hpGm72toaJwfnHvDLOKALMu8+uqrpKSkcNlll020OUPwuIO89Yf9tNf2sdsUwfmpDH5xy2wMZxALlyQJk8WAyWIg2f06NP8MrvoGXLV87AzX0NA459AEAdiwYQPd3d188YtfxGic+A7RAer2dvHu0xX4QxFet8lcdmUB3181bexGPXna4ZUH1Ylll/9gbK6poaFxznLBC0JrayubNm1i3rx5Z7QG8Viihohq2PNOAz6bjmdsQe6/vpT7L5s8djcRAl5+QE1W9tk/gmHiM7FqaGhMLBe0ICiKwiuvvILNZuPqq6+eaHMQQlC3z8XmF6vobvPTmKrjBcXHTz87i9sWjvHye9v+oC73d+3/qDOANTQ0LnguaEHYunUrra2t3HLLLVitEztksr22j00vVtFypAdHmoUtuTq2BgP88u75rJw5xp3cHQfhnR/C1KvVfPoaGhoaXMCC4Ha7ef/99yktLWX69OkTZkdvp58tL9VQtbMDS4KR6EVOHmtohzA8fe9CPjV5jMfQR0LwwpfVzJw3/XpclyrU0DhfCSth/BE/gUgAf9iPP+LHH/YTjoZjJRKNqPvKoP1BJRQJEVLUIisyQSWIrMixcwPnH1r0EIuz4zNP6oIUBCEEr732GjqdjmuvvXZCUlMEvDI7Xq9j/0fN6PQSifNTWdvpor6mhVUzs/j+qjLyU21jf+P3fwLt++COv4NDWylNQyMqogQjQfrkPnpDvSNuB/a9sld1+P1O3x/xE4kev4bEqWLWmzHpTVj0Fkx6E2a9eUhxGB2Y9WashvhFMy5IQSgvL6empoZrr72WpKQzW73rVInICuXvN7LrzXrCIYXMuWm8KHvYWN1EWXYiz942hyWT45RSu2YDbPoVzL8HSlfF5x4aGnFGiSr4Ij58sg9v2Isv7MMXPrrvlb1DjgORQKz1PtCCH9gfKCfCIBlINCeSaEok0ZxIkjmJbEc2NoMNm9F23NZqsGIzqFuT3oRRZ8SgM2DUGzFKRoz6/mOdMVYMOsNZkTPtghMEr9fLW2+9RV5eHgsWjJjjKS4c2trGlpeq8XaHyJ7uZEdClP8+3EiKzcSjn5nFrQvy0I9lrvioApGgGiYKdMNLX1GXMrzmP8fuHhoap4gQAk/YQ3ewm+5gNz2hHrqD3WrrO+zFK3tjztwje446d9mHJ+w5qQMfYLCjthqsWA1W7AY76db02PFAsRltqsM3qQ4/yZwU27cZbGeFsx4PLjhBeOuttwiFQtxwww3oxnGxkz3vNrDxn1Wk5SfgnZfED/c3IbdHuW9ZMV9dMSWWgmLUdB6Gg6+p6wgE3Ecd/+DtsY+xOgN8+V11kXQNjTEgpIToC/WHVOTeIaGVgf3u0FGn3x3spjfUS0QMH2KRkLAb7diNdhxGB3aTnURTItn2bBwmR+y8w+gYchw733/OZrCh12kz60+VC0oQjhw5wr59+1i+fDkZGeMXPz+0tY2N/6zCMTmBX0c9NOzq4Krpmfzfa8soTBulc45G1dWuDr4GB18HV/+i4tlz1Fa/wQIGc/928P6gbdZsdcEUDY1jEELgDXvpCfbEHHhvqDfWgh9w7L2hXnpCPfSEeugL9RFUgiNeUy/pSTQlkmxJxml2UpBYwJz0OaRYUkg2J+O0ONVidpJsSSbJlITNaEMnXWAZac8iLihBaGlpISMjg6VLl47bPev3u3j/z5XY8+z8uKuDKVkJrPvyYi6ZMorRQ+GgumrZwdfg0Hrwdait/MJlsPh+KL0WknLj/yE0zkmUqEKv3Is74MYVdOEKuIZs3UH30f2AGzkqD3sdnaQj2ZxMkjmJZHMyOY4cpqdOJ8mUdDS8Yk4ccpxkSsJutJ9SqCUcDlNfV08wOLLIaIwOi8XCpEmTTjnzQlwXyIkXZ7JiWjgcHrf0FG21vbz8+G4SM6z8VvJitOh5/evLTpqUjuZdsPH/wZF31aUrTQ6YehVMux6mXHnWLe+oMT5ERZSeUA+d/k66Al24g+5YC/7Y/YFWveD437dBMpBiSSHVmkqKNYVUSyqp1lRSLak4LU6SzcmxkmROIsGUMC6t9traWhISEkhNvbDXPT5ThBC4XC48Hs9x2RcmeoGcs47xEgN3q4/XflWOLcnM3iIzTfu7eOHznzq5GBx4Cf7176oIzL4Vpl0HRZeqIR+N8xIhBN2hbjr8HXT4O+j0d9IZUJ1+h7+DrkBX7Hi44Y16ST8kBDPVOZUUS0rMuadYhjr9RHPiWRmWCQaDFBYWamJwhkiSRGpqKp2dnaf83gtOEMYDjzvIq0/sQafXkXF9Hj/8VzlfWT6ZefnOkd8kBGx6At55GPIWw+3PnHD9Yo1zg3A0TKe/k3Z/O+3+djp8Heq23/kP7Iej4ePem2xOJs2aRro1naKkItKt6aTb0mPnBpz+eLXgxwNNDMaG0/0eNUEYY4LeMK8+sQc5EOHKr87m9ud3UpLp4JtXTh35TUoE1n8HdjwFMz4NN/9OW/bwHECJKnQGOmnztdHmb6Pd106br412v7pt87XRFeg6Lmxj0VvIsGWQYctgbsZcMmwZZNoyybBlkG5NJ8OWQZo1DZNeSzioMb5ogjCGhEMKr/26nL6uIDc8OIef766nyyuz9gsLMRtGCBWFPPD8PVD1Diz9Fqx4GMZxOKzGyAghcAVdNHmaaPI20expptnbHNtv97ejiKGrylkNVrLsWWTZsliau1Tdt2fFHH6GLYNEU6LWEr4AKCwsZMeOHaSljfykP5o644kmCGOEokR588n9dNT1cc19M6lQZF7c1czXV0xh1qQRZkP3NsMzt0FHBdzwC5j/pXG1WUMlHA1T01NDhauCQ92HaPQ00uRposXbctywynRrOrmOXOZlziPHnhNz+AMlwZigOXuNcxZNEMYAERV88JeDNBxwsfyuUlJKkrnt8Y8oy07kaytGCBW17oVnboWQF+76hzp6SCPuBCNBjnQfodJdSYWrgoPugxzuPhyL4VsNVgoSCyhKKmJp7lImJUwi15HLJMckchw5WAxaKO98pq6ujpUrV3LxxRezadMmFi5cyD333MPq1avp6Ohg3bp1TJkyhXvvvZeamhpsNhtPPvkks2fPxuVycccdd9Dc3MySJUsYPILzb3/7G0888QSyLLN48WJ+85vfnJXrtsddECRJWgn8AtADa4UQPxumzq3AGkAA5UKIO+Nt11ghhGDji1Uc2trG4huLmLEsl68/u5sev8xf7l2EyTBM+OfIO/D8l8CSBPe+CVkzx93uC4HeUC+H3Ic41H2Ig+6DVLorqempiYV5Ek2JlKWWcXfZ3ZSlllGWUkZ+Yv5500GrcXpUVVXx/PPP89RTT7Fw4UKeeeYZPvnkE1555RUeeeQR8vLymDdvHi+99BLvv/8+X/jCF9izZw8/+tGPWLp0KQ8//DCvv/46f/zjHwGorKzkueeeY+PGjRiNRh544AHWrVvHF77whQn+pMcTV0GQJEkP/Bq4CmgCtkuS9IoQomJQnanA94FLhBDdkiSdUyk4Kze1Uv5uI7OWT2L+qkLW72vllfIWvn1VCdNzEo9/w/Y/whvfgcwZcOc/IDF7/I0+z1CiCo2eRg51H4oJwCH3Idr97bE6adY0ylLKuDzvcqanTKcstYxse7YW3tE4jqKiImbNmgXAjBkzuOKKK5AkiVmzZlFXV0d9fT0vvPACACtWrMDlctHX18dHH33Eiy++CMB1112H06mOKnzvvffYuXMnCxcuBCAQCIxrpoRTId5PCIuAKiFEDYAkSX8HbgIqBtX5X8CvhRDdAEKIjjjbNKYc+KiZtDwHy26ditsn84OX9jMrN4mvLD9muctAD2z4L9jyG5h6DXzuKTA7Jsboc5hwNExVdxUHXAfUmL/7EEd6jsQSnuklPUVJRSzIWkCps5RSZyklKSWkWc+OTjuNsx+z+eicH51OFzvW6XREIpFTnsskhOCLX/wijz766JjaGQ/iLQi5QOOg4ybg2JUdSgAkSdqIGlZaI4R489gLSZJ0H3AfQH7+GC8neZr0uQJ01HtY8unJIMEPXtqPJxjhf26Zg1HfH3boqIStv4e9z0HYD4vug2seBb3WfXMyItEI1T3VVLgqhgjAQIqFBGMC01Kn8dmpn6XEWUJpSimTkydj1muT+DTix7Jly1i3bh0//OEP+fDDD0lLSyMxMZFLL72UZ555hh/84AesX7+e7u5uAK644gpuuukmvvWtb5GRkYHb7cbj8VBQUDDBn+R4zgavZACmAsuBScBHkiTNEkL0DK4khHgSeBLU1BXjbeRw1O7pAqB4bjqv7W1l/f42vruylNIMG1S+Btt+r+YiMlhg1i2qGGTPnmCrz048sofqnmqqe6o51H2IA64DHHIfIqSEAHAYHZSllnFn2Z3MSJ3BjNQZTEqYpIV8NMadNWvWcO+99zJ79mxsNht//vOfAVi9ejV33HEHM2bM4FOf+lSs4Tp9+nR++tOfcvXVVxONRjEajfz6178+KwUhrrmMJElagtriv6b/+PsAQohHB9X5HbBVCPGn/uP3gIeEENtHuu6Z5DIaS178n53IgQgrvjmHqx//iBnOKH+ZW4l+x1PQ2wBJebDw3+CiL4ItZaLNPSvwyl6qe1XHX9VTFROBwfF+q8FKWUoZM9JmxJy/1tl7/lNZWUlZWdlEm3HeMNz3OdG5jLYDUyVJKgKagduBY0cQvQTcAfxJkqQ01BBSTZztOmN8vSFaq3tZeG0hv/n7y/xH5O98rncTuveCajbSlY9AyaoLNjTUHeymprdGLT011PbWUt1bTZuvLVbHrDdTnFTMwqyFTE6ezJTkKUxOmkyOI0fLZa+hMQHE1VsJISKSJH0NeAu1f+ApIcQBSZJ+DOwQQrzS/9rVkiRVAArwHSGEK552jQW1u9tBQMrB/2CNbz0RgwXdnNvVsFDmjIk2b1wQQtDqa6WmV3X4g51/d6g7Vs+it1CUVMT8zPkxpz85eTK5jlzN8WtonEXEvfkqhHgDeOOYcw8P2hfAt/vL2Y+3A3b+meqXbSTpk7D7d/EHyz3c++DDYD+/w0JCCJo8TWxt28q21m1sa9uGK3hUu5PMSRQnFbMifwVFSUUUJxVTnFxMtj1bC/doaJwDXJjxjFNFCGjeqY4WOvAvghEzzYE/M3mWzCWNP+eHV85Ef56KQZuvjW1t29jaupVtbdtiIZ90azoX51zMvPR5FCcXU5xUTIolRevk1dA4h9EE4USEg3DgRdj2JLTsBlMCLPw3avV3IF50syMxF4O+hZvnnj+rlgUjQT5q+ojNrZvZ1rqNBk8DoKZiXpi1kC/P/DILsxdSlFikOX8NjfOMUQmCJEk/pz/+H2d7zg6iCnz036oQ+F2QVgrX/g/MuR3MCdT8Zi8Op5m1Ne1cNT0Tp/3cTlMshKC8s5yXql7irbq38Ia9OIwOFmQu4PZpt7MoaxFTnVO1sI+GxnnOaJ8QKoEnJUkyAH8CnhVC9MbPrAnmnYdh86/UNYsX36+uWNbfGpaDERor3NhnJNNd38MtCyZNsLGnT6u3lVdrXuWV6leo76vHarByVcFV3Dj5RuZnzseg0x4gNTSO5emnn2bHjh386le/mmhTxpxR/eKFEGuBtZIklQL3AHv7Zxb/QQjxQTwNHHe2PqmKweL7YdV/Hfdy/T4XSiTKNjlAVqKFZVPTJ8DI08cf9vNew3u8XP0y21q3IRBqKGjWl7mq4CrsRvtEm6ihoTFBjLoJ2J+oblp/6QLKgW9LkvTvQojb42Tf+HJoPbz5PfXJ4JpHhq1SvbsTs8PIG61u7r98Mnrd2R9HF0Kwt2svLxx+gbfr38YX9pHryOUrc77CDZNvYFLCufuUo3F+8qNXD1DR0jem15yek8jqG04+JPzmm2+msbGRYDDIN77xDe677z7+9Kc/8eijj5KcnMycOXNi+Y1effVVfvrTnyLLMqmpqaxbt47MzEzWrFlDbW0tNTU1NDQ08Pjjj7NlyxbWr19Pbm4ur7766rit734qjLYP4XHgeuB94BEhxLb+l/5LkqRD8TJuXGnZDf+8F7LnwGfXwjDj4yOyQv0BF5FJVhQX3DI/bwIMHT0hJcSbtW/yzMFnqHBVYDVYuabwGm6afBMXZV6k9QloaAzDU089RUpKCoFAgIULF3LdddexevVqdu7cSVJSEpdffjnz5s0DYOnSpWzZsgVJkli7di2PPfYYP//5zwGorq7mgw8+oKKigiVLlvDCCy/w2GOP8elPf5rXX3+dm2++eSI/5rCM9glhL/ADIYRvmNcWjaE9E0NPg7pymS0N7ngOTMOHTRoq3ERCChv8XhYVpVCYdnaGV1q9rTx36DleOPICPaEeJidN5geLf8D1k6/XQkIa5wSjacnHiyeeeIJ//etfADQ2NvLXv/6V5cuXk56uhodvu+02Dh8+DEBTUxO33XYbra2tyLJMUVFR7DqrVq3CaDQya9YsFEVh5cqVALE02mcjoxWEnsF1JUlKBpYLIV465zuXAz2w7lZ1iOkXXoGEzBGr1uzuRG/Rs8Pv5bEFJeNo5MkRQrCtbRvPHnyWDxrVbp3L8y7njml3sChrkTZEVENjFHz44Ye8++67bN68GZvNxvLly5k2bRoVFRXD1n/wwQf59re/zY033siHH37ImjVrYq8NTpttNBpjv8GBNNpnI6MVhNVCiH8NHAgheiRJWo2ah+jcJSLDPz4Priq4+wXImDZiVSUSpXZvF71OA1ZFz7WzssbR0JHxh/28Wv0qzx58lureapLNydwz4x5uLb2VHEfORJunoXFO0dvbi9PpxGazcfDgQbZs2UIgEGDDhg24XC4SExN5/vnnmTNnTqx+bq46D2kg6+m5zGgFYbhg87k9JlEIeO2banrqm38LxZedsHrzoW7kQIQNpgA3LMrBZprYj++RPfyt4m/8teKveMIeylLK+MklP2FV0SptPQANjdNk5cqV/O53v6OsrIzS0lIuvvhisrOzWbNmDUuWLCE5OZm5c+fG6q9Zs4ZbbrkFp9PJihUrqK2tnUDrz5xRpb+WJOkp1LDRr/tPfRVIEUJ8KX6mjcyYpL/e8Bh88J9w2UNw+fdPWv2Dvx2kcmsrP7f5+ccDn2J+gfPM7n+aeGQPf6vsFwLZw4q8Fdwz8x7mpM/RwkIa5zRa+uuxJZ7prx8Efgg813/8DqoonJuUP6eKwezbYflDJ60ejQpqyztps0sUpNu5KD95HIwcilf2sq5yHX+p+At9ch/L85bzwJwHKEvVfkAaGhpjw2gnpvmAk3vOc4Haj+Hlr6prFtz4y9gM5BPRWtVDwBNmiy3ErQtKxrUl7gv7eKbyGf5c8Wd6Q70sn7Sc++fez4zUCyPFtoaGxvgx2nkI6cB3gRmAZeC8EGJFnOyKD52H4Lm7IKUYbvsrGEaXg6hmdydCBw1mwWfmjU8iO1/Yx7MHn+XpA0/TG+rl0kmX8sCcB5iRpgmBhoZGfBhtyGgdarjoeuB+4ItAZ7yMihvbngS9Ce56Hqyj6wMQUUH17k4azYKl09LJSLSc/E1ngBCCfx75J0/seoKeUA/LcpfxlTlfYVb6rLjeV0NDQ2O0gpAqhPijJEnfEEJsADZIkjTimsdnLasegyVfA+foF7dur+/D1xNivy3M1xfEd2ayK+Bi9abVbGjawMKshXzzom8yO312XO+poaGhMcBoBSHcv22VJOk6oAU491aE0ekhpejk9QZRs7sTIUF3sp4V0zLiZBhsaNzAw5sexit7eWjRQ9wx7Q4ttYSGhsa4MlqP81NJkpKA/w38H2At8K3RvFGSpJWSJB2SJKlKkqTjOqYlSfqSJEmdkiTt6S9fHrX1cUYIwZGdHdTrFa6bn4tRP/YO2h/285PNP+Fr73+NNGsaz13/HHeV3aWJgYbGWcrTTz/N1772tTG51l133UVpaSkzZ87k3nvvJRwOn/xNceSkXqc/y+lUIUSvEGK/EOJyIcR8IcQro3zvr4FVwHTgDkmSpg9T9TkhxNz+svZUP0S8cDX78LqCHDIq3BKHcNGBrgPc9tptPH/4eb4040s8e92zTHFOGfP7aGhonJ3cddddVFZUsndXOX6fnyd/+3sUfxjFF0bxyER6Q0R6gkTcQcJdAcIdfqKh+KW9OGnISAihSJJ0B/D4aVx/EVAlhKgBkCTp78BNwPCJQc4yqnd1IABzoYOSzIQxu64SVfjj/j/y2z2/JdWayh+u/gOLsxeP2fU1NM551j8EbfvG9ppZs2DVz05aLR7pr/+/n/+cLZu38Oabb5KTncNL617AIOm5cu6lRFrVnKHzp82h8Ug9ijs41CCdBDpJHSEf53T7o41LbJQk6VeSJC2TJOmigTKK9+UCjYOOm/rPHctnJUnaK0nSPyVJGrYpLknSfZIk7ZAkaUdn5/gMcKrY3kaTXuHmi8fu6aDJ08Q9b93DL3f/kisLruSFG1/QxEBD4yziqaeeYufOnezYsYMnnniC5uZmVq9ezcaNG/nkk0+GJLobSH+9a9cubrv1Vv7r0Z+h+MJEgxGqDh7hrWdf5YW1f+fzn/8Cy+YuYedbm7EYzLz2+usggc5iQJ9oJurQ8+zL/2DVzddhyLRhzLJjzHFgzHVgynFgyrJjzLRjTLehM8cvbc5orzyQvOPHg84JYCzmIbyKuiRnSJKkfwf+PNx1hRBPAk+CmrpiDO57QrrbfPg7g9TYBf8xZ2ySxL1S/QqPbH0ECYlHlz3KdUXXaekmNDSGYxQt+XhxovTXIiq49bO3cPjwYZS+EHX7q/juDx+ita0NOSxTmFeA0h1EyArXrLgKo8XM7PlzUaIK133uRiSDjtkL59Lc14Yx3Ra75/3/66tcuvwyLrti+QR9apXRzlS+/DSv3wwMbl5P6j83+NquQYdrgcdO815jyuGdHQAUzE4l0XJmKxsJIfhN+W/4XfnvmJ85n0eWPqJlItXQOAv54IMPePedd9n44SdYzRZWXHMFU3OL2b9rL3KLF6ICxSsTDUZQ+mS++b1v842vfJ0bb7iBDZs/5ieP/hRjlh1dgglbQgLGNCsARqMRvVX1I3q9fkj66x/96Ed0dnby+9//fkI+82BGO1P54eHOCyF+PNz5QWwHpkqSVIQqBLcDdx5z7WwhRGv/4Y1A5WhsijflW1pp0Uf59NLRz1kYjqiI8tj2x1hXuY6bp9zM6iWrtcXrNTQmGKFEERGBiEQRkShEoghF4KprJ8mWgMkHB8r3snX7Nvx3+Ph48yd0B3pJcibzr7deYfacORhzHPQFvBRML8aQbOFv/3hGjfUbdKN+8l+7di1vvfUW7733HjrdxI8sHK1nGrxSmgV1xvJJHbcQIiJJ0teAtwA98JQQ4oAkST8GdvSPVPq6JEk3AhHADXzpFOyPC91tPsKdQTpSdFxclHra14lEI6zetJpXql/h7rK7+c7C72jDSTU0xgmhqE4+5vAjR0WA6DFRZ4MOyaBj1apVrH3mT8y5chElJSVcfPHF5E0vYs2Pf8SyVZfH0l9LOglJJ51x+uv777+fgoIClixZAsBnPvMZHn542Pb3uDCq9NfHvUmSzMBbQojlY27RKBiT9Ncn4O2/VFC5qZXodTl864bTyyYqKzLf2fAd3m98nwfmPsD9s+/X+gs0NE7Aqaa/FlGBUKIQEf0tftXh0y8Exzl9vQ7J0N+C7y8YTq1Ffy4Rz/TXx2JD7Q847wgFIlRt7+CgUeHfZo28nOaJ8If9fOODb7CldQvfW/g97p5+9xhbqaFx4SCEQISjapEVdTtcK1+SkPQSGHTozBJSvwBg0Kn7cR6yeT4w2j6EfaijikAN/aQzdMTRecPBTa2IcJR9SVFm5iad8vt7Q7088N4D7O/az08v+f/ZO+/4qsrzgX/fu+/NvdmLkYSwIYDsIYogDtyj2mrRuq1S/NlaW7U/K2itWnexzvJDq9VqXa17gAxBZmRvSAIkhOxxb+4+5/39cW5CAgmEkEsSON/P53zOes85z3vOvc/zzud5lMv6XhYFKXV0Tk6kjLTrB1VkSImsVS3CIWht9GYDBrtJK+EbIyV8Y/1YfV3pHw+trSFc3Gg7DJRIKTtnlOjjQKqSjYsKqXEIUrNc2MzGY7q+3FfOL7/9Jfk1+Txz1jOck3VOlCTV0enaSEWiVGuzb8NlPsLlPpTuQUL76w4qfyEQFgOGGDPCYkCYjVqTj670o0ZrDUI3YLOU0g0ghHAJIQZLKVdGT7QTz57NFdSU+fjBGeL0XunHdO1+z35u++Y2ynxlvDj1RSZ0nxAlKXV0ugZSSlR3kFBE4TdZKv2gHGzyEVYjdI/BEGPSFL/FcNK27XdmWmsQXgYaz0yua+ZYl2fjokLMThNbjD7uOoaYyXk1edz+ze14w15eO/c1hqcOP/pFOjonCTKsEq70Ey71asq/1EuozEu4zIcMKAcTmgSmJDvmVAf2nCRMSXZMKXZMyXYMMWZqt23DFB/deCM6R6a1BkHIRsORpJSqEOKkGkxfXeJl7+ZKDEPjUPe5GZnZOoOwvXI7t31zGwZh4PXzX2dA4oAoS6qj0zFIKVGqAgT31RLaX6cp/zIv4Qp/kw5eY6wFU6oDx8hUzCmOBqVvjLPqHbudnNYq9TwhxP+g1QoAdst4lQAAIABJREFUZgB50RGpY9iwqBCDSbDRqtAryUGKy3rUa+pCdfxm0W8wG83MO38eWbHHN4lNR6czoQbCBAs9BPe6Ce6tJbjPjeqJuGc2NirtD0nGlOrAnKKV+KPpayfazJkzh5dffpm9e/eyevVqBg9uzjkzzJ49G6fTyb333nuCJYwurf1ydwBzgAfRRhstAG6PllAnmqAvzLblxfQdmcrcov1MHtC6QDh/WfUXijxFujHQ6fJIVRIu82rKf59mAEIl3oaxhaYUO7b+CVgyXVgyYjGnOxBRiA/S0bz00kvMnz+fBx98kC1btjRrEBq7nTjZaK0vo1I0txMnJdtWFBPyKySPTKZiRwGjWtF/MH/PfD7e9TG3Db2NUWmjToCUOjrtg1Ql4QofoUIPwUI3wSIPof0eZFAFQNhNWDJcxA5JxpLhwpLhwuA4Pn9ex8pfVv2FbZXb2vWeAxMHct/Y+1o8f8cdd5CXl0d2djbhcJjFixfz6KOP8uGHH3LLLbcwfPhwli5dyrXXXtuucnUmWjsP4R/A3VLK6sh+AvCMlPLmaAp3ItCGmhaRlh3LbkWrDo/udWSDUOotZfby2eQk5XDn8DtPhJg6Om1CqhKl0k+wyE2w0EOoyEOwyNPQ2SvMBszdncSMTtdcLWe6MCXZT8m2/ldeeYWvvvqKNWvWcO+993LxxRdz1VVXNZwPBoPUe0iYPXt2B0kZXVrbZDSs3hgASCmrhBAjoiTTCWXf1kqqS7ycc9Ng3thTSqzNRN8UZ4vpVany4NIHCSpBHj/zccyGE1ty0tE5FG14Z0gbzllxcGhnqNyHUunXJnYBmASWbk4cI1Ox9HBh6enElOLQJnV1Mo5Uku8ofvazn3W0CFGntQbBIIRIkFJWAQghEo/h2k7NhoWFOGIt9B2Vyppl2xmZlYDhCKWjt7e+zfLi5fxx/B/Jjss+gZLqnOpIJdLUc6CO0IG6RuP6Nf/7DRgFpkQbpmQ7tn4JmNMcmHs4MaednO3+J4qYmJiOFiHqtFapPwMsF0K8DwjgKuDPUZPqBFFd6mXP5grGXNgLT1BhZ6mHy4a3HKdgR9UOns99nsk9J3N1/6tPoKQ6pxqKJ6gp/mJvgwEIlXghHCntG8CYYMOcbMfaKw5Tsr1hMcbrwzuPF5fLhdvt7mgxTjit7VR+UwiRC9QHyrlSStkl4iIfiU2LijAYBDmTerBqbxUAo7ISm00bUALc//39OC1OZp8+W59BqdNuqAGF4N5aAvk1BPe5CR2oQ3WHGs4bnGbM3WJwTuimhVbspoVSFGa9tB8trrnmGm677TbmzJnDBx980NHinDBa3ewTiWNQhhYPASFEppRyb9QkizJBf5itP+ynz8hUYuKsrFlRidEgOC2jeYd2f/3xr+ys2smLU18kyd72GAk6OqovTKCghkB+LcH8GoJFWiQuDGBOi9GaebrFaMo/PQajy9LRIp8yFBQUAJCcnNwkdvKiRYuapDulO5UjAWyeAboDpUAWWoCcnOiJFl22rzhA0K8wbIrmxTt3TxU53WNxWA5/JT/s/4G3trzFNQOuYVLPSSdaVJ0ujlIXIphfQyC/hkBeDaEDddr4fqPA0tOF66yeWLPjsGS5uvSkLp2uT2t/fX8CxgPzpZQjhBBTgC7r5F9KzatpapaLtOxYQorKun3VXDs287C01f5q/rhU60C+Z/Q9h99LVVHCYUwWvRSnc5BwdQDfpnJ8m8oJ7qkFqQ3xtGS6iJ2aiSU7DmumC3GMHnV1dKJJaw1CSEpZIYQwCCEMUsqFQojnoypZFCncWkXVAS/n3DgIIQRb9tfgD6mHTUiTUvLIikeoDFTyt6l/w26yH3avpe+9xdbvF3HT869gthzd3YXOyUu40q8ZgY3lBPdpHZKmNAeuszO1Wb49nJoPfx2dTkprDUK1EMIJLAHeFkKU0jTOcosIIaYBf0ULrDNXSvlEC+l+AnwAjJFSRi8+JprfIrvLTN9RWkS03D1ah/LoQzqU/7PrP3y751t+M+o3DEo6PLSfEg6xccHX+Ny1bP1+IcOmToum2DqdkFCZt8EIhPZrfwlzDyex52dhH5KMOcXRwRLq6LSe1hqEywAf8BtgOhBHKyKmCSGMwIvAuUAhsFoI8cmhI5SEEC7gbiDq8RVqynwUbCxn9AW9MEZGaeTuqaJHvJ30uIOud/fV7uOJVU8wOm00Nwy+odl75f24Gp+7FqsjhtzP/8vQKechDHoJ8GRGhlUCe2oJ7KzGt7WCcIkXAEumi7gLszVHb4m6C2edrklrh53W1wZU4B+HnhdCLJdSNhcRZiywS0qZF0n3LppxOXTI6p+AvwC/a6XcbWbj4kIMQjBkUg9AaxZas6eS8b0PjhxSVIX7l96PURh57IzHMBqab+fdtGg+MQmJnHHNL/j65ecpWP8j2SNajF+t0wWRUhIu8eLfWYV/ZzXB/Bpt5q9BYMlyEXdJb80IxOnNhTpdn/Ya0tBSkagHsK/RfiEwrnECIcRIIENK+bkQokWDIIS4nYiH1czMwzt/W0PQH2brsmJ6j0whJl77AxdV+yipDTTpP3hv+3tsKNvA42c+Tjdnt2bvVVddRf7aNYy+5EoGnXEWy959kzWf/0c3CCcBSm0Q/84qAruq8e+qapgTYEqx4xidhq1fAtbecRhs+oigU5E33niDNWvW8Le//a2jRWl32usXLY+e5HCEEAbgWeDGoz5AyteA1wBGjx7dpuftWFVC0Bdm2JSMhmP1/Qf1BqHMW8YLa19gfLfxXJR9UYv32vr9QqSqknPWVIwmM8OnXcLSf/2Dsj35pGTpLi26EvXNQP7tlfi3VzU0AxliTFj7JmDrG4+1XwKmeL0WoHNyE+0iThGQ0Wi/Z+RYPS5gCLAoMvM3HfhECHFpVDqWpSQzJ5H03rENh9YUVBFjMTIwXTv21JqnCCgB/nfc/7Y4G1lKyaZF8+nWbwBJPbTsDTtnGis+epfcz//LtBm/bnfRddqXcHWgwQAEdlVrvoCMAmuvWGJG9sLaV5scpruA6BgOPPYYga3t6/7aOmgg6X/4w1HTXX755ezbtw+/38/dd9/N7bffzuuvv87jjz9OfHw8p512GlarVjj49NNPefTRRwkGgyQlJfH222+TlpbG7Nmzyc/PJy8vj7179/Lcc8+xYsUKvvzyS3r06MGnn36K2WzmkUce4dNPP8Xn83H66afz6quvoigKEyZM4KmnnmLy5Mk88MADGAwG/vzn6HsLaq8e0Jb+NauBfkKIbCGEBS2mwif1J6WUNVLKZCllLyllL2AFEB1jAAw5qyeX3DW8iaLP3VPFiMwEjAbB8v3L+TL/S24Zegu94nq1eJ+SvF1UFO5lyORzG47ZnS6GTD6HrUsX4amqjIb4OseBDKv4d1VT/UUeB57L5cATq6j+eBeh/R4cI1JIun4w3R8aT8ptw3CdlaENEdWNwSnJvHnzyM3NZc2aNcyZM4eioiJmzZrFsmXLWLp0aZMZzGeccQYrVqxg7dq1XHPNNTz55JMN53bv3s13333HJ598wnXXXceUKVPYuHEjdrudzz//HICZM2eyevVqNm3ahM/n47PPPsNkMvHGG29w5513Mn/+fL766itmzZp1QvLeXjWE65s7KKUMCyFmAl+jDTudF3GB8QiwRkr5SXPXnSg8gTDbDtRy19n9CCpBHlv5GBmuDG4deusRr9u0aD4ms4UBp5/Z5PjICy5l3TdfsP6bz5n4s2Zfic4JQkpJuMxHYGcV/l3VBHbXHKwFZMcRMyoN24AETKkO3S9VJ6Q1JfloMWfOHD7++GMA9u3bx1tvvcXkyZNJSUkBNDfYO3bsAKCwsJCf/exnFBcXEwwGyc4+2Fx8wQUXYDabGTp0KIqiMG2aNix96NChDS4yFi5cyJNPPonX66WyspKcnBwuueQScnJyuP7667n44otZvnw5lhM08fWIBkEI4ab5/gEBSCllLNrGppbuIaX8AvjikGMPtZB28lHkPS52rFxG/tpczr/jfwBYu7cKVWoBceZtmkdBbQGvnPMKVmPLbcXhYJDtyxbTd+wErI6m7nATuvWgz6hxrPv2S8ZefjVmqz788ESieIJaR/DOagK7qlBqggAYE204RqRgG5CItU88Bqs+O1ineRYtWsT8+fNZvnw5DoeDyZMnM3DgwCa1gsbcdddd3HPPPVx66aUsWrSoiY+j+mYlg8GA2WxuKHgYDAbC4TB+v58ZM2awZs0aMjIymD17Nn6/v+H6jRs3Eh8fT2lpafQyfAhHNAhSSteJEuREUFtWyqaF39B/3OlkjxjNmoIqDAKSE9z8fcXfOS/rPCb2mHjEe+zOXYm/zkPO5HOaPT/64svZvWYFW5Ys5LRzL4hGNnQiqEGFYEEt/l1VBHZWEyrWRkcLu0nrCO4bj61vPKakw2eY6+g0R01NDQkJCTgcDrZt28aKFSvw+XwsXryYiooKYmNjef/99znttNMa0vfooQ1h/8c/DhuRf0TqlX9ycjIej4cPPvigIULbRx99RGVlJUuWLOHiiy9m1apVxMfHt2NOm+eYmoyEEKk0GmLa1bydjph2Meu//YJFb84lc+hwftxbRf90F39d9yQmg4nfj/n9Ue+xadF8XEkpZA4Z1uz5HgNzSOvdj9wv/suwqefrE9XaGdUfxre1Et/Gcvw7qrT4AEaBNSuW2PN7Yesbj1lv/9dpI9OmTeOVV15h0KBBDBgwgPHjx9OtWzdmz57NhAkTiI+PZ/jw4Q3pZ8+ezdVXX01CQgJnn302+fn5rX5WfHw8t912G0OGDCE9PZ0xY8YAUF5ezv3338+CBQvIyMhg5syZ3H333cdscNqCkPLoIzhb8nYqpewQb6ejR4+W9bFNj5Vda1by36f+xOQbbueGlVbGDilktfd5fj/m91w/+Mjt/u7Kcv4+42bGXn41Z1zTctqtyxbzxZynuOK+WfQeOaZNcuocRKkL4d9SgW9TOf5d1aBIjLEW7EOSsQ1IwJIdh8GiNwN1dbZu3cqgQYe7iNFpG829TyFErpSyxclSp5y30z6jxpI5dDjL3n+bcOplbA/9k4GJA7l24LVHvXbLkoVIqZIzeeoR0/UfN5ElSa+T+/nHukFoI4o7iG+zZgQCedWggjHBivP07tiHJmPp6dJrATo67cwp5+1UCMHkX9zKm7+/iwm+T8gNVfDg+OcxGY78KqSUbF68gB4Dc0hIbznMJoDRZGLktEtY8vbrlBbkkdqrd3tm4aQlXOXXjMDmcoIFmstoU7Id16QM7EOStKYgfUSQjk7UOFZvp99zjN5OOyMpmb2ozBrI4D1byE68kNNSTjvqNcU7t1G1v5Axl17ZqmcMnXo+yz/4F7mf/4cLfnV4HAWdg36CfJsr8G2pIFTkAQ66jHYMTcaUpg8L1dE5UbTWICxE83B6N1pTUau8nXZWVKkyP3MrlxdKBmwwwCVHv2bzogWYrFYGjD+jVc+wxTgZcva5rP/mS8689gaciW0PuymlRAmFCIeC2joYIBw8uG+x2bC5YrG7XBhN5jY/50QgVUlwnxvf5nJ8mytQKrSRFpZMF3EX9MKWk4w5WR8VpKPTEbTWIJiAb4BK4D3gPSllRdSkijJvbHgPr3MPvuEXUbhmA3lrV9N7RMtt/aGAn20/LKH/uIlY7K33bz/ygstY+9VnrPvmc8645hetusZbW8PSd98k78fVhIMBlIjiby0Wux2bUzMONqcLuysWuysWm9NF934D6DV8VKvv1V5IRSWwu0aLG7ClAtUT0kYG9YnHNakn9kFJGGP1iHM6Oh1Na91fPww8LIQYBvwMWCyEKJRSNj8YvxNT6a/klY0vEK7L5vKf/JZ1RQ+y6M3/I2voCIym5l/HrlXLCfq8DGlh7kFLxKel02/MBNZ/+yXjLv8pZlvLE9VUVWHjgm9Y+q9/EPT76D/+DOyuWEwWC0azBZPZjMlixWQxN9k3mkwE/T58bjd+dy0+dy0+T2Tb46a6pBi/203Aq7XwXfQ/v2PgxLOOKR9tQSqSQF41vg3l+DaXo3rDCIsR24AE7DlJ2AYm6t5CdXQ6Gcf6jywFDgAVQGr7ixN9nl3zLH7Fi6y4gqFZScRdfwv/efIR1n/zOSMvvKzZazYtXkBsSho9Bw055ueNuuhydq76gc1LvmP4eRc2m+bArh0smPcyB3bvpOfgIUy9+U6SM7KO+VlHIhTw89Hjs/nqpeeISUgkY/DQdr0/RJqDCmrwbtBiCauekGYEBifiGJaCrV8CwqzPy9Dp2nSk++vp06ezZs0azGYzY8eO5dVXX8Vsbr9m4lb9O4UQM4QQi4AFQBJwm5Sy+ZlZnZjcklz+u/u/xAamclrqQMxGA71HjiFr2Ah++OAdfO7aw66pLS9l76b15Jw1tU2TzLoPGER63/78+MV/kKra5JzP4+bbv/+Ntx/8Le6Kci6c+Vt++tDj7W4MAMxWG5fe+7/Epabz36cfpaKwfeYUSikJ7Kml+tPdFD+xirLXNuLNLcGaHUfi9EF0/+M4kq4ZiH1wkm4MdHSOk+nTp7Nt2zY2btyIz+dj7ty57Xr/1tYQMoBfSynXtevTTzAL9y6kW0w38nacyWWTtPgHDcNQf3cXP7z/NlNvvrPJNVsWfwdSknPWkecetIQQglEXXc7nf32S3T+upu/ocUhVZdOi+Sx55w0CdR5GXnApp1/988N8I7U3dqeLKx94mHce/C0fPj6Lnz/6DM6ExKNf2AyhA3XUrS3Ft74MpToARoFtQCKO05KxDUzS/QXpHBff/3sH5fs87XrP5AwnZ/60/1HTdWb31xdeeLCVYezYsRQWFrbrO2pVkU1K+UBXNwYA9465l3uHvExYMTeJkJackcWwcy9g/bdfUr5vT8Px+rkHGTnDiEtNa/Nz+4+biCs5hdzPP6Ykfzf/mvV7vnl1Donde3Ld488z5Ybbom4M6olLTePK+2fjd7v5+ImHCfq8rb42XBPAvbiQkud/pOT5H/F8X4g5zUHC1f3p/sfxJP9iMI7TUnVjoNOl6Qrur0OhEG+99VaDB9X24pTr1dtZrLnqGJmZ0OT46Vf/nG3LFrHozbn85A+PIISgaNtmqkuKmXDV0WcxHwmD0cjIaZew+J/zePuB32BzuZg24zcMPnNKh/g6Suvdl4t/cx//efJPfPr8X7j8d39ssUNd9YfxbSrHu7aUQF4NSLBkuIi/tA/2YckYnfroIJ32pzUl+WjRFdxfz5gxg0mTJnHmmU1d8B8vp1yj7pqCSvqlOol3NH3Bjtg4Jvzk5+zZsJb8tZqfpE2L5mOx2+k39vTjfu7QqeeTmt2H0867gJuff7XNfRLtRe8RYzjn1hkUrMtl/tyXaOzTSioqvq0VVLyzlf2PrqTqg52EqwO4zs4k7d7RpP5qOM7Tu+vGQOeko7H76/Xr1zNixAgGDhzYYvq77rqLmTNnsnHjRl599dUm7qtb6/76gw8+YOPGjdx2222tcn/98MMPU1ZWxrPPPtueWQdOsRqCqkpy91Rx4dBuzZ4ffv5FrJ//JYvenEv3/oPYsXwpA06fdMThoq3F6ojh+if+etz3aU+GTZ1GbVkZKz9+j9jkFEZNuARvbgne9aWodWEMDhMxY9JwjEjFkuHSZwzrnPR0dvfXc+fO5euvv2bBggUYolCgPKUMwu4yD7X+cJP+g8YYTSYmX38LH//lYT7+y8OEAv5jnnvQ1Rh/0U+x5AscyyyUrlkLRoF9cBKOkanY+icgjKdcJVLnFKazu7++4447yMrKYsKECQBceeWVPPRQs/HG2kSr3F93Ntrq/vpfq/bywEcbWXjvZLKTm+/ElVLy0eOzKFj/IwndunPTc6+edCVjGVbxb6ukLrcE//YqUCVuQzU7yldz2m2X02vMyI4WUecURHd/3b60xf111It/QohpQojtQohdQoj7mzl/hxBioxBinRBiqRBicLRk2X7ATVKMhV5JLbufqB+GajSZGHr2+SeNMZBSEizyUP3JboofW0nFP7cSLHTjPLMHab8ZSe8Hz6Y6rpJPX3yc0oK8jhZXR0enA4hqDUEIYQR2AOcChcBq4Fop5ZZGaWKllLWR7UuBGVLKI46lOp4AOVV1QRJijt4Z6qmqxBEXh8HQtYdQypCCd10ZnhXFmjdRo8Cek4RjVBq2vgkI40GD564o550HfwtScs0jTxKXmt6Bkuucaug1hPalM9YQxgK7pJR5Usog8C7QxD9EvTGIEANEtQ2rNcYAwJmQ2KWNQbjCR/UXeRQ/voqqD3ciQyrxl/Wh+/+OI+nng7APSGxiDABcSclcef9sQsEA//zDPezZ2OWnnujo6BwD0e5U7gHsa7RfCIw7NJEQ4lfAPYAFODvKMp20SFXi31lF3fJi/NsrQYA9J5mY8d2w9o5rVfNXSlY20//8LP99+s98+OeHmDT9RkZdfMVJ03Smo6PTMp1ilJGU8kXgRSHEz4EHgRsOTSOEuB24HSAzM/PECtjJUb0h6nJL8KwoRqnwY3CacU3JIGZcN0xx1mO+X0K3Hvz80af56uXnWfzPeZTk7+a8X96F2Xr8w291dHQ6L9E2CEVofpDq6Rk51hLvAi83d0JK+RrwGmh9CO0lYFdFSklwr5u61QfwrS9DhlQsWbHEnZeFPScZYTq+1kCL3cElv3mAVf95n6XvvUVF4V4uizjH09HROTmJtkFYDfQTQmSjGYJrgJ83TiCE6Cel3BnZvQjYiU6LKLUB6n4sxZtbQrjMhzAbcIxIJWZ8Nyzdne36LCEE4674Kam9evP5C0/xzwd+w0V3/55ew0a063N0dLoSHen++pZbbmHNmjVIKenfvz9vvPEGTmf7/e+j2qkspQwDM4Gvga3Av6WUm4UQj0RGFAHMFEJsFkKsQ+tHOKy56FRHhlW8G8oof30TxY+vovarAgwxZhJ+0o9uD44j4cp+7W4MGpM9YjTTH3sOZ0IiHz02i9WffEhHzF9RFYWA10tddRXVJQeo3F90mEtxHZ2Tmeeee47169ezYcMGMjMz290oRb0PQUr5BfDFIccearR9d7Rl6IpIKQkVeajLLcG7rgzpC2OMs+CanIFjVNoJjzuckN6dax99mq9f/itL3n6dA3m7mHbH3e3i1sPncVOav5vSgjxK83dTU1ZCOBAgHAwQCgQIBfyEAwGUcPiwa8+59Vecdu4Fxy2DTudi4RuvUbqnfefDpGb1ZsqNtx81XWd2fx0bGwto+sHn87X7YI9O0amscxA1oOD9sYS6lQcIHagDk9BGCo1Kw9o3HmHouNE+Fpudi399H6s/6cvSf71JZdE+LvjVPbiSkjFZLJjMliM67JNSUldVSWlBHiX5uyjNz6O0YDe1ZQedd7mSUkjo1g1HbBxmqw2TxYrZqi0mqxWzxYrZph1f9d8P2PjdN7pB0GlX5s2bR2JiIj6fjzFjxnDRRRcxa9YscnNziYuLY8qUKYwYoTWb1ru/FkIwd+5cnnzySZ555hlAc3+9cOFCtmzZwoQJE/jwww958sknueKKK/j888+5/PLLmTlzZoPrieuvv57PPvuMSy65hDfeeIOrrrqKF154ga+++oqVK1c2yHfTTTfxxRdfMHjw4IZntRe6QegkhCv9eH7YT92aA0i/grmHk/jL++AYloLB0X4h8o4XIQRjL7tK61f465O8dd//NDmvxX22RJS3Rdu3WjEaTVTuL8RbU92QNqFbD7r1HcBp515IanYfUnv1xhEb12pZ/B43i96cS/m+PVGJMqfTcbSmJB8tOrv769dffx1FUbjrrrt47733uOmmm9ot77pB6ECklATyavAs249/a4U2b2BoCs6J3bFmxna0eEek12kjuf7JFyhY/yPhYIBwMEgo0sxT39QTDgQIh7TjSihE9vDRpGb31pR/VjYWe8suRFrDoDMms+Tt19m8eAFnXXdzO+VM51Smsftrh8PB5MmTGThwYJOgOI256667uOeee7j00ktZtGgRs2fPbjjXWvfXa9asISMjg9mzZ7fK/TWA0WhsCMijG4QujgypeNeV4vlhP6HiOgwOE67JGcSMb9u8gY4iNjmFYVPP77DnO+Li6TV8FFuXLuLMa2/AYOy6M8t1Oged2f11XFwcu3fvpm/fvkgp+eSTT44Yq6Et6AbhBKLUBvAsL6ZuVTFqXRhzuoOEn/TDMTwFYdaVWVvIOWsqebmr2LNhLdkjWnTRoqPTKjqz++vXX3+dG264gdraWqSUnHbaabz8crPTttrMKeX+uqNQvSFqF+3Ds2w/qBLboCStWaiV7iR0WiYcCvHqHb8ga+hwLv71fR0tjs5xoDu3a1/a4txOryFEERlW8awoxv3dXlRfGMfINGLPzsCUdGKHjJ7MmMxmBk6cxMbvvsFf58EWE735GDo6Jzt6OKwoIKXEu7GcA8/lUvNZHubuTlLvGkHi1f11YxAFciZNRQmF2LF8aUeLoqPTpdFrCO1MYG8tNZ/nE9xTiynNQfJNOVj7J+hNQ1EkrU8/knpmsmnxfIadc8RQGjo6OkdANwjtRLjST81X+fg2lGNwmom/si8xo9IPizmg0/4IIRg86Wy+f+cNKvcXkdi9R0eLpKPTJdGbjI4T1R+m+vM8DjyzBv/WSlxTM0n/3RicY7vpxuAEMvjMKQhhYMuS7zpaFB2dLoteQzgOFE+Q8rmbCJXU4RiZRtx5WRi70DyCkwlnYhJZp41gy5LvmPjT6Ud0oaGjo9M8+r+mjSieIGV/30io3EfyTUNIvLq/bgw6mJxJZ+OuKGPv5g0dLYrOScwbb7zBzJkzj+maXr16UV5e3qo01dXVvPTSS8cjYpvRDUIbUNxByl7biFLpJ/nGHGz9EzpaJB2gz5jxWB0xbFm8oKNF0dFpMx1pEPQmo2NEqQ1S9vcNKNUBkm7MwdYnvqNF0olgtlgZMOFMtixdyFTfncftK0mn46j+dDfB/XXtek9L9xjiL+lz1HTt4f4YpxupAAAgAElEQVS6oqKCa6+9lqKiIiZMmNAkfsg///lP5syZQzAYZNy4cbz00ksYG7lduf/++9m9ezfDhw/n3HPPZdasWVx22WVUVVURCoV49NFHueyyy9r13dSj1xCOAaUmQNlrG1BqAiTfPEQ3Bp2QwWdNJRwIsGPFso4WRaeLMm/ePHJzc1mzZg1z5syhqKiIWbNmsWzZMpYuXdrE0V29++u1a9c2OJsDePjhhznjjDPYvHkzV1xxBXv37gW02cPvvfcey5YtY926dRiNRt5+++0mz3/iiSfo06cP69at46mnnsJms/Hxxx/z448/snDhQn77299GLUCVXkNoJeGaAOWvbUDxhEi+eQjWXq1306xz4ujefyAJ3bqzeckChkw5t6PF0WkjrSnJR4v2cH+9ZMkSPvroIwAuuugiEhK0ZuUFCxaQm5vb4LfI5/ORmpp6RHmklPzhD39gyZIlGAwGioqKKCkpIT29/eObn1I1BKm2zaqGq/2Uvaobg66ANidhKoVbNlFTeqCjxdHpYjR2f71+/XpGjBhxRI+id911FzNnzmTjxo28+uqrTdxXN4eUkhtuuIF169axbt06tm/f3sRldnO8/fbblJWVkZuby7p160hLSzvqc9rKKWUQ3Iv2ceCZNVR/uhv/jipk6OjxeMOVmjFQvSFSbh2KNatzxynQgcGTpoAQbF6sz0nQOTaO5v46FArx/vvvN0nfnPvrSZMm8c477wDw5ZdfUlVVBcDUqVP54IMPGmIcVFZWsmfPniYyuFwu3G53k2ekpqZiNptZuHDhYenbk6gbBCHENCHEdiHELiHE/c2cv0cIsUUIsUEIsUAIEbXQV6YUB8YEG56VxZTP28T+R5ZT/sZmPD/sJ1zhOyx9uMJH2WsbUH0KKbcOxZLhipZoOu1IbHIqmTnD2PL9d1Fra9U5OZk2bRrhcJhBgwZx//33H+b+euLEiU08iNa7vx41ahTJyckNx2fNmsWSJUvIycnho48+IjMzE4DBgwfz6KOPct555zFs2DDOPfdciouLm8iQlJTExIkTGTJkCL/73e+YPn06a9asYejQobz55pvtHgOhMVF1fy2EMAI7gHOBQmA1cK2UckujNFOAlVJKrxDiTmCylPJnR7rv8bq/VoMKgbwaAjuq8G+vJFyhVb9MSTZsAxKxDkjAFGel/PXNyJBC8i1DsfTQvWh2JbYs+Y4vX3yWn81+gp6DhnS0ODqtQHd/3b50RvfXY4FdUsq8iDDvApcBDQZBSrmwUfoVwHVRlgmDxYh9YCL2gYlAH8LlPvzbK/HvqMKz6gCeH/Zr6Rwmkm8diqW7bgy6Gv3Gns78/3uZzYsX6AZBR6eVRNsg9AD2NdovBMYdIf0twJfNnRBC3A7cDjRUv9oLU7IdZ3IPnBN7IEMKgfxavHsLcQ7NwpKmG4O2IKUkHK4lEDiAP1BMMFiO1ZqOM6Y/FkvKcXl/DQYr8dRtx1u3GynDCGFGCCPCYMJQvy3MDJjanf3bPqe0ZBhmqxOj0Y7JGIPBaMdocGA02jEYzO2Y666JqgZRlDoUxY/Vmn5CPfOqapBw2E047G7YllJpYQk3bCMEAgGIptuIiPz12wbt92EwYRCmyG/FhMFgQmvAaM+8hFHVQGQJosqgJpcwIDBGZDFGnlu/bYjsH/rOW2q5kQjR/rLX02mGnQohrgNGA2c1d15K+RrwGmhNRtGSI4ybAvk8RYZ3sOxMppvnSrp3uwqHIztajwQ0BVpXt4OKikWUVyzG683HaLRjNGqKy2hwYDQ5GhSZdtyB0RRDTEw/4mKHYzafmHkRmrKvwe/fjz9QTMB/gECgGH/gAIHI4vcfQFUP75cBMJsTiInpjzOmPzHOyDqmP2Zz0w57RQlQ591JnWc7nvqlbjvBYFmr5DT1hMyesHHzrS2mEcISeZ92jMYYjEYHFksyVmvaIUs6NmsaJlN8iwpTSoVwuJZQqJpQqIZQqAq/t5TKA/lYrAnEJvYmNiEbmy0No9HZasWrKAECgf3a+44sgcABpAyDMAARhRhRhPVKKBQIUFdVSSjgw2AKgzGEMASRIoDEj6p6UZQ6VBlseJbVkkZS8hRSkqeSkHA6RqOtVTIeSihUTXX1Kmpq1hEMVRIOu1Eiij+suBsZgUDDNYkJr+L1Nu3WbFCYEUVqEDaEqE8jkUiQEk2BSqSUSKkCqraNilTDNKdgtXubGgyGEEZEI0VNEyV+cB8kihpAVQKNDEBA+x4H744QJk3PSzUiU/uoLbs9E7M5OiMdo20QioCMRvs9I8eaIIQ4B/hf4CwpZeDQ8ycCKVX2F7/P7t1PEwpV0737TwkGy9i79+/s2fMK8fHj6N7talJTp2E0tk+QG0XxUlm1nIqKRVSUL8If0JqqnM5BJCVNQlUDKIoPRfESVuoIBEsb9lVVWzfG4cgmNnY4cbEjiIsbTkzMAAyGY//EqhrA7z+AP7CfQCMl5A8U4/cXEwjsP+zZQhixWFKxWdMj8k/BZk3Hak3HakvHYk7CHyimzrMDT90O6up2UHzgYxTF03CP+hqEweigrm4HXm8BoI0EMxisxMT0JSnxTGKcA3A6BxIT0xejwYYqw0g1FCk9hrR9qaAqQf779J9wpSRy1nW/aHh3TRbVFykdR86FPQQCJdTWbiAUqjjs3RgMVqwWzUgYjLaIAagiFKohHK6lxT+9B4oa3U4qRmQ4BqOIx2xKwmpLJ8bZE6vDhUoV/kYG4HA5BBZLMgZh1hRivSJUwyjhEEo4hKqEkaoKAqQKap0BJWhEDRlQggaUkAE1aEANuRDYMAg7RrMVa1IlPu/77N//LlIxEqhMIVCWRqA8DTV08HdvdcSQkpVNalY2KVnZxCQ7cHt+pKp6JdVVK/HUbY/8LixYLImYTC5MRidmczw2ewaoVgLuEHVVXtxltVQXVxE7xUTY68JksmCy2DBZ7JgsVgytcFQopSQcDBIOBggHg4SCAcKBAKqiaErfqNlOgxGEQTYsGCRCBMDg0+wp9caldQhhxGCwYjK5MBisqGEI+kIEPH5URQHAbIvBYrdjsdkxWc2R+ytIqR6s8Rz2zOYLC1p+ouczLdqdyia0TuWpaIZgNfBzKeXmRmlGAB8A06SUO1tz3/aOqVxbu4Ht22dR695AfNwY+g+Yjcup9eQHAiUUF3/E/uJ/4/PtxWh0kp5+Kd27/RSXa8gxV6+93nzKKxZRUbGYqqqVSBnEaHSQmDCRpKTJJCWdhc3WrVX3klJFUepwu7dQU7OWmtq11NSsbVAgBoOd2NhhxMUOJy5uODZbT0KhKoLBCoKhCkLByibrYLCCUKQ0dygWSzI2a3estm7YbN2xWbtjs0X2relYLMnHXI2VUhIIFOPxbKeuLmIoPDsJK55I7UFT/M6YATgcWW2qJv/w/tss//BdbvvbPGKTU47pWlUNEgiUEQgeIBAoOWxRFR8mcxwyZMVbHaC2pJaqwgoCHpVwwEhcYi+69R5Kt37DCYdq8dQUUOcpJOAvIRQuR5E1YKrD7AhicoQxmrX/ohoShH12CMdiFIlYTKnY7D1xxmYTl9CXhNQBOGITKdtbQNG2zRRt3Uzhts14a6oBsLti6TFwMD0G5tBz0BDi0tIJer346zwE6uoIeD2NtuvwezwEvHUE6jzaqCyhYHKVYIovxJxQiMGquZAIe5IIVfUgXN2TuvIgQbkdR5qbmG5e7IlaLUOqJsyyN3Gxo+mWeS4paeMI+cMc2L2TkrxdHNi9gwO7d+Iuj9TyhCCpRwbpffqRNmYiWd27EwoGNGMWwWS2YLJaMFmsmC1WjBYzSigcUf4BQsEgSjDYMKJMCIHJoqU3mEwgNYNZv25uW1UVwkEtDwaTEavDjsVuw2S1IIRW65AomnVFYDBYMRisCGEk5Pfh92jvVFUUhMGA1RGD1eFACYUI+LyEAn6Qmmxmm10zEHYHZqv1MB2iKgrhUBAlGCIcCmpLMIgSCgEQn96tVaFi29KpHFWDEBHgQuB5wAjMk1L+WQjxCLBGSvmJEGI+MBSoH3u1V0p56ZHu2V4GIRisZPfup9hf/D4WSwr9+j5AWtolzSp5KSXV1avYv//flJZ9iaoGcDoH0b3b1SQlTSIcdkeaCqoJhSPrUFWTdTBYRiCgTZZyOPqQHDEA8fGjMRjax+pLKfH7i6ipXUttzTpqatfidm9BylAzqQ1YLIlYzEmYD1lbbekHlb61G0Zj1/TkWl1ygP/7n1s545pfMO6Knx7z9eFgEL/HHVk8+OoOblfs28ueTevwVGheLOPS0skaMpysYcPJyBmG3XX0OStSVfHW1lBbVkptRSHuyhI8lT48FRV4KstxV1TgqaxAVcJNLxQi0lQCsSmpmvIfmEOPgTkk9ujZbv0A9U2ZZeXzKS//jtra9TQuzRqEHTN9CNWkUL3HxIGttXirahvO22Pj8NXWNOzHpaWT3rsf6X36kd6nP6m9+2CxaTWPegUmpUQJRxR+4GCJv14hNsZgMmK2WDHVL1YLJrOlTflXwmGCPi8Bbx1BnxdV0WpYFqsdi8OB1RGDyWIBIOT346+LGIFwGCEE1pgYbDEuLA7HYbUaVVEI+v0EfV6CPh/hoNYQYjAYMNvtGI2mBsVfX7MAzYAYzWbNKFosGM0WLHY7RtPRa/6d0iBEg+M1CFIqFBX9i915z6IodWT0vIHs7LswmVo3zyAUqqWk5BP2F/8bt3tzi+lMJhdmUwJmc3xkSSA2bjjJSZOx29u3Y/xIKEoAj2czgUApZnOiZgQsSZhMcY3aY09e3p11H0Xbt2AyWzCaTBiMRm1tMmM0GTEYTRhMJu2YwUjQ72tQ+vV/3OawOV1kDjmNrKHDyRw6nPi09nclAAeNhruiHHdlOZ6Kcuqqq0nq0ZMeg3KITT6y64P2JBAsp6J8IeFwLfHxY3A6Bx/WLFlXXUVZQR6le/KpKi4iLjWd9N59SevT74hG8mjDTlVFK8WHQ0GMJrOmIFuhGNuClJJQwE/A6yXorSMUiChwkwmBZjyEEFpNwOnE6ohpVdNWPUo4TNDvazAQUlUwmi2NFH99/sxtNu66QWgF1TW5bN8+G49nCwkJE+jffxbOmH5tlsXt3ozbsxWzKb6R4o/HZIpvU/u9TvtTtreA7T8sQQmHUcNhba1o68bbqqKghsNY7A5sThc2pxOb04Xd6cIa42yyb3M6MdvseqzsdqSzzUOob1IyGAxNag9IsMbEYI2JwWA4vtE+iqI08XTannTGeQidit15z1FQ8Des1nSGDHmB1JQLjvsP7XLl4HLltJOEOtEgJbMXKZm9OloMnWPgyy+/5MCB9vVFlZ6ezgUXXHDENAUFBZx//vmMGzeODz/8kNTUVM466yx++OEHxowZw0033cSsWbMoLS3l7bffZuzYsSxevJi7774b0Jp4lixZQm5uLg899BAul4tdu3YxZcoUXnrpJQwGA06nk1/+8pfMnz+fF198kVWrVjFv3jwAbr31Vn79619TUFDAtGnTGDVqFD/++CM5OTm8+eabOBzRdel+8rcXNCI+bjRZWXcyYfy3pKVeqJfudHR0DmPnzp3MmDGDzZs3s2/fPn7729+ybds2tm3bxjvvvMPSpUt5+umneeyxxwB4+umnefHFF1m3bh3ff/89drvWJ7Jq1SpeeOEFtmzZwu7duxu8n9bV1TFu3DjWr1+P3W7n9ddfZ+XKlaxYsYK///3vrF27FoDt27czY8YMtm7dSmxs7AkJmnNK1RCSks4kKenMjhZDR0fnKBytJB9NsrKyGD9+PAUFBWRnZzN06FAAcnJymDp1KkIIhg4dSkFBAQATJ07knnvuYfr06Vx55ZX07NkTgLFjx9K7d28Arr32WpYuXcpVV12F0WjkJz/5CQBLly7liiuuICYmBoArr7yS77//nksvvZSMjAwmTpwIwHXXXcecOXO49957o5r3U6qGoKOjo3M06pUz0BAZDbQRQfX7BoOBcFgb+XX//fczd+5cfD4fEydOZNu2bQCHtUDU79tstlb1G7R0fTTRDYKOjo7OcbB7926GDh3Kfffdx5gxYxoMwqpVq8jPz0dVVd577z3OOOOMw64988wz+c9//oPX66Wuro6PP/6YM8/UWjH27t3L8uXLAXjnnXeavb690Q2Cjo6OznHw/PPPM2TIEIYNG4bZbG5o7hozZgwzZ85k0KBBZGdnc8UVVxx27ciRI7nxxhsZO3Ys48aN49Zbb2XEiBEADBgwgBdffJFBgwZRVVXFnXfeGfW8nHLDTnV0dDonnW3Y6fGwaNEinn76aT777LM2XV9QUMDFF1/Mpk2b2ixDW4ad6jUEHR0dHR3gFBtlpKOjo3MimDx5MpMnT27z9b169Tqu2kFb0WsIOjo6OjqAbhB0dHR0dCLoBkFHR0dHB9ANgo6Ojo5OBN0g6Ojo6HQhpk+fzoABAxgyZAg333wzoWbiRLQV3SDo6OjoNIOUErVR5LZooDQKhtNapk+fzrZt29i4cSM+n4+5c+e2mzz6sFMdHZ1Ox44df8Lt2dqu93Q5B9G//x+PmKYruL++8MILG+QdO3YshYWF7faO9BqCjo6OTiO6ivvrUCjEW2+9xbRp09ot71GvIQghpgF/RYupPFdK+cQh5yehxVweBlwjpfwg2jLp6Oh0bo5Wko8mXcX99YwZM5g0aVKDM7z2IKoGQQhhBF4EzgUKgdVCiE+klFsaJdsL3AhE19E3IBUFDIYTFhhH9fsJl5QQKikhXFJKuKIcU1Iylt7ZWHv1wtDIzW5nQQ0GCZeWYrBaMcbHI8zmqD5PqipKRQWhklLCpSWES0uRwSCm1FRMqWmY01IxpaZGXY6OQCoK4YoKwqVlWt5LSlDcnlZeLEFVkIqqrcNKw75UwqCoSFWBsIKwWjGlpja8S1NaGqbUVIxO51Efo/r9hMvKDv6OS7VtpIo5IxNLZgbmjAwsPXogIgHouzptcX990UUX8cUXXzBx4kS+/vprILrurx9++GHKysp49dVXjyVrRyXaNYSxwC4pZR6AEOJd4DKgwSBIKQsi56LbewOUPvsslW++hdHlwuByYnTFHlzHujA6XQfXLhfC1OijNXYCeIhDQNXnJ1zaSPGXlBAqLUWtqTmiPKZu3bBmZ2Pp3RtLdi+svXtj6d1bU4CNPr5UVVSvD7WuDtVbh1rnPbjt9SIsFowxMRgcDgwxMdoS2T5UkcpQiFBxMaGiIkJFRQQj61Chtg6XljbJn8HpxBgfjzEhIbKOx9SwndDUqB3qKLHRvlRUlMqI4i8paXhH4bIyiPyxWkQIjElJmFNTMaWnY0pLxZyWhik1DWOsq0l+G78D0UIAdqkoqN7IO2xmUdweVI8bxe1GdXtQ3LWobg+q243i8aDW1qJ4PBAOYzj0txT57Wi/MRdGlxPhcKBUVzf6bUR+J+XlR897azGZEAYDGI3autG+9Gm/nUMxOBwNxsGUloopMQnFXdsgZ7i0FKWZ37CwWsFgQPp8jW5mwJyejjkrE0uDocjEktETg9OJsFoRFgsGq1XbPoJClFKCqmoFOEU5uFbVg/sAQgAishIHjx2y3eS9GAwN6+YKh1JRQEoUt4dwTQ0yHCZYVIQMhVBqawnuK8S3eQuBA8XIYJBAQQF5+/YxsG9fBt50E6uWLWNLbi5xiYmsWrWK3du2kZWRwbvvvMNtN92k/W4Axe0GKTl9+HBunjGD3915J1IIPv7wQ/7xf/+HGgiwd+9efli2jAmnn97E/fXcuXP5+uuvWbBgAQZD+7b6R9sg9AD2NdovBMa15UZCiNuB2wEyMzPbJEzM+PEIgxHF40atdTf80QNlu7V9jwfp9bbp3hgMmJKSMKWlYc7MxDFmNKbUNG0/LVIqS0oiXFZGIC+fYH4+wfw8Ann51Hz8cZM/rMHhwJiSHFFa3rbLBNqfMKIkpaJoCr/xyIn6P3LPnsScfjrmHj0wd0tHBoOaEquqQqmqRqmuRqmqIpifj1JV1ayCadVrionR3kVaKjFjxzZsayVY7X0Ji4VwaenBUumBkgaDGyosxJeb26yiajbvESOB0Rgxot6miuxI11utmlJ3OjHExmJ0OjGlpzcofmEyasbD7dZ+U24PgbKyBuOhHvLdmuR93LiG7fp8m1LTMMbFHlRoR5OvsaI7CmpdnWaA62sjpaVNSvy+3B8JV1RgjI3VvkVmJvbRozTZUlIP/o5TUzHExgIQLisjtG8fwb37CO3bS3DvPoL79uL+9luUqqojC2QyYbBYNONgtSKsFkIPPIAfDir8E0Bj40A4TGDfPmQwSHBPAeEDB0BRUN1uhMmMMBoxxDgwJSYiamu076QozHntNZasWIFBCAb17cvZgwaxcv16Rg0ezK9uv528ffuYNGYMFw4dSrCgAFSV4J49AAxJSuK6Cy9k/KRJANx45ZUMdrnYU1BA/169eOHxx7l5yxYG9unDTb+aiX/nTu644w6ysrKYMGECoDUzPfTQQ+3zPqLp/loIcRUwTUp5a2T/emCclHJmM2nfAD5rTR9CNN1fy1BIKwW63U0VpyZks9vCasWUlNRiifSoz5SScGkZwfw8gvn5BPLyUSormy3xG2LqS8KRbbsdGQo1KLuGkm4z2yA0hd+jB+aePbV1WtuaY9SIwVDr6pqWsg5VZo1Ka8aERIzO9mkmU/1+wqWlqB5P0/xG1kpdHdLrbVjLsHLwXTYsB9+vsfHxiBE43iYQqSiafB4Phrj4dst7V0Bxuwnu3UuosAjV50UGgshAABkMoAaDTfcDAWQgSOWVVzCwVy/NyBmNB9cGI8JoaLTfyADW6y8pG7Zlo21UVattNF4ryuHHVBVhMmn/YbMZUb/U17RagWxUq1m4cCHP/vWvfPLeewdrLZEaDSLS/NN4qa8VRWTJz8/n8muuYe2SJU3zoKiYkpMxOOxHlact7q+jXUMoAjIa7feMHOu0CLMZU0ICJCScuGcKgTlNa+ONGT/+hD33eDBYLBhSUzvu+TYbljbWFE8UwmjEGBeHMS6uo0U54RhdLuw5Odhzclp9Te3WrZi7dz+2BzVTmzoxPYSHI+qbo8xmjHY7wmRq87c3xcWB0Yg5JaWdpTzKc6N8/9VAPyFENpohuAb4eZSfqaOjo9Oh6O6vm0FKGQZmAl8DW4F/Syk3CyEeEUJcCiCEGCOEKASuBl4VQmyOpkw6Ojqdl64YwbEz0tb3GPV5CFLKL4AvDjn2UKPt1WhNSTo6OqcwNpuNiooKkpKSTtjQ8JMRKSUVFRXYbLZjvlZ3XaGjo9Mp6NmzJ4WFhZSVlXW0KF0em83WMEHuWNANgo6OTqfAbDaTnZ3d0WKc0ui+jHR0dHR0AN0g6Ojo6OhE0A2Cjo6Ojg4Q5ZnK0UIIUQbsaePlyUB5O4rTGTjZ8nSy5QdOvjydbPmBky9PzeUnS0rZ4my3LmkQjgchxJojTd3uipxseTrZ8gMnX55OtvzAyZentuRHbzLS0dHR0QF0g6Cjo6OjE+FUNAivdbQAUeBky9PJlh84+fJ0suUHTr48HXN+Trk+BB0dHR2d5jkVawg6Ojo6Os2gGwQdHR0dHeAUMwhCiGlCiO1CiF1CiPs7Wp7jRQhRIITYKIRYJ4SITgi5KCOEmCeEKBVCbGp0LFEI8a0QYmdkfeKiFR0nLeRnthCiKPKd1gkhLuxIGY8VIUSGEGKhEGKLEGKzEOLuyPEu+Z2OkJ8u+52EEDYhxCohxPpInh6OHM8WQqyM6Lz3hBBHDAN4yvQhCCGMwA7gXLTYzquBa6WUWzpUsONACFEAjJZSdtnJNEKISYAHeFNKOSRy7EmgUkr5RMRwJ0gp7+tIOVtLC/mZDXiklE93pGxtRQjRDegmpfxRCOECcoHLgRvpgt/pCPn5KV30OwnNX3iMlNIjhDADS4G7gXuAj6SU7wohXgHWSylfbuk+p1INYSywS0qZJ6UMAu8Cl3WwTKc8UsolQOUhhy8D/hHZ/gfan7VL0EJ+ujRSymIp5Y+RbTdasKsedNHvdIT8dFmkhieya44sEjgbqI9Tf9RvdCoZhB7Avkb7hXTxHwHaB/9GCJErhLi9o4VpR9KklMWR7QNAWkcK007MFEJsiDQpdYmmleYQQvQCRgArOQm+0yH5gS78nYQQRiHEOqAU+BbYDVRHIldCK3TeqWQQTkbOkFKOBC4AfhVprjipkFqbZldv13wZ6AMMB4qBZzpWnLYhhHACHwK/llLWNj7XFb9TM/np0t9JSqlIKYejRaAcCww81nucSgahCMhotP//7d1BaB1VFMbx/2dFiQkYhHbTohLrogpRKBRsKgSEri1EbWtDcOXCjTtRKoVAt60bwVBaaDFqo000uDSUoIvSiBZaGleli7hINipUUEpzurjnSQzvJSQhmU7f99vk5b7JcC83M2fm3plzd2VZbUXE7/lzAZig/BM8DOZznLcx3rtQcX02JCLm82BdBM5Qw37KcelLwGhEjGdxbfupWXsehn4CiIg/gcvAK0C3pMZCaKue89opIMwAz+es+2PAYWCy4jqtm6TOnBBDUidwELix8l/VxiQwlJ+HgO8qrMuGNU6a6RA166ecsDwLzEbEqSVf1bKfWrWnzv0kabuk7vzcQXl4ZpYSGAZys1X7qG2eMgLIx8g+AbYB5yLiZMVVWjdJPZS7AihLoX5Rx/ZI+hLop6TqnQdOAN8CY8DTlDTnb0ZELSZqW7SnnzIMEcBt4N0lY+8PPEkHgB+B68BiFn9EGXevXT+t0J4j1LSfJPVSJo23US70xyJiOM8TXwFPAb8CxyLi35b7aaeAYGZmrbXTkJGZma3AAcHMzAAHBDMzSw4IZmYGOCCYmVlyQDDbYpL6JX1fdT3MlnNAMDMzwAHBrCVJxzLH/DVJI5k87I6k05lzfkrS9tz2ZUlXMjHaRCMxmqTdkn7IPPW/SHoud98l6RtJv0kazbdnzSrlgGDWhKQ9wFtAXyYMuwe8DXQCP0FnMxAAAAEsSURBVEfEi8A05U1kgAvABxHRS3kDtlE+CnwaES8B+ylJ06Bk2HwfeAHoAfo2vVFmq3h09U3M2tJrwF5gJi/eOyjJ2xaBi7nN58C4pCeB7oiYzvLzwNeZa2pnREwARMQ/ALm/qxExl79fA56lLGpiVhkHBLPmBJyPiA//Vyh9vGy79eZ+WZpP5h4+Fu0B4CEjs+amgAFJO+C/9YOfoRwzjeyRR4GfIuIv4A9Jr2b5IDCdq3HNSXo99/G4pCe2tBVma+CrErMmIuKmpOOUFekeAe4C7wF/A/vyuwXKPAOU1MKf5Qn/FvBOlg8CI5KGcx9vbGEzzNbE2U7N1kDSnYjoqroeZpvBQ0ZmZgb4DsHMzJLvEMzMDHBAMDOz5IBgZmaAA4KZmSUHBDMzA+A+U12hkhKQ5g0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rryLxsN_koW",
        "colab_type": "text"
      },
      "source": [
        "1. The 'adam' optimizer with learning rate of 0.0001 has the best performance. \n",
        "2. The accuracy rate of 'adamax' optimizer with different learning rates has big difference. The model with learning rate of 0.01 has accuracy rate of more than 70%, however, models with learning rate of 0.1 and 0.001 has really bad accuracy rate. So accuracy rate of this optimizer can be influenced by learning rate obviously. \n",
        "3. The accuracy rate of 'rmsprop' optimizer with different learning rates has big difference. The model with 0.001 has accuracy rate of more than 70%, however, models with learning rate of 0.1 has really bad accuracy rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydAqeY9S8uHA",
        "colab_type": "text"
      },
      "source": [
        "### Additional Written Tasks\n",
        "\n",
        "1. Describe the process of backpropagation in your own words: \n",
        "```\n",
        "Your answer goes here.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8zSBnHECcJ7",
        "colab_type": "text"
      },
      "source": [
        "Backpropagation is a algorithm allowing us to adjust weights of all layers from right to left. \n",
        "\n",
        "For a neural network model, the first step is to select weights for inputs randomly. \n",
        "Secondly, the output for every neuron from the input layer, to the hidden layers, and the output layer are calculated.\n",
        "Thirdly, to calculate the error in the outputs using formular like this 'error = 1/2(actual ouput - desired output)^2'.\n",
        "Fourthly, the ultimate goal is to minimize the error function in the third step, so we travel back from the output layer to the hidden layer to adjust the weights to make the error decreased. Keep repeating the process until the desired output is achieved. This backward approach is called backpropagation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FwlRJSfBlCvy"
      },
      "source": [
        "## Stretch Goals: \n",
        "\n",
        "- Implement GridSearch on anyone of the experiments\n",
        "- On the learning rate experiments, implement [EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)\n",
        "- Review material on the math behind gradient descent: \n",
        "\n",
        "  - Gradient Descent\n",
        "    - Gradient Descent, Step-by-Step  by StatQuest w/ Josh Starmer. This will help you understand the gradient descent based optimization that happens underneath the hood of neural networks. It uses a non-neural network example, which I believe is a gentler introduction. You will hear me refer to this technique as \"vanilla\" gradient descent. \n",
        "    - Stochastic Gradient Descent, Clearly Explained!!! by StatQuest w/ Josh Starmer. This builds on the techniques in the previous video.  This technique is the one that is actually implemented inside modern 'nets. \n",
        "These are great resources to help you understand tomorrow's material at a deeper level. I highly recommend watching these ahead of tomorrow.\n",
        "\n",
        "  - Background Math\n",
        "    - Dot products and duality by 3Blue1Brown. Explains the core linear algebra operation happening in today's perceptron.\n",
        "The paradox of the derivative by 3Blue1Brown. Does a great job explaining a derivative. \n",
        "    - Visualizing the chain rule and product rule by 3Blue1Brown. Explains the black magic that happens within Stochastic Gradient Descent. \n",
        "These math resources are very much optional. They can be very heady, but I encourage you to explore. Your understanding of neural networks will greatly increase if you understand this math background.\n",
        "\n",
        "\n"
      ]
    }
  ]
}